
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "generated/gallery/examples/plot_meg_data_example.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_generated_gallery_examples_plot_meg_data_example.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_generated_gallery_examples_plot_meg_data_example.py:


Support recovery on MEG data
============================

This example compares several methods that recover the support in the MEG/EEG
source localization problem with statistical guarantees. Here we work
with two datasets that study three different tasks (visual, audio, somato).

We reproduce the real data experiment of Chevalier et al. (2020) [1]_,
which shows the benefit of (ensemble) clustered inference such as
(ensemble of) clustered desparsified Multi-Task Lasso ((e)cd-MTLasso)
over standard approach such as sLORETA. Specifically, it retrieves
the support using a natural threshold (not computed a posteriori)
of the estimated parameter. The estimated support enjoys statistical
guarantees.

References
----------
.. [1] Chevalier, J. A., Gramfort, A., Salmon, J., & Thirion, B. (2020).
       Statistical control for spatio-temporal MEG/EEG source imaging with
       desparsified multi-task Lasso. In NeurIPS 2020-34h Conference on
       Neural Information Processing Systems.

.. GENERATED FROM PYTHON SOURCE LINES 24-46

.. code-block:: Python


    import os

    import matplotlib.image as mpimg
    import matplotlib.pyplot as plt
    import mne
    import numpy as np
    from mne.datasets import sample, somato
    from mne.inverse_sparse.mxne_inverse import _make_sparse_stc, _prepare_gain
    from mne.minimum_norm import apply_inverse, make_inverse_operator
    from scipy.sparse.csgraph import connected_components
    from sklearn.cluster import FeatureAgglomeration
    from sklearn.metrics.pairwise import pairwise_distances

    from hidimstat.clustered_inference import clustered_inference
    from hidimstat.ensemble_clustered_inference import ensemble_clustered_inference
    from hidimstat.stat_tools import zscore_from_pval

    offscreen = True
    save_fig = False
    plot_saved_fig = False
    interactive_plot = False







.. GENERATED FROM PYTHON SOURCE LINES 47-54

Specific preprocessing functions
--------------------------------
The functions below are used to load or preprocess the data or to put
the solution in a convenient format. If you are reading this example
for the first time, you should skip this section.

The following function loads the data from the sample dataset.

.. GENERATED FROM PYTHON SOURCE LINES 54-105

.. code-block:: Python



    def _load_sample(cond):
        """Load data from the sample dataset"""

        # Get data paths
        subject = "sample"
        data_path = sample.data_path()
        fwd_fname_suffix = "MEG/sample/sample_audvis-meg-eeg-oct-6-fwd.fif"
        fwd_fname = os.path.join(data_path, fwd_fname_suffix)
        ave_fname = os.path.join(data_path, "MEG/sample/sample_audvis-ave.fif")
        cov_fname_suffix = "MEG/sample/sample_audvis-shrunk-cov.fif"
        cov_fname = os.path.join(data_path, cov_fname_suffix)
        cov_fname = data_path + "/" + cov_fname_suffix
        subjects_dir = os.path.join(data_path, "subjects")

        if cond == "audio":
            condition = "Left Auditory"
        elif cond == "visual":
            condition = "Left visual"

        # Read noise covariance matrix
        noise_cov = mne.read_cov(cov_fname)

        # Read forward matrix
        forward = mne.read_forward_solution(fwd_fname)

        # Handling average file
        evoked = mne.read_evokeds(ave_fname, condition=condition, baseline=(None, 0))
        evoked = evoked.pick_types("grad")

        # Selecting relevant time window
        evoked.plot()
        t_min, t_max = 0.05, 0.1
        t_step = 0.01

        pca = False

        return (
            subject,
            subjects_dir,
            noise_cov,
            forward,
            evoked,
            t_min,
            t_max,
            t_step,
            pca,
        )









.. GENERATED FROM PYTHON SOURCE LINES 106-107

The next function loads the data from the somato dataset.

.. GENERATED FROM PYTHON SOURCE LINES 107-165

.. code-block:: Python



    def _load_somato(cond):
        """Load data from the somato dataset"""

        # Get data paths
        data_path = somato.data_path()
        subject = "01"
        subjects_dir = str(data_path) + "/derivatives/freesurfer/subjects"
        raw_fname = os.path.join(
            data_path, f"sub-{subject}", "meg", f"sub-{subject}_task-{cond}_meg.fif"
        )
        fwd_fname = os.path.join(
            data_path, "derivatives", f"sub-{subject}", f"sub-{subject}_task-{cond}-fwd.fif"
        )

        # Read evoked
        raw = mne.io.read_raw_fif(raw_fname)
        events = mne.find_events(raw, stim_channel="STI 014")
        reject = dict(grad=4000e-13, eog=350e-6)
        picks = mne.pick_types(raw.info, meg=True, eeg=True, eog=True)

        event_id, tmin, tmax = 1, -0.2, 0.25
        epochs = mne.Epochs(
            raw, events, event_id, tmin, tmax, picks=picks, reject=reject, preload=True
        )
        evoked = epochs.average()
        evoked = evoked.pick_types("grad")
        # evoked.plot()

        # Compute noise covariance matrix
        noise_cov = mne.compute_covariance(epochs, rank="info", tmax=0.0)

        # Read forward matrix
        forward = mne.read_forward_solution(fwd_fname)

        # Selecting relevant time window: focusing on early signal
        t_min, t_max = 0.03, 0.05
        t_step = 1.0 / 300

        # We must reduce the whitener since data were preprocessed for removal
        # of environmental noise with maxwell filter leading to an effective
        # number of 64 samples.
        pca = True

        return (
            subject,
            subjects_dir,
            noise_cov,
            forward,
            evoked,
            t_min,
            t_max,
            t_step,
            pca,
        )









.. GENERATED FROM PYTHON SOURCE LINES 166-168

The function below preprocess the raw M/EEG data, it notably computes the
whitened MEG/EEG measurements and prepares the gain matrix.

.. GENERATED FROM PYTHON SOURCE LINES 168-243

.. code-block:: Python



    def preprocess_meg_eeg_data(
        evoked, forward, noise_cov, loose=0.0, depth=0.0, pca=False
    ):
        """Preprocess MEG or EEG data to produce the whitened MEG/EEG measurements
        (target) and the preprocessed gain matrix (design matrix). This function
        is mainly wrapping the `_prepare_gain` MNE function.

        Parameters
        ----------
        evoked : instance of mne.Evoked
            The evoked data.

        forward : instance of Forward
            The forward solution.

        noise_cov : instance of Covariance
            The noise covariance.

        loose : float in [0, 1] or 'auto'
            Value that weights the source variances of the dipole components
            that are parallel (tangential) to the cortical surface. If loose
            is 0 then the solution is computed with fixed orientation.
            If loose is 1, it corresponds to free orientations.
            The default value ('auto') is set to 0.2 for surface-oriented source
            space and set to 1.0 for volumic or discrete source space.
            See for details:
            https://mne.tools/stable/auto_tutorials/inverse/35_dipole_orientations.html?highlight=loose

        depth : None or float in [0, 1]
            Depth weighting coefficients. If None, no depth weighting is performed.

        pca : bool, optional (default=False)
            If True, whitener is reduced.
            If False, whitener is not reduced (square matrix).

        Returns
        -------
        G : array, shape (n_channels, n_dipoles)
            The preprocessed gain matrix. If pca=True then n_channels is
            effectively equal to the rank of the data.

        M : array, shape (n_channels, n_times)
            The whitened MEG/EEG measurements. If pca=True then n_channels is
            effectively equal to the rank of the data.

        forward : instance of Forward
            The preprocessed forward solution.
        """

        all_ch_names = evoked.ch_names

        # Handle depth weighting and whitening (here is no weights)
        forward, G, gain_info, whitener, _, _ = _prepare_gain(
            forward,
            evoked.info,
            noise_cov,
            pca=pca,
            depth=depth,
            loose=loose,
            weights=None,
            weights_min=None,
            rank=None,
        )

        # Select channels of interest
        sel = [all_ch_names.index(name) for name in gain_info["ch_names"]]

        M = evoked.data[sel]
        M = np.dot(whitener, M)

        return G, M, forward









.. GENERATED FROM PYTHON SOURCE LINES 244-246

The next function translates the solution in a readable format for the
MNE plotting functions that require a Source Time Course (STC) object.

.. GENERATED FROM PYTHON SOURCE LINES 246-262

.. code-block:: Python



    def _compute_stc(zscore_active_set, active_set, evoked, forward):
        """Wrapper of `_make_sparse_stc`"""

        X = np.atleast_2d(zscore_active_set)

        if X.shape[1] > 1 and X.shape[0] == 1:
            X = X.T

        stc = _make_sparse_stc(
            X, active_set, forward, tmin=evoked.times[0], tstep=1.0 / evoked.info["sfreq"]
        )
        return stc









.. GENERATED FROM PYTHON SOURCE LINES 263-265

The function below will be used to modify the connectivity matrix
to avoid multiple warnings when we run the clustering algorithm.

.. GENERATED FROM PYTHON SOURCE LINES 265-294

.. code-block:: Python



    def _fix_connectivity(X, connectivity, affinity):
        """Complete the connectivity matrix if necessary"""

        # Convert connectivity matrix into LIL format
        connectivity = connectivity.tolil()

        # Compute the number of nodes
        n_connected_components, labels = connected_components(connectivity)

        if n_connected_components > 1:

            for i in range(n_connected_components):
                idx_i = np.where(labels == i)[0]
                Xi = X[idx_i]
                for j in range(i):
                    idx_j = np.where(labels == j)[0]
                    Xj = X[idx_j]
                    D = pairwise_distances(Xi, Xj, metric=affinity)
                    ii, jj = np.where(D == np.min(D))
                    ii = ii[0]
                    jj = jj[0]
                    connectivity[idx_i[ii], idx_j[jj]] = True
                    connectivity[idx_j[jj], idx_i[ii]] = True

        return connectivity, n_connected_components









.. GENERATED FROM PYTHON SOURCE LINES 295-300

Downloading data
----------------

After choosing a task, we run the function that loads the data to get
the corresponding evoked, forward and noise covariance matrices.

.. GENERATED FROM PYTHON SOURCE LINES 300-317

.. code-block:: Python


    # Choose the experiment (task)
    list_cond = ["audio", "visual", "somato"]
    cond = list_cond[2]
    print(f"Let's process the condition: {cond}")

    # Load the data
    if cond in ["audio", "visual"]:
        sub, subs_dir, noise_cov, forward, evoked, t_min, t_max, t_step, pca = _load_sample(
            cond
        )

    elif cond == "somato":
        sub, subs_dir, noise_cov, forward, evoked, t_min, t_max, t_step, pca = _load_somato(
            cond
        )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Let's process the condition: somato
    Using default location ~/mne_data for somato...
    Creating /home/circleci/mne_data
    Downloading file 'MNE-somato-data.tar.gz' from 'https://osf.io/download/tp4sg?version=7' to '/home/circleci/mne_data'.
      0%|                                               | 0.00/611M [00:00<?, ?B/s]      0%|▏                                     | 2.66M/611M [00:00<00:22, 26.6MB/s]      1%|▌                                     | 8.27M/611M [00:00<00:13, 43.9MB/s]      2%|▉                                     | 14.6M/611M [00:00<00:11, 52.8MB/s]      4%|█▎                                    | 21.7M/611M [00:00<00:09, 60.1MB/s]      5%|█▊                                    | 28.8M/611M [00:00<00:09, 63.8MB/s]      6%|██▏                                   | 36.1M/611M [00:00<00:08, 67.1MB/s]      7%|██▋                                   | 43.6M/611M [00:00<00:08, 69.7MB/s]      8%|███▏                                  | 51.0M/611M [00:00<00:07, 71.0MB/s]     10%|███▋                                  | 58.4M/611M [00:00<00:07, 72.1MB/s]     11%|████                                  | 65.9M/611M [00:01<00:07, 72.9MB/s]     12%|████▌                                 | 73.2M/611M [00:01<00:07, 72.2MB/s]     13%|█████                                 | 80.6M/611M [00:01<00:07, 72.8MB/s]     14%|█████▍                                | 87.9M/611M [00:01<00:07, 69.1MB/s]     16%|█████▉                                | 94.8M/611M [00:01<00:07, 69.0MB/s]     17%|██████▌                                | 102M/611M [00:01<00:07, 70.6MB/s]     18%|███████                                | 110M/611M [00:01<00:07, 71.4MB/s]     19%|███████▍                               | 117M/611M [00:01<00:06, 72.2MB/s]     20%|███████▉                               | 124M/611M [00:01<00:06, 72.2MB/s]     22%|████████▍                              | 131M/611M [00:01<00:06, 72.0MB/s]     23%|████████▊                              | 139M/611M [00:02<00:06, 72.4MB/s]     24%|█████████▎                             | 146M/611M [00:02<00:06, 72.4MB/s]     25%|█████████▊                             | 153M/611M [00:02<00:06, 71.8MB/s]     26%|██████████▎                            | 161M/611M [00:02<00:06, 72.2MB/s]     28%|██████████▋                            | 168M/611M [00:02<00:06, 72.6MB/s]     29%|███████████▏                           | 175M/611M [00:02<00:05, 73.0MB/s]     30%|███████████▋                           | 183M/611M [00:02<00:05, 73.1MB/s]     31%|████████████▏                          | 190M/611M [00:02<00:05, 72.7MB/s]     32%|████████████▌                          | 197M/611M [00:02<00:05, 71.9MB/s]     34%|█████████████                          | 205M/611M [00:02<00:05, 72.4MB/s]     35%|█████████████▌                         | 212M/611M [00:03<00:05, 69.7MB/s]     36%|█████████████▉                         | 219M/611M [00:03<00:06, 61.3MB/s]     37%|██████████████▍                        | 225M/611M [00:03<00:06, 59.8MB/s]     38%|██████████████▊                        | 232M/611M [00:03<00:06, 62.7MB/s]     39%|███████████████▎                       | 239M/611M [00:03<00:05, 63.9MB/s]     40%|███████████████▋                       | 246M/611M [00:03<00:05, 67.0MB/s]     41%|████████████████▏                      | 253M/611M [00:03<00:05, 67.1MB/s]     43%|████████████████▋                      | 261M/611M [00:03<00:05, 68.9MB/s]     44%|█████████████████                      | 267M/611M [00:03<00:05, 67.1MB/s]     45%|█████████████████▌                     | 275M/611M [00:04<00:04, 68.9MB/s]     46%|██████████████████                     | 282M/611M [00:04<00:04, 70.5MB/s]     47%|██████████████████▌                    | 290M/611M [00:04<00:04, 72.1MB/s]     49%|██████████████████▉                    | 297M/611M [00:04<00:04, 70.9MB/s]     50%|███████████████████▍                   | 304M/611M [00:04<00:04, 70.1MB/s]     51%|███████████████████▉                   | 311M/611M [00:04<00:04, 70.7MB/s]     52%|████████████████████▎                  | 318M/611M [00:04<00:04, 70.5MB/s]     53%|████████████████████▊                  | 325M/611M [00:04<00:04, 69.0MB/s]     54%|█████████████████████▎                 | 333M/611M [00:04<00:03, 69.9MB/s]     56%|█████████████████████▋                 | 340M/611M [00:04<00:03, 70.7MB/s]     57%|██████████████████████▏                | 347M/611M [00:05<00:03, 68.9MB/s]     58%|██████████████████████▌                | 354M/611M [00:05<00:03, 68.2MB/s]     59%|███████████████████████                | 361M/611M [00:05<00:03, 69.5MB/s]     60%|███████████████████████▌               | 368M/611M [00:05<00:03, 70.2MB/s]     61%|███████████████████████▉               | 375M/611M [00:05<00:03, 67.3MB/s]     63%|████████████████████████▍              | 383M/611M [00:05<00:03, 68.7MB/s]     64%|████████████████████████▉              | 390M/611M [00:05<00:03, 70.4MB/s]     65%|█████████████████████████▍             | 397M/611M [00:05<00:02, 71.1MB/s]     66%|█████████████████████████▊             | 405M/611M [00:05<00:02, 71.7MB/s]     67%|██████████████████████████▎            | 412M/611M [00:05<00:02, 72.1MB/s]     69%|██████████████████████████▊            | 419M/611M [00:06<00:02, 72.5MB/s]     70%|███████████████████████████▎           | 427M/611M [00:06<00:02, 70.9MB/s]     71%|███████████████████████████▋           | 434M/611M [00:06<00:02, 71.4MB/s]     72%|████████████████████████████▏          | 441M/611M [00:06<00:02, 71.6MB/s]     73%|████████████████████████████▋          | 448M/611M [00:06<00:02, 72.3MB/s]     75%|█████████████████████████████          | 456M/611M [00:06<00:02, 72.7MB/s]     76%|█████████████████████████████▌         | 463M/611M [00:06<00:01, 73.7MB/s]     77%|██████████████████████████████         | 471M/611M [00:06<00:01, 71.6MB/s]     78%|██████████████████████████████▌        | 478M/611M [00:06<00:01, 69.8MB/s]     79%|██████████████████████████████▉        | 485M/611M [00:06<00:01, 68.5MB/s]     81%|███████████████████████████████▍       | 492M/611M [00:07<00:01, 65.4MB/s]     82%|███████████████████████████████▊       | 498M/611M [00:07<00:01, 59.9MB/s]     83%|████████████████████████████████▎      | 505M/611M [00:07<00:01, 62.1MB/s]     84%|████████████████████████████████▋      | 512M/611M [00:07<00:01, 62.2MB/s]     85%|█████████████████████████████████      | 518M/611M [00:07<00:01, 60.6MB/s]     86%|█████████████████████████████████▍     | 524M/611M [00:07<00:01, 59.4MB/s]     87%|█████████████████████████████████▉     | 531M/611M [00:07<00:01, 62.6MB/s]     88%|██████████████████████████████████▎    | 538M/611M [00:07<00:01, 64.8MB/s]     89%|██████████████████████████████████▊    | 545M/611M [00:07<00:00, 67.1MB/s]     90%|███████████████████████████████████▎   | 552M/611M [00:08<00:00, 68.3MB/s]     92%|███████████████████████████████████▋   | 559M/611M [00:08<00:00, 69.0MB/s]     93%|████████████████████████████████████▏  | 567M/611M [00:08<00:00, 69.5MB/s]     94%|████████████████████████████████████▋  | 574M/611M [00:08<00:00, 70.5MB/s]     95%|█████████████████████████████████████  | 581M/611M [00:08<00:00, 70.7MB/s]     96%|█████████████████████████████████████▌ | 588M/611M [00:08<00:00, 71.0MB/s]     97%|██████████████████████████████████████ | 595M/611M [00:08<00:00, 71.0MB/s]     99%|██████████████████████████████████████▍| 602M/611M [00:08<00:00, 71.0MB/s]    100%|██████████████████████████████████████▉| 609M/611M [00:08<00:00, 70.6MB/s]      0%|                                               | 0.00/611M [00:00<?, ?B/s]    100%|███████████████████████████████████████| 611M/611M [00:00<00:00, 2.30TB/s]
    Untarring contents of '/home/circleci/mne_data/MNE-somato-data.tar.gz' to '/home/circleci/mne_data'
    Attempting to create new mne-python configuration file:
    /home/circleci/.mne/mne-python.json
    Could not read the /home/circleci/.mne/mne-python.json json file during the writing. Assuming it is empty. Got: Expecting value: line 1 column 1 (char 0)
    Download complete in 20s (582.2 MB)
    Opening raw data file /home/circleci/mne_data/MNE-somato-data/sub-01/meg/sub-01_task-somato_meg.fif...
        Range : 237600 ... 506999 =    791.189 ...  1688.266 secs
    Ready.
    Finding events on: STI 014
    111 events found on stim channel STI 014
    Event IDs: [1]
    Not setting metadata
    111 matching events found
    Setting baseline interval to [-0.19979521315838786, 0.0] s
    Applying baseline correction (mode: mean)
    0 projection items activated
    Loading data for 111 events and 136 original time points ...
    0 bad epochs dropped
    NOTE: pick_types() is a legacy function. New code should use inst.pick(...).
        Setting small MEG eigenvalues to zero (without PCA)
    Reducing data rank from 306 -> 64
    Estimating covariance using EMPIRICAL
    Done.
    Number of samples used : 6771
    [done]
    Reading forward solution from /home/circleci/mne_data/MNE-somato-data/derivatives/sub-01/sub-01_task-somato-fwd.fif...
        Reading a source space...
        [done]
        Reading a source space...
        [done]
        2 source spaces read
        Desired named matrix (kind = 3523 (FIFF_MNE_FORWARD_SOLUTION_GRAD)) not available
        Read MEG forward solution (8155 sources, 306 channels, free orientations)
        Source spaces transformed to the forward solution coordinate frame




.. GENERATED FROM PYTHON SOURCE LINES 318-323

Preparing data for clustered inference
--------------------------------------

For clustered inference we need the targets ``Y``, the design matrix ``X``
and the ``connectivity`` matrix, which is a sparse adjacency matrix.

.. GENERATED FROM PYTHON SOURCE LINES 323-340

.. code-block:: Python


    # Collecting features' connectivity
    connectivity = mne.source_estimate.spatial_src_adjacency(forward["src"])

    # Croping evoked according to relevant time window
    evoked.crop(tmin=t_min, tmax=t_max)

    # Choosing frequency and number of clusters used for compression.
    # Reducing the frequency to 100Hz to make inference faster
    step = int(t_step * evoked.info["sfreq"])
    evoked.decimate(step)
    t_min = evoked.times[0]
    t_step = 1.0 / evoked.info["sfreq"]

    # Preprocessing MEG data
    X, Y, forward = preprocess_meg_eeg_data(evoked, forward, noise_cov, pca=pca)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    -- number of adjacent vertices : 8196
    /home/circleci/project/examples/plot_meg_data_example.py:325: RuntimeWarning: 0.5% of original source space vertices have been omitted, tri-based adjacency will have holes.
    Consider using distance-based adjacency or morphing data to all source space vertices.
      connectivity = mne.source_estimate.spatial_src_adjacency(forward["src"])
    Converting forward solution to fixed orientation
        No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....
        Changing to fixed-orientation forward solution with surface-based source orientations...
        [done]
    Computing inverse operator with 204 channels.
        204 out of 306 channels remain after picking
    Selected 204 channels
    Whitening the forward solution.
    Computing rank from covariance with rank=None
        Using tolerance 2.1e-12 (2.2e-16 eps * 204 dim * 46  max singular value)
        Estimated rank (grad): 64
        GRAD: rank 64 computed from 204 data channels with 0 projectors
        Setting small GRAD eigenvalues to zero (without PCA)
    Creating the source covariance matrix
    Adjusting source covariance matrix.




.. GENERATED FROM PYTHON SOURCE LINES 341-348

Running clustered inference
---------------------------

For MEG data ``n_clusters = 1000`` is generally a good default choice.
Taking ``n_clusters > 2000`` might lead to an unpowerful inference.
Taking ``n_clusters < 500`` might compress too much the data leading
to a compressed problem not close enough to the original problem.

.. GENERATED FROM PYTHON SOURCE LINES 348-379

.. code-block:: Python


    n_clusters = 1000

    # Setting theoretical FWER target
    fwer_target = 0.1

    # Computing threshold taking into account for Bonferroni correction
    correction_clust_inf = 1.0 / n_clusters
    zscore_threshold = zscore_from_pval((fwer_target / 2) * correction_clust_inf)

    # Initializing FeatureAgglomeration object used for the clustering step
    connectivity_fixed, _ = _fix_connectivity(X.T, connectivity, affinity="euclidean")
    ward = FeatureAgglomeration(n_clusters=n_clusters, connectivity=connectivity)

    # Making the inference with the clustered inference algorithm
    inference_method = "desparsified-group-lasso"
    beta_hat, pval, pval_corr, one_minus_pval, one_minus_pval_corr = clustered_inference(
        X, Y, ward, n_clusters, method=inference_method
    )

    # Extracting active set (support)
    active_set = np.logical_or(
        pval_corr < fwer_target / 2, one_minus_pval_corr < fwer_target / 2
    )
    active_set_full = np.copy(active_set)
    active_set_full[:] = True

    # Translating p-vals into z-scores for nicer visualization
    zscore = zscore_from_pval(pval, one_minus_pval)
    zscore_active_set = zscore[active_set]





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Clustered inference: n_clusters = 1000, inference method = desparsified-group-lasso, seed = 0
    /home/circleci/project/.venv/lib/python3.13/site-packages/sklearn/cluster/_agglomerative.py:321: UserWarning: the number of connected components of the connectivity matrix is 2 > 1. Completing it to avoid stopping the tree early.
      connectivity, n_connected_components = _fix_connectivity(
    Group reid: AR1 cov estimation




.. GENERATED FROM PYTHON SOURCE LINES 380-384

Visualization
-------------
Now, let us plot the thresholded statistical maps derived thanks to the
clustered inference algorithm referred as cd-MTLasso.

.. GENERATED FROM PYTHON SOURCE LINES 384-431

.. code-block:: Python


    # Let's put the solution into the format supported by the plotting functions
    stc = _compute_stc(zscore_active_set, active_set, evoked, forward)

    # Plotting parameters
    if cond == "audio":
        hemi = "lh"
        view = "lat"
    elif cond == "visual":
        hemi = "rh"
        view = "med"
    elif cond == "somato":
        hemi = "rh"
        view = "lat"


    if active_set.sum() != 0:
        max_stc = np.max(np.abs(stc.data))
        clim = dict(pos_lims=(3, zscore_threshold, max_stc), kind="value")
        brain = stc.plot(
            subject=sub,
            hemi=hemi,
            clim=clim,
            subjects_dir=subs_dir,
            views=view,
            time_viewer=False,
            backend="matplotlib" if offscreen else "pyvistaqt",
        )
        if offscreen:
            brain.text(0.05, 0.9, f"{cond} - cd-MTLasso", fontsize=20)
        else:
            brain.add_text(0.05, 0.9, f"{cond} - cd-MTLasso", "title", font_size=20)


    # Hack for nice figures on HiDimStat website
    if save_fig:
        brain.save_image(f"figures/meg_{cond}_cd-MTLasso.png")
    if plot_saved_fig:
        brain.close()
        img = mpimg.imread(f"figures/meg_{cond}_cd-MTLasso.png")
        plt.imshow(img)
        plt.axis("off")
        plt.show()

    if interactive_plot:
        brain = stc.plot(subject=sub, hemi="both", subjects_dir=subs_dir, clim=clim)




.. image-sg:: /generated/gallery/examples/images/sphx_glr_plot_meg_data_example_001.png
   :alt: plot meg data example
   :srcset: /generated/gallery/examples/images/sphx_glr_plot_meg_data_example_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Octahedron subdivision grade 6
        Triangle neighbors and vertex normals...
    Loading geometry from /home/circleci/mne_data/MNE-somato-data/derivatives/freesurfer/subjects/01/surf/rh.sphere...
    Setting up the triangulation for the decimated surface...
    /home/circleci/project/examples/plot_meg_data_example.py:403: RuntimeWarning: 155245/163577 vertices not included in smoothing, consider increasing the number of steps
      brain = stc.plot(
        10 smooth iterations done.




.. GENERATED FROM PYTHON SOURCE LINES 432-436

Comparison with sLORETA
------------------------
Now, we compare the results derived from cd-MTLasso with the solution
obtained from the one of the most standard approach: sLORETA.

.. GENERATED FROM PYTHON SOURCE LINES 436-488

.. code-block:: Python


    # Running sLORETA with standard hyper-parameter
    lambda2 = 1.0 / 9
    inv = make_inverse_operator(
        evoked.info, forward, noise_cov, loose=0.0, depth=0.0, fixed=True
    )
    stc_full = apply_inverse(evoked, inv, lambda2=lambda2, method="sLORETA")
    stc_full = stc_full.mean()

    # Computing threshold taking into account for Bonferroni correction
    n_features = stc_full.data.size
    correction = 1.0 / n_features
    zscore_threshold_no_clust = zscore_from_pval((fwer_target / 2) * correction)

    # Computing estimated support by sLORETA
    active_set = np.abs(stc_full.data) > zscore_threshold_no_clust
    active_set = active_set.flatten()

    # Putting the solution into the format supported by the plotting functions
    sLORETA_solution = np.atleast_2d(stc_full.data[active_set]).flatten()
    stc = _make_sparse_stc(
        sLORETA_solution, active_set, forward, stc_full.tmin, tstep=stc_full.tstep
    )

    # Plotting sLORETA solution
    if active_set.sum() != 0:
        max_stc = np.max(np.abs(stc.data))
        clim = dict(pos_lims=(3, zscore_threshold_no_clust, max_stc), kind="value")
        brain = stc.plot(
            subject=sub,
            hemi=hemi,
            clim=clim,
            subjects_dir=subs_dir,
            views=view,
            time_viewer=False,
            backend="matplotlib" if offscreen else "pyvistaqt",
        )
        if offscreen:
            brain.text(0.05, 0.9, f"{cond} - sLORETA", fontsize=20)
        else:
            brain.add_text(0.05, 0.9, f"{cond} - sLORETA", "title", font_size=20)

        # Hack for nice figures on HiDimStat website
        if save_fig:
            brain.save_image(f"figures/meg_{cond}_sLORETA.png")
        if plot_saved_fig:
            brain.close()
            img = mpimg.imread(f"figures/meg_{cond}_sLORETA.png")
            plt.imshow(img)
            plt.axis("off")
            plt.show()




.. image-sg:: /generated/gallery/examples/images/sphx_glr_plot_meg_data_example_002.png
   :alt: plot meg data example
   :srcset: /generated/gallery/examples/images/sphx_glr_plot_meg_data_example_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Computing inverse operator with 204 channels.
        204 out of 204 channels remain after picking
    Selected 204 channels
    Whitening the forward solution.
    Computing rank from covariance with rank=None
        Using tolerance 2.1e-12 (2.2e-16 eps * 204 dim * 46  max singular value)
        Estimated rank (grad): 64
        GRAD: rank 64 computed from 204 data channels with 0 projectors
        Setting small GRAD eigenvalues to zero (without PCA)
    Creating the source covariance matrix
    Adjusting source covariance matrix.
    Computing SVD of whitened and weighted lead field matrix.
        largest singular value = 2.06293
        scaling factor to adjust the trace = 2.84039e+19 (nchan = 204 nzero = 140)
    Preparing the inverse operator for use...
        Scaled noise and source covariance from nave = 1 to nave = 111
        Created the regularized inverter
        The projection vectors do not apply to these channels.
        Created the whitener using a noise covariance matrix with rank 64 (140 small eigenvalues omitted)
        Computing noise-normalization factors (sLORETA)...
    [done]
    Applying inverse operator to "1"...
        Picked 204 channels from the data
        Computing inverse...
        Eigenleads need to be weighted ...
        Computing residual...
        Explained  95.4% variance
        sLORETA...
    [done]
    Octahedron subdivision grade 6
        Triangle neighbors and vertex normals...
    Loading geometry from /home/circleci/mne_data/MNE-somato-data/derivatives/freesurfer/subjects/01/surf/rh.sphere...
    Setting up the triangulation for the decimated surface...
    /home/circleci/project/examples/plot_meg_data_example.py:464: RuntimeWarning: 139134/163577 vertices not included in smoothing, consider increasing the number of steps
      brain = stc.plot(
        10 smooth iterations done.




.. GENERATED FROM PYTHON SOURCE LINES 489-497

Analysis of the results
-----------------------
While the clustered inference solution always highlights the expected
cortex (audio, visual or somato-sensory) with a universal predertemined
threshold, the solution derived from the sLORETA method does not enjoy
the same property. For the audio task the method is conservative and
for the somato task the method makes false discoveries (then it seems
anti-conservative).

.. GENERATED FROM PYTHON SOURCE LINES 500-507

Running ensemble clustered inference
------------------------------------

To go further it is possible to run the ensemble clustered inference
algorithm. It might take several minutes on standard device with
``n_jobs=1`` (around 10 min). Just set
``run_ensemble_clustered_inference=True`` below.

.. GENERATED FROM PYTHON SOURCE LINES 507-561

.. code-block:: Python

    run_ensemble_clustered_inference = False

    if run_ensemble_clustered_inference:
        # Making the inference with the ensembled clustered inference algorithm
        beta_hat, pval, pval_corr, one_minus_pval, one_minus_pval_corr = (
            ensemble_clustered_inference(
                X, Y, ward, n_clusters, inference_method=inference_method
            )
        )

        # Extracting active set (support)
        active_set = np.logical_or(
            pval_corr < fwer_target / 2, one_minus_pval_corr < fwer_target / 2
        )
        active_set_full = np.copy(active_set)
        active_set_full[:] = True

        # Translating p-vals into z-scores for nicer visualization
        zscore = zscore_from_pval(pval, one_minus_pval)
        zscore_active_set = zscore[active_set]

        # Putting the solution into the format supported by the plotting functions
        stc = _compute_stc(zscore_active_set, active_set, evoked, forward)

        # Plotting ensemble clustered inference solution
        if active_set.sum() != 0:
            max_stc = np.max(np.abs(stc._data))
            clim = dict(pos_lims=(3, zscore_threshold, max_stc), kind="value")
            brain = stc.plot(
                subject=sub,
                hemi=hemi,
                clim=clim,
                subjects_dir=subs_dir,
                views=view,
                time_viewer=False,
                backend="matplotlib" if offscreen else "pyvistaqt",
            )
            if offscreen:
                brain.text(0.05, 0.9, f"{cond} - ecd-MTLasso", fontsize=20)
            else:
                brain.add_text(0.05, 0.9, f"{cond} - ecd-MTLasso", "title", font_size=20)

            # Hack for nice figures on HiDimStat website
            if save_fig:
                brain.save_image(f"figures/meg_{cond}_ecd-MTLasso.png")
            if plot_saved_fig:
                brain.close()
                img = mpimg.imread(f"figures/meg_{cond}_ecd-MTLasso.png")
                plt.imshow(img)
                plt.axis("off")
                plt.show()

            if interactive_plot:
                brain = stc.plot(subject=sub, hemi="both", subjects_dir=subs_dir, clim=clim)








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (2 minutes 35.337 seconds)

**Estimated memory usage:**  482 MB


.. _sphx_glr_download_generated_gallery_examples_plot_meg_data_example.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_meg_data_example.ipynb <plot_meg_data_example.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_meg_data_example.py <plot_meg_data_example.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_meg_data_example.zip <plot_meg_data_example.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
