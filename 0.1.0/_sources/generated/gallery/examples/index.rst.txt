:orphan:

.. _general_examples:

Examples Gallery
================

.. contents:: Contents
   :local:
   :depth: 3



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows the advantages of spatially relaxed inference when dealing with high-dimensional spatial data. To do so, we compare several statistical methods that aim at recovering the support, i.e., predictive features. Among those methods some leverage the spatial structure of the data. For more details about the inference algorithms presented in this example or about the generative process used to simulate the data, please refer to Chevalier et al. (2021) [1]_.">

.. only:: html

  .. image:: /generated/gallery/examples/images/thumb/sphx_glr_plot_2D_simulation_example_thumb.png
    :alt:

  :ref:`sphx_glr_generated_gallery_examples_plot_2D_simulation_example.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Support recovery on simulated data (2D)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example compares several methods that estimate a decoder map support with statistical guarantees. More precisely, we aim at thresholding the weights of some estimated decoder maps according to the confidence we have that they are nonzero. Here, we work with the Haxby dataset and we focus on the &#x27;face vs house&#x27; contrast. Thus, we consider the labeled activation maps of a given subject and try produce a brain map that corresponds to the discriminative pattern that makes the decoding of the two conditions.">

.. only:: html

  .. image:: /generated/gallery/examples/images/thumb/sphx_glr_plot_fmri_data_example_thumb.png
    :alt:

  :ref:`sphx_glr_generated_gallery_examples_plot_fmri_data_example.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Support recovery on fMRI data</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example compares several methods that recover the support in the MEG/EEG source localization problem with statistical guarantees. Here we work with two datasets that study three different tasks (visual, audio, somato).">

.. only:: html

  .. image:: /generated/gallery/examples/images/thumb/sphx_glr_plot_meg_data_example_thumb.png
    :alt:

  :ref:`sphx_glr_generated_gallery_examples_plot_meg_data_example.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Support recovery on MEG data</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /generated/gallery/examples/plot_2D_simulation_example
   /generated/gallery/examples/plot_fmri_data_example
   /generated/gallery/examples/plot_meg_data_example


.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-gallery

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download all examples in Python source code: examples_python.zip </generated/gallery/examples/examples_python.zip>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download all examples in Jupyter notebooks: examples_jupyter.zip </generated/gallery/examples/examples_jupyter.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
