<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title id="head-title">report-3.10-os-ubuntu-latest.html</title>
      <style type="text/css">body {
  font-family: Helvetica, Arial, sans-serif;
  font-size: 12px;
  /* do not increase min-width as some may use split screens */
  min-width: 800px;
  color: #999;
}

h1 {
  font-size: 24px;
  color: black;
}

h2 {
  font-size: 16px;
  color: black;
}

p {
  color: black;
}

a {
  color: #999;
}

table {
  border-collapse: collapse;
}

/******************************
 * SUMMARY INFORMATION
 ******************************/
#environment td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  vertical-align: top;
}
#environment tr:nth-child(odd) {
  background-color: #f6f6f6;
}
#environment ul {
  margin: 0;
  padding: 0 20px;
}

/******************************
 * TEST RESULT COLORS
 ******************************/
span.passed,
.passed .col-result {
  color: green;
}

span.skipped,
span.xfailed,
span.rerun,
.skipped .col-result,
.xfailed .col-result,
.rerun .col-result {
  color: orange;
}

span.error,
span.failed,
span.xpassed,
.error .col-result,
.failed .col-result,
.xpassed .col-result {
  color: red;
}

.col-links__extra {
  margin-right: 3px;
}

/******************************
 * RESULTS TABLE
 *
 * 1. Table Layout
 * 2. Extra
 * 3. Sorting items
 *
 ******************************/
/*------------------
 * 1. Table Layout
 *------------------*/
#results-table {
  border: 1px solid #e6e6e6;
  color: #999;
  font-size: 12px;
  width: 100%;
}
#results-table th,
#results-table td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  text-align: left;
}
#results-table th {
  font-weight: bold;
}

/*------------------
 * 2. Extra
 *------------------*/
.logwrapper {
  max-height: 230px;
  overflow-y: scroll;
  background-color: #e6e6e6;
}
.logwrapper.expanded {
  max-height: none;
}
.logwrapper.expanded .logexpander:after {
  content: "collapse [-]";
}
.logwrapper .logexpander {
  z-index: 1;
  position: sticky;
  top: 10px;
  width: max-content;
  border: 1px solid;
  border-radius: 3px;
  padding: 5px 7px;
  margin: 10px 0 10px calc(100% - 80px);
  cursor: pointer;
  background-color: #e6e6e6;
}
.logwrapper .logexpander:after {
  content: "expand [+]";
}
.logwrapper .logexpander:hover {
  color: #000;
  border-color: #000;
}
.logwrapper .log {
  min-height: 40px;
  position: relative;
  top: -50px;
  height: calc(100% + 50px);
  border: 1px solid #e6e6e6;
  color: black;
  display: block;
  font-family: "Courier New", Courier, monospace;
  padding: 5px;
  padding-right: 80px;
  white-space: pre-wrap;
}

div.media {
  border: 1px solid #e6e6e6;
  float: right;
  height: 240px;
  margin: 0 5px;
  overflow: hidden;
  width: 320px;
}

.media-container {
  display: grid;
  grid-template-columns: 25px auto 25px;
  align-items: center;
  flex: 1 1;
  overflow: hidden;
  height: 200px;
}

.media-container--fullscreen {
  grid-template-columns: 0px auto 0px;
}

.media-container__nav--right,
.media-container__nav--left {
  text-align: center;
  cursor: pointer;
}

.media-container__viewport {
  cursor: pointer;
  text-align: center;
  height: inherit;
}
.media-container__viewport img,
.media-container__viewport video {
  object-fit: cover;
  width: 100%;
  max-height: 100%;
}

.media__name,
.media__counter {
  display: flex;
  flex-direction: row;
  justify-content: space-around;
  flex: 0 0 25px;
  align-items: center;
}

.collapsible td:not(.col-links) {
  cursor: pointer;
}
.collapsible td:not(.col-links):hover::after {
  color: #bbb;
  font-style: italic;
  cursor: pointer;
}

.col-result {
  width: 130px;
}
.col-result:hover::after {
  content: " (hide details)";
}

.col-result.collapsed:hover::after {
  content: " (show details)";
}

#environment-header h2:hover::after {
  content: " (hide details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

#environment-header.collapsed h2:hover::after {
  content: " (show details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

/*------------------
 * 3. Sorting items
 *------------------*/
.sortable {
  cursor: pointer;
}
.sortable.desc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: -12.5px;
  border: 10px solid #4caf50;
  border-bottom: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}
.sortable.asc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: 12.5px;
  border: 10px solid #4caf50;
  border-top: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}

.hidden, .summary__reload__button.hidden {
  display: none;
}

.summary__data {
  flex: 0 0 550px;
}
.summary__reload {
  flex: 1 1;
  display: flex;
  justify-content: center;
}
.summary__reload__button {
  flex: 0 0 300px;
  display: flex;
  color: white;
  font-weight: bold;
  background-color: #4caf50;
  text-align: center;
  justify-content: center;
  align-items: center;
  border-radius: 3px;
  cursor: pointer;
}
.summary__reload__button:hover {
  background-color: #46a049;
}
.summary__spacer {
  flex: 0 0 550px;
}

.controls {
  display: flex;
  justify-content: space-between;
}

.filters,
.collapse {
  display: flex;
  align-items: center;
}
.filters button,
.collapse button {
  color: #999;
  border: none;
  background: none;
  cursor: pointer;
  text-decoration: underline;
}
.filters button:hover,
.collapse button:hover {
  color: #ccc;
}

.filter__label {
  margin-right: 10px;
}

      </style>
    
  </head>
  <body>
    <h1 id="title">report-3.10-os-ubuntu-latest.html</h1>
    <p>Report generated on 03-Feb-2026 at 12:44:42 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.0.0</p>
    <div id="environment-header">
      <h2>Environment</h2>
    </div>
    <table id="environment"></table>
    <!-- TEMPLATES -->
      <template id="template_environment_row">
      <tr>
        <td></td>
        <td></td>
      </tr>
    </template>
    <template id="template_results-table__body--empty">
      <tbody class="results-table-row">
        <tr id="not-found-message">
          <td colspan="4">No results found. Check the filters.</th>
        </tr>
    </template>
    <template id="template_results-table__tbody">
      <tbody class="results-table-row">
        <tr class="collapsible">
        </tr>
        <tr class="extras-row">
          <td class="extra" colspan="4">
            <div class="extraHTML"></div>
            <div class="media">
              <div class="media-container">
                  <div class="media-container__nav--left"><</div>
                  <div class="media-container__viewport">
                    <img src="" />
                    <video controls>
                      <source src="" type="video/mp4">
                    </video>
                  </div>
                  <div class="media-container__nav--right">></div>
                </div>
                <div class="media__name"></div>
                <div class="media__counter"></div>
            </div>
            <div class="logwrapper">
              <div class="logexpander"></div>
              <div class="log"></div>
            </div>
          </td>
        </tr>
      </tbody>
    </template>
    <!-- END TEMPLATES -->
    <div class="summary">
      <div class="summary__data">
        <h2>Summary</h2>
        <div class="additional-summary prefix">
        </div>
        <p class="run-count">367 tests took 00:04:26.</p>
        <p class="filter">(Un)check the boxes to filter the results.</p>
        <div class="summary__reload">
          <div class="summary__reload__button hidden" onclick="location.reload()">
            <div>There are still tests running. <br />Reload this page to ge the latest results!</div>
          </div>
        </div>
        <div class="summary__spacer"></div>
        <div class="controls">
          <div class="filters">
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="failed" disabled/>
            <span class="failed">0 Failed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="passed" />
            <span class="passed">320 Passed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="skipped" disabled/>
            <span class="skipped">0 Skipped,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xfailed" />
            <span class="xfailed">47 Unexpected failures,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xpassed" disabled/>
            <span class="xpassed">0 Unexpected passes,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="error" disabled/>
            <span class="error">0 Errors,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="rerun" disabled/>
            <span class="rerun">0 Reruns</span>
          </div>
          <div class="collapse">
            <button id="show_all_details">Show all details</button>&nbsp;/&nbsp;<button id="hide_all_details">Hide all details</button>
          </div>
        </div>
      </div>
      <div class="additional-summary summary">
      </div>
      <div class="additional-summary postfix">
      </div>
    </div>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable" data-column-type="result">Result</th>
          <th class="sortable" data-column-type="testId">Test</th>
          <th class="sortable" data-column-type="duration">Duration</th>
          <th>Links</th>
        </tr>
      </thead>
    </table>
  </body>
  <footer>
    <div id="data-container" data-jsonblob="{&#34;environment&#34;: {&#34;Python&#34;: &#34;3.10.19&#34;, &#34;Platform&#34;: &#34;Linux-6.11.0-1018-azure-x86_64-with-glibc2.39&#34;, &#34;Packages&#34;: {&#34;pytest&#34;: &#34;8.0.0&#34;, &#34;pluggy&#34;: &#34;1.6.0&#34;}, &#34;Plugins&#34;: {&#34;env&#34;: &#34;1.0.0&#34;, &#34;xdist&#34;: &#34;3.4.0&#34;, &#34;randomly&#34;: &#34;3.3.0&#34;, &#34;cov&#34;: &#34;5.0.0&#34;, &#34;timeout&#34;: &#34;2.3.1&#34;, &#34;reportlog&#34;: &#34;0.2.1&#34;, &#34;mpl&#34;: &#34;0.14.0&#34;, &#34;html&#34;: &#34;4.0.0&#34;, &#34;metadata&#34;: &#34;3.1.1&#34;, &#34;durations&#34;: &#34;1.0.0&#34;}, &#34;CI&#34;: &#34;true&#34;, &#34;JAVA_HOME&#34;: &#34;/usr/lib/jvm/temurin-17-jdk-amd64&#34;}, &#34;tests&#34;: {&#34;test/_utils/test_scenario.py::test_multivariate_simulation_reproducibility&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_reproducibility&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_reproducibility&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_support_size&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_support_size&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_ar_support_size&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_minimal&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_minimal&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_minimal&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[no roi]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[no roi]&#34;, &#34;duration&#34;: &#34;9 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_2D[no roi]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;9 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_samples&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_samples&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_samples&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_zero_support&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_zero_support&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_zero_support&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_snr&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_snr&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_ar_snr&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_weights_2D&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_weights_2D&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_weights_2D&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_correlation]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_correlation]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_correlation]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_features&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_features&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_features&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_function_d0crt&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_function_d0crt&#34;, &#34;duration&#34;: &#34;71 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_function_d0crt&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;71 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[no_correlation]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[no_correlation]&#34;, &#34;duration&#34;: &#34;96 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_all[no_correlation]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;96 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_zero_signal_noise_ratio&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_zero_signal_noise_ratio&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_zero_signal_noise_ratio&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_empirical_snr_2&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_empirical_snr_2&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_empirical_snr_2&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_invalid&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_invalid&#34;, &#34;duration&#34;: &#34;31 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_invalid&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;31 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_3D&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_3D&#34;, &#34;duration&#34;: &#34;23 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_3D&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;23 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[only noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[only noise]&#34;, &#34;duration&#34;: &#34;11 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_2D[only noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;11 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_with_shuffle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_with_shuffle]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_with_shuffle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[no_correlation_with_shuffle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[no_correlation_with_shuffle]&#34;, &#34;duration&#34;: &#34;77 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_all[no_correlation_with_shuffle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;77 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[basic case]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[basic case]&#34;, &#34;duration&#34;: &#34;21 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_2D[basic case]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;21 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_2D&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_2D&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_2D&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_empirical_snr&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_empirical_snr&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_empirical_snr&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_target&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_target&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_target&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_rho_noise&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_rho_noise&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_ar_rho_noise&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[basic_correlation]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[basic_correlation]&#34;, &#34;duration&#34;: &#34;135 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_all[basic_correlation]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;135 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[no noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[no noise]&#34;, &#34;duration&#34;: &#34;10 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_2D[no noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;10 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_3D&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_3D&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_3D&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_rho&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_rho&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_ar_rho&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_weights_3D&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_weights_3D&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_weights_3D&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_no_shuffle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_no_shuffle]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_no_shuffle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_roi_full&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_roi_full&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_roi_full&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator17-check17-check_get_params_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator17-check17-check_get_params_invariance]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator17-check17-check_get_params_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_repeatability&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_repeatability&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_d0crt_repeatability&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_distillation_x_different&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_distillation_x_different&#34;, &#34;duration&#34;: &#34;49 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_distillation_x_different&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;49 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_estimed_coefficient&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_estimed_coefficient&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_estimed_coefficient&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_distillation_y_different&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_distillation_y_different&#34;, &#34;duration&#34;: &#34;34 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_distillation_y_different&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;34 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit&#34;, &#34;duration&#34;: &#34;124 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;124 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit_errors&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit_errors&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit_errors&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_no_cv&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_no_cv&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_no_cv&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator3-check3-check_estimators_fit_returns_self]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator3-check3-check_estimators_fit_returns_self]&#34;, &#34;duration&#34;: &#34;230 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator3-check3-check_estimators_fit_returns_self]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;230 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_screening&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_screening&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_screening&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator0-check0-check_estimators_dtypes]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator0-check0-check_estimators_dtypes]&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator0-check0-check_estimators_dtypes]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator10-check10-check_estimator_sparse_matrix]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator10-check10-check_estimator_sparse_matrix]&#34;, &#34;duration&#34;: &#34;22 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator10-check10-check_estimator_sparse_matrix]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;22 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_invalid_lasso_screening&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_invalid_lasso_screening&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_invalid_lasso_screening&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_reproducibility_with_integer&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_reproducibility_with_integer&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_d0crt_reproducibility_with_integer&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator19-check19-check_dict_unchanged]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator19-check19-check_dict_unchanged]&#34;, &#34;duration&#34;: &#34;309 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator19-check19-check_dict_unchanged]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;309 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator14-check14-check_methods_sample_order_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator14-check14-check_methods_sample_order_invariance]&#34;, &#34;duration&#34;: &#34;304 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator14-check14-check_methods_sample_order_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;304 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator16-check16-check_fit2d_1sample]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator16-check16-check_fit2d_1sample]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator16-check16-check_fit2d_1sample]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_warning_not_used_parameters&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_warning_not_used_parameters&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_warning_not_used_parameters&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator2-check2-check_estimators_fit_returns_self]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator2-check2-check_estimators_fit_returns_self]&#34;, &#34;duration&#34;: &#34;237 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator2-check2-check_estimators_fit_returns_self]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;237 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator4-check4-check_complex_data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator4-check4-check_complex_data]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator4-check4-check_complex_data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_exception_not_fitted&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_exception_not_fitted&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_exception_not_fitted&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator13-check13-check_estimator_get_tags_default_keys]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator13-check13-check_estimator_get_tags_default_keys]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator13-check13-check_estimator_get_tags_default_keys]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_randomness_with_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_randomness_with_none&#34;, &#34;duration&#34;: &#34;00:00:05&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_d0crt_randomness_with_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:05&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_refit&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_refit&#34;, &#34;duration&#34;: &#34;164 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_refit&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;164 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator23-check23-check_fit2d_predict1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator23-check23-check_fit2d_predict1d]&#34;, &#34;duration&#34;: &#34;311 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator23-check23-check_fit2d_predict1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;311 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_rf&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_rf&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_d0crt_rf&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator2-check2-check_parameters_default_constructible]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator2-check2-check_parameters_default_constructible]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator2-check2-check_parameters_default_constructible]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ncheck = functools.partial(&amp;lt;function check_parameters_default_constructible at 0x7f4ffd4db010&amp;gt;, &#39;D0CRT&#39;)\nname = &#39;check_parameters_default_constructible&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_parameters_default_constructible at 0x7f4ffd4db010&amp;gt;, &#39;D0CRT&#39;)\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nname       = &#39;check_parameters_default_constructible&#39;\n\ntest/test_distilled_conditional_randomization_test.py:63: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3438: in check_parameters_default_constructible\n    estimator = _construct_instance(Estimator)\n        Estimator  = &amp;lt;class &#39;hidimstat.distilled_conditional_randomization_test.D0CRT&#39;&amp;gt;\n        name       = &#39;D0CRT&#39;\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nEstimator = &amp;lt;class &#39;hidimstat.distilled_conditional_randomization_test.D0CRT&#39;&amp;gt;\n\n    def _construct_instance(Estimator):\n        \&#34;\&#34;\&#34;Construct Estimator instance if possible.\&#34;\&#34;\&#34;\n        required_parameters = getattr(Estimator, \&#34;_required_parameters\&#34;, [])\n        if len(required_parameters):\n            if required_parameters in ([\&#34;estimator\&#34;], [\&#34;base_estimator\&#34;]):\n                # `RANSACRegressor` will raise an error with any model other\n                # than `LinearRegression` if we don&#39;t fix `min_samples` parameter.\n                # For common test, we can enforce using `LinearRegression` that\n                # is the default estimator in `RANSACRegressor` instead of `Ridge`.\n                if issubclass(Estimator, RANSACRegressor):\n                    estimator = Estimator(LinearRegression())\n                elif issubclass(Estimator, RegressorMixin):\n                    estimator = Estimator(Ridge())\n                elif issubclass(Estimator, SelectFromModel):\n                    # Increases coverage because SGDRegressor has partial_fit\n                    estimator = Estimator(SGDRegressor(random_state=0))\n                else:\n                    estimator = Estimator(LogisticRegression(C=1))\n            elif required_parameters in ([\&#34;estimators\&#34;],):\n                # Heterogeneous ensemble classes (i.e. stacking, voting)\n                if issubclass(Estimator, RegressorMixin):\n                    estimator = Estimator(\n                        estimators=[\n                            (\&#34;est1\&#34;, DecisionTreeRegressor(max_depth=3, random_state=0)),\n                            (\&#34;est2\&#34;, DecisionTreeRegressor(max_depth=3, random_state=1)),\n                        ]\n                    )\n                else:\n                    estimator = Estimator(\n                        estimators=[\n                            (\&#34;est1\&#34;, DecisionTreeClassifier(max_depth=3, random_state=0)),\n                            (\&#34;est2\&#34;, DecisionTreeClassifier(max_depth=3, random_state=1)),\n                        ]\n                    )\n            else:\n                msg = (\n                    f\&#34;Can&#39;t instantiate estimator {Estimator.__name__} \&#34;\n                    f\&#34;parameters {required_parameters}\&#34;\n                )\n                # raise additional warning to be shown by pytest\n                warnings.warn(msg, SkipTestWarning)\n                raise SkipTest(msg)\n        else:\n&amp;gt;           estimator = Estimator()\nE           TypeError: D0CRT.__init__() missing 1 required positional argument: &#39;estimator&#39;\n\nEstimator  = &amp;lt;class &#39;hidimstat.distilled_conditional_randomization_test.D0CRT&#39;&amp;gt;\nrequired_parameters = []\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:463: TypeError\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator5-check5-check_n_features_in]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator5-check5-check_n_features_in]&#34;, &#34;duration&#34;: &#34;231 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator5-check5-check_n_features_in]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;231 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ncheck = functools.partial(&amp;lt;function check_n_features_in at 0x7ff219febac0&amp;gt;, &#39;D0CRT&#39;)\nname = &#39;check_n_features_in&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_n_features_in at 0x7ff219febac0&amp;gt;, &#39;D0CRT&#39;)\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nname       = &#39;check_n_features_in&#39;\n\ntest/test_distilled_conditional_randomization_test.py:63: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;D0CRT&#39;\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\n    def check_n_features_in(name, estimator_orig):\n        # Make sure that n_features_in_ attribute doesn&#39;t exist until fit is\n        # called, and that its value is correct.\n    \n        rng = np.random.RandomState(0)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if \&#34;warm_start\&#34; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        assert not hasattr(estimator, \&#34;n_features_in_\&#34;)\n        estimator.fit(X, y)\n&amp;gt;       assert hasattr(estimator, \&#34;n_features_in_\&#34;)\nE       AssertionError\n\nX          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7FF214A3B040),\n      la...ate(PCG64) at 0x7FF214A3B340,\n                              tol=1e-06),\n      random_state=0, screening_threshold=None)\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nn_samples  = 100\nname       = &#39;D0CRT&#39;\nrng        = RandomState(MT19937) at 0x7FF214A3AB40\ny          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3951: AssertionError\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator22-check22-check_fit1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator22-check22-check_fit1d]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator22-check22-check_fit1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator21-check21-check_fit_idempotent]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator21-check21-check_fit_idempotent]&#34;, &#34;duration&#34;: &#34;937 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator21-check21-check_fit_idempotent]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;937 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator18-check18-check_set_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator18-check18-check_set_params]&#34;, &#34;duration&#34;: &#34;46 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator18-check18-check_set_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;46 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_leave_one_covariate_out.py::test_loco&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_leave_one_covariate_out.py::test_loco&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_leave_one_covariate_out.py::test_loco&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_none&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_threshols_value&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_threshols_value&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_threshols_value&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_all&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_all&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_all&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_best&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_best&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_k_best&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_percentile&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_threshold_max&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_threshold_max&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_threshold_max&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_threshold_min&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_threshold_min&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_threshold_min&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_lowest&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_lowest&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_k_lowest&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_best_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_best_none&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_k_best_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_lowest_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_lowest_none&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_k_lowest_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_threshold&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_threshold&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_threshold&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_k_lowest&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_k_lowest&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_k_lowest&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::test_selection_fdr&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::test_selection_fdr&#34;, &#34;duration&#34;: &#34;42 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::test_selection_fdr&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;42 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_percentile&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_percentile&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_percentile&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_k_best&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_k_best&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_k_best&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_not_fit&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_not_fit&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestBVIExceptions::test_not_fit&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_pvalue_None&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_pvalue_None&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_pvalue_None&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::test_selection_bhq&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::test_selection_bhq&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::test_selection_bhq&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::test_fwer_selection&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::test_fwer_selection&#34;, &#34;duration&#34;: &#34;9 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::test_fwer_selection&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;9 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator8-check8-check_estimators_nan_inf]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator8-check8-check_estimators_nan_inf]&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator8-check8-check_estimators_nan_inf]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::test_plot_importance_ascending&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::test_plot_importance_ascending&#34;, &#34;duration&#34;: &#34;211 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::test_plot_importance_ascending&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;211 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::test_plot_importance_axis&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::test_plot_importance_axis&#34;, &#34;duration&#34;: &#34;281 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::test_plot_importance_axis&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;281 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::test_clustered_fwer_selection&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::test_clustered_fwer_selection&#34;, &#34;duration&#34;: &#34;79 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::test_clustered_fwer_selection&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;79 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nUsing number of clusters for multiple testing correction.\n&#34;}], &#34;test/test_base_variable_importance.py::test_plot_importance_feature_names&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::test_plot_importance_feature_names&#34;, &#34;duration&#34;: &#34;158 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::test_plot_importance_feature_names&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;158 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_fdr_control&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_fdr_control&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_fdr_control&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_wrong_fdr&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_wrong_fdr&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_wrong_fdr&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_not_fit&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_not_fit&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_not_fit&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_pvalue_None&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_pvalue_None&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_pvalue_None&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_regression.py::test_alpha_max&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_regression.py::test_alpha_max&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_regression.py::test_alpha_max&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_permutation_feature_importance.py::test_pfi_reproducibility_with_rng&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_permutation_feature_importance.py::test_pfi_reproducibility_with_rng&#34;, &#34;duration&#34;: &#34;148 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_permutation_feature_importance.py::test_pfi_reproducibility_with_rng&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;148 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_permutation_feature_importance.py::test_pfi_reproducibility_with_integer&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_permutation_feature_importance.py::test_pfi_reproducibility_with_integer&#34;, &#34;duration&#34;: &#34;76 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_permutation_feature_importance.py::test_pfi_reproducibility_with_integer&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;76 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_RF_regression&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_RF_regression&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_RF_regression&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_linear&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_linear&#34;, &#34;duration&#34;: &#34;320 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_d0crt_linear&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;320 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_refit&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_refit&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_refit&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit_refit&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit_refit&#34;, &#34;duration&#34;: &#34;162 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit_refit&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;162 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator20-check20-check_dont_overwrite_parameters]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator20-check20-check_dont_overwrite_parameters]&#34;, &#34;duration&#34;: &#34;309 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator20-check20-check_dont_overwrite_parameters]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;309 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator9-check9-check_estimator_sparse_array]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator9-check9-check_estimator_sparse_array]&#34;, &#34;duration&#34;: &#34;19 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator9-check9-check_estimator_sparse_array]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;19 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator3-check3-check_fit2d_1feature]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator3-check3-check_fit2d_1feature]&#34;, &#34;duration&#34;: &#34;69 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator3-check3-check_fit2d_1feature]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;69 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &#39;D0CRT&#39;\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\n    @ignore_warnings\n    def check_fit2d_1feature(name, estimator_orig):\n        # check fitting a 2d array with only 1 feature either works or returns\n        # informative message\n        rnd = np.random.RandomState(0)\n        X = 3 * rnd.uniform(size=(10, 1))\n        X = _enforce_estimator_tags_X(estimator_orig, X)\n        y = X[:, 0].astype(int)\n        estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if hasattr(estimator, \&#34;n_components\&#34;):\n            estimator.n_components = 1\n        if hasattr(estimator, \&#34;n_clusters\&#34;):\n            estimator.n_clusters = 1\n        # ensure two labels in subsample for RandomizedLogisticRegression\n        if name == \&#34;RandomizedLogisticRegression\&#34;:\n            estimator.sample_fraction = 1\n        # ensure non skipped trials for RANSACRegressor\n        if name == \&#34;RANSACRegressor\&#34;:\n            estimator.residual_threshold = 0.5\n    \n        y = _enforce_estimator_tags_y(estimator, y)\n        set_random_state(estimator, 1)\n    \n        msgs = [r\&#34;1 feature\\(s\\)\&#34;, \&#34;n_features = 1\&#34;, \&#34;n_features=1\&#34;]\n    \n        with raises(ValueError, match=msgs, may_pass=True):\n&amp;gt;           estimator.fit(X, y)\n\nX          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7F4FF3D92340),\n      la...ate(PCG64) at 0x7F4FF3D91240,\n                              tol=1e-06),\n      random_state=1, screening_threshold=None)\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nmsgs       = [&#39;1 feature\\\\(s\\\\)&#39;, &#39;n_features = 1&#39;, &#39;n_features=1&#39;]\nname       = &#39;D0CRT&#39;\nrnd        = RandomState(MT19937) at 0x7F4FFDFD9440\ny          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1673: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/distilled_conditional_randomization_test.py:280: in fit\n    results = Parallel(self.n_jobs, verbose=self.joblib_verbose)(\n        X          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\n        X_         = array([[-0.36293708],\n       [ 0.53895184],\n       [-0.07048605],\n       [-0.38424253],\n       [-1.04139636],\n       [ 0.16331669],\n       [-0.96587166],\n       [ 1.49617496],\n       [ 1.88587438],\n       [-1.25938418]])\n        rng        = Generator(PCG64) at 0x7F4FF98C1380\n        self       = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7F4FF3D92340),\n      la...ate(PCG64) at 0x7F4FF3D91240,\n                              tol=1e-06),\n      random_state=1, screening_threshold=None)\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n        y_         = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object D0CRT.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff9887920&amp;gt;\n        iterator   = &amp;lt;generator object D0CRT.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff9887920&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;function _joblib_fit at 0x7f4ffb096f80&amp;gt;, (), {&#39;X&#39;: array([[-0.36293708],\n       [ 0.53895184],\n       [-0.07048605]...]]), &#39;estimator&#39;: LassoCV(n_jobs=1, random_state=RandomState(PCG64) at 0x7F4FF3D92340), &#39;fit_y&#39;: True, &#39;idx&#39;: 0, ...})]\n        iterator   = &amp;lt;generator object D0CRT.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff9887920&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3b41180&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3b41180&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff3b429b0&amp;gt;\n        dispatch_timestamp = 1770122548.576843\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff3b429b0&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3b41180&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff3b41ea0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3b41180&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff3b42c80&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3b41180&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff3b41c00&amp;gt;\n        args       = ()\n        func       = &amp;lt;function _joblib_fit at 0x7f4ffb096f80&amp;gt;\n        kwargs     = {&#39;X&#39;: array([[-0.36293708],\n       [ 0.53895184],\n       [-0.07048605],\n       [-0.38424253],\n       [-1.04139636],\n  ...18]]), &#39;estimator&#39;: LassoCV(n_jobs=1, random_state=RandomState(PCG64) at 0x7F4FF3D92340), &#39;fit_y&#39;: True, &#39;idx&#39;: 0, ...}\nsrc/hidimstat/distilled_conditional_randomization_test.py:658: in _joblib_fit\n    model_x.fit(X_minus_idx, X[:, idx], sample_weight=sample_weight)\n        X          = array([[-0.36293708],\n       [ 0.53895184],\n       [-0.07048605],\n       [-0.38424253],\n       [-1.04139636],\n       [ 0.16331669],\n       [-0.96587166],\n       [ 1.49617496],\n       [ 1.88587438],\n       [-1.25938418]])\n        X_minus_idx = array([], shape=(10, 0), dtype=float64)\n        estimator  = LassoCV(n_jobs=1, random_state=RandomState(PCG64) at 0x7F4FF3D92340)\n        fit_y      = True\n        idx        = 0\n        lasso_weights = None\n        model_distillation_x = LassoCV(n_alphas=10)\n        model_x    = LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4FF3D91A40)\n        random_state = Generator(PCG64) at 0x7F4FF98C12A0\n        sample_weight = None\n        sigma_X    = True\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n.venv/lib/python3.10/site-packages/sklearn/base.py:1473: in wrapper\n    return fit_method(estimator, *args, **kwargs)\n        args       = (array([], shape=(10, 0), dtype=float64), array([-0.36293708,  0.53895184, -0.07048605, -0.38424253, -1.04139636,\n        0.16331669, -0.96587166,  1.49617496,  1.88587438, -1.25938418]))\n        estimator  = LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4FF3D91A40)\n        fit_method = &amp;lt;function LinearModelCV.fit at 0x7f4ffdc5c1f0&amp;gt;\n        global_skip_validation = False\n        kwargs     = {&#39;sample_weight&#39;: None}\n        partial_fit_and_fitted = False\n        prefer_skip_nested_validation = True\n.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:1617: in fit\n    X, y = self._validate_data(\n        X          = array([], shape=(10, 0), dtype=float64)\n        check_X_params = {&#39;accept_large_sparse&#39;: False, &#39;accept_sparse&#39;: &#39;csc&#39;, &#39;copy&#39;: False, &#39;dtype&#39;: [&amp;lt;class &#39;numpy.float64&#39;&amp;gt;, &amp;lt;class &#39;numpy.float32&#39;&amp;gt;]}\n        check_y_params = {&#39;copy&#39;: False, &#39;dtype&#39;: [&amp;lt;class &#39;numpy.float64&#39;&amp;gt;, &amp;lt;class &#39;numpy.float32&#39;&amp;gt;], &#39;ensure_2d&#39;: False}\n        copy_X     = True\n        params     = {}\n        reference_to_old_X = array([], shape=(10, 0), dtype=float64)\n        sample_weight = None\n        self       = LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4FF3D91A40)\n        y          = array([-0.36293708,  0.53895184, -0.07048605, -0.38424253, -1.04139636,\n        0.16331669, -0.96587166,  1.49617496,  1.88587438, -1.25938418])\n.venv/lib/python3.10/site-packages/sklearn/base.py:645: in _validate_data\n    X = check_array(X, input_name=\&#34;X\&#34;, **check_X_params)\n        X          = array([], shape=(10, 0), dtype=float64)\n        cast_to_ndarray = True\n        check_X_params = {&#39;accept_large_sparse&#39;: False, &#39;accept_sparse&#39;: &#39;csc&#39;, &#39;copy&#39;: False, &#39;dtype&#39;: [&amp;lt;class &#39;numpy.float64&#39;&amp;gt;, &amp;lt;class &#39;numpy.float32&#39;&amp;gt;], ...}\n        check_params = {&#39;estimator&#39;: LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4FF3D91A40)}\n        check_y_params = {&#39;copy&#39;: False, &#39;dtype&#39;: [&amp;lt;class &#39;numpy.float64&#39;&amp;gt;, &amp;lt;class &#39;numpy.float32&#39;&amp;gt;], &#39;ensure_2d&#39;: False}\n        default_check_params = {&#39;estimator&#39;: LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4FF3D91A40)}\n        no_val_X   = False\n        no_val_y   = False\n        reset      = True\n        self       = LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4FF3D91A40)\n        validate_separately = ({&#39;accept_large_sparse&#39;: False, &#39;accept_sparse&#39;: &#39;csc&#39;, &#39;copy&#39;: False, &#39;dtype&#39;: [&amp;lt;class &#39;numpy.float64&#39;&amp;gt;, &amp;lt;class &#39;numpy.float32&#39;&amp;gt;]}, {&#39;copy&#39;: False, &#39;dtype&#39;: [&amp;lt;class &#39;numpy.float64&#39;&amp;gt;, &amp;lt;class &#39;numpy.float32&#39;&amp;gt;], &#39;ensure_2d&#39;: False})\n        y          = array([-0.36293708,  0.53895184, -0.07048605, -0.38424253, -1.04139636,\n        0.16331669, -0.96587166,  1.49617496,  1.88587438, -1.25938418])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\narray = array([], shape=(10, 0), dtype=float64), accept_sparse = &#39;csc&#39;\n\n    def check_array(\n        array,\n        accept_sparse=False,\n        *,\n        accept_large_sparse=True,\n        dtype=\&#34;numeric\&#34;,\n        order=None,\n        copy=False,\n        force_all_finite=True,\n        ensure_2d=True,\n        allow_nd=False,\n        ensure_min_samples=1,\n        ensure_min_features=1,\n        estimator=None,\n        input_name=\&#34;\&#34;,\n    ):\n        \&#34;\&#34;\&#34;Input validation on an array, list, sparse matrix or similar.\n    \n        By default, the input is checked to be a non-empty 2D array containing\n        only finite values. If the dtype of the array is object, attempt\n        converting to float, raising on failure.\n    \n        Parameters\n        ----------\n        array : object\n            Input object to check / convert.\n    \n        accept_sparse : str, bool or list/tuple of str, default=False\n            String[s] representing allowed sparse matrix formats, such as &#39;csc&#39;,\n            &#39;csr&#39;, etc. If the input is sparse but not in the allowed format,\n            it will be converted to the first listed format. True allows the input\n            to be any format. False means that a sparse matrix input will\n            raise an error.\n    \n        accept_large_sparse : bool, default=True\n            If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\n            accept_sparse, accept_large_sparse=False will cause it to be accepted\n            only if its indices are stored with a 32-bit dtype.\n    \n            .. versionadded:: 0.20\n    \n        dtype : &#39;numeric&#39;, type, list of type or None, default=&#39;numeric&#39;\n            Data type of result. If None, the dtype of the input is preserved.\n            If \&#34;numeric\&#34;, dtype is preserved unless array.dtype is object.\n            If dtype is a list of types, conversion on the first type is only\n            performed if the dtype of the input is not in the list.\n    \n        order : {&#39;F&#39;, &#39;C&#39;} or None, default=None\n            Whether an array will be forced to be fortran or c-style.\n            When order is None (default), then if copy=False, nothing is ensured\n            about the memory layout of the output array; otherwise (copy=True)\n            the memory layout of the returned array is kept as close as possible\n            to the original array.\n    \n        copy : bool, default=False\n            Whether a forced copy will be triggered. If copy=False, a copy might\n            be triggered by a conversion.\n    \n        force_all_finite : bool or &#39;allow-nan&#39;, default=True\n            Whether to raise an error on np.inf, np.nan, pd.NA in array. The\n            possibilities are:\n    \n            - True: Force all values of array to be finite.\n            - False: accepts np.inf, np.nan, pd.NA in array.\n            - &#39;allow-nan&#39;: accepts only np.nan and pd.NA values in array. Values\n              cannot be infinite.\n    \n            .. versionadded:: 0.20\n               ``force_all_finite`` accepts the string ``&#39;allow-nan&#39;``.\n    \n            .. versionchanged:: 0.23\n               Accepts `pd.NA` and converts it into `np.nan`\n    \n        ensure_2d : bool, default=True\n            Whether to raise a value error if array is not 2D.\n    \n        allow_nd : bool, default=False\n            Whether to allow array.ndim &amp;gt; 2.\n    \n        ensure_min_samples : int, default=1\n            Make sure that the array has a minimum number of samples in its first\n            axis (rows for a 2D array). Setting to 0 disables this check.\n    \n        ensure_min_features : int, default=1\n            Make sure that the 2D array has some minimum number of features\n            (columns). The default value of 1 rejects empty datasets.\n            This check is only enforced when the input data has effectively 2\n            dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0\n            disables this check.\n    \n        estimator : str or estimator instance, default=None\n            If passed, include the name of the estimator in warning messages.\n    \n        input_name : str, default=\&#34;\&#34;\n            The data name used to construct the error message. In particular\n            if `input_name` is \&#34;X\&#34; and the data has NaN values and\n            allow_nan is False, the error message will link to the imputer\n            documentation.\n    \n            .. versionadded:: 1.1.0\n    \n        Returns\n        -------\n        array_converted : object\n            The converted and validated array.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_array\n        &amp;gt;&amp;gt;&amp;gt; X = [[1, 2, 3], [4, 5, 6]]\n        &amp;gt;&amp;gt;&amp;gt; X_checked = check_array(X)\n        &amp;gt;&amp;gt;&amp;gt; X_checked\n        array([[1, 2, 3], [4, 5, 6]])\n        \&#34;\&#34;\&#34;\n        if isinstance(array, np.matrix):\n            raise TypeError(\n                \&#34;np.matrix is not supported. Please convert to a numpy array with \&#34;\n                \&#34;np.asarray. For more information see: \&#34;\n                \&#34;https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\&#34;\n            )\n    \n        xp, is_array_api_compliant = get_namespace(array)\n    \n        # store reference to original array to check if copy is needed when\n        # function returns\n        array_orig = array\n    \n        # store whether originally we wanted numeric dtype\n        dtype_numeric = isinstance(dtype, str) and dtype == \&#34;numeric\&#34;\n    \n        dtype_orig = getattr(array, \&#34;dtype\&#34;, None)\n        if not is_array_api_compliant and not hasattr(dtype_orig, \&#34;kind\&#34;):\n            # not a data type (e.g. a column named dtype in a pandas DataFrame)\n            dtype_orig = None\n    \n        # check if the object contains several dtypes (typically a pandas\n        # DataFrame), and store them. If not, store None.\n        dtypes_orig = None\n        pandas_requires_conversion = False\n        # track if we have a Series-like object to raise a better error message\n        type_if_series = None\n        if hasattr(array, \&#34;dtypes\&#34;) and hasattr(array.dtypes, \&#34;__array__\&#34;):\n            # throw warning if columns are sparse. If all columns are sparse, then\n            # array.sparse exists and sparsity will be preserved (later).\n            with suppress(ImportError):\n                from pandas import SparseDtype\n    \n                def is_sparse(dtype):\n                    return isinstance(dtype, SparseDtype)\n    \n                if not hasattr(array, \&#34;sparse\&#34;) and array.dtypes.apply(is_sparse).any():\n                    warnings.warn(\n                        \&#34;pandas.DataFrame with sparse columns found.\&#34;\n                        \&#34;It will be converted to a dense numpy array.\&#34;\n                    )\n    \n            dtypes_orig = list(array.dtypes)\n            pandas_requires_conversion = any(\n                _pandas_dtype_needs_early_conversion(i) for i in dtypes_orig\n            )\n            if all(isinstance(dtype_iter, np.dtype) for dtype_iter in dtypes_orig):\n                dtype_orig = np.result_type(*dtypes_orig)\n            elif pandas_requires_conversion and any(d == object for d in dtypes_orig):\n                # Force object if any of the dtypes is an object\n                dtype_orig = object\n    \n        elif (_is_extension_array_dtype(array) or hasattr(array, \&#34;iloc\&#34;)) and hasattr(\n            array, \&#34;dtype\&#34;\n        ):\n            # array is a pandas series\n            type_if_series = type(array)\n            pandas_requires_conversion = _pandas_dtype_needs_early_conversion(array.dtype)\n            if isinstance(array.dtype, np.dtype):\n                dtype_orig = array.dtype\n            else:\n                # Set to None to let array.astype work out the best dtype\n                dtype_orig = None\n    \n        if dtype_numeric:\n            if (\n                dtype_orig is not None\n                and hasattr(dtype_orig, \&#34;kind\&#34;)\n                and dtype_orig.kind == \&#34;O\&#34;\n            ):\n                # if input is object, convert to float.\n                dtype = xp.float64\n            else:\n                dtype = None\n    \n        if isinstance(dtype, (list, tuple)):\n            if dtype_orig is not None and dtype_orig in dtype:\n                # no dtype conversion required\n                dtype = None\n            else:\n                # dtype conversion required. Let&#39;s select the first element of the\n                # list of accepted types.\n                dtype = dtype[0]\n    \n        if pandas_requires_conversion:\n            # pandas dataframe requires conversion earlier to handle extension dtypes with\n            # nans\n            # Use the original dtype for conversion if dtype is None\n            new_dtype = dtype_orig if dtype is None else dtype\n            array = array.astype(new_dtype)\n            # Since we converted here, we do not need to convert again later\n            dtype = None\n    \n        if force_all_finite not in (True, False, \&#34;allow-nan\&#34;):\n            raise ValueError(\n                &#39;force_all_finite should be a bool or \&#34;allow-nan\&#34;. Got {!r} instead&#39;.format(\n                    force_all_finite\n                )\n            )\n    \n        if dtype is not None and _is_numpy_namespace(xp):\n            # convert to dtype object to conform to Array API to be use `xp.isdtype` later\n            dtype = np.dtype(dtype)\n    \n        estimator_name = _check_estimator_name(estimator)\n        context = \&#34; by %s\&#34; % estimator_name if estimator is not None else \&#34;\&#34;\n    \n        # When all dataframe columns are sparse, convert to a sparse array\n        if hasattr(array, \&#34;sparse\&#34;) and array.ndim &amp;gt; 1:\n            with suppress(ImportError):\n                from pandas import SparseDtype  # noqa: F811\n    \n                def is_sparse(dtype):\n                    return isinstance(dtype, SparseDtype)\n    \n                if array.dtypes.apply(is_sparse).all():\n                    # DataFrame.sparse only supports `to_coo`\n                    array = array.sparse.to_coo()\n                    if array.dtype == np.dtype(\&#34;object\&#34;):\n                        unique_dtypes = set([dt.subtype.name for dt in array_orig.dtypes])\n                        if len(unique_dtypes) &amp;gt; 1:\n                            raise ValueError(\n                                \&#34;Pandas DataFrame with mixed sparse extension arrays \&#34;\n                                \&#34;generated a sparse matrix with object dtype which \&#34;\n                                \&#34;can not be converted to a scipy sparse matrix.\&#34;\n                                \&#34;Sparse extension arrays should all have the same \&#34;\n                                \&#34;numeric type.\&#34;\n                            )\n    \n        if sp.issparse(array):\n            _ensure_no_complex_data(array)\n            array = _ensure_sparse_format(\n                array,\n                accept_sparse=accept_sparse,\n                dtype=dtype,\n                copy=copy,\n                force_all_finite=force_all_finite,\n                accept_large_sparse=accept_large_sparse,\n                estimator_name=estimator_name,\n                input_name=input_name,\n            )\n            if ensure_2d and array.ndim &amp;lt; 2:\n                raise ValueError(\n                    f\&#34;Expected 2D input, got input with shape {array.shape}.\\n\&#34;\n                    \&#34;Reshape your data either using array.reshape(-1, 1) if \&#34;\n                    \&#34;your data has a single feature or array.reshape(1, -1) \&#34;\n                    \&#34;if it contains a single sample.\&#34;\n                )\n        else:\n            # If np.array(..) gives ComplexWarning, then we convert the warning\n            # to an error. This is needed because specifying a non complex\n            # dtype to the function converts complex to real dtype,\n            # thereby passing the test made in the lines following the scope\n            # of warnings context manager.\n            with warnings.catch_warnings():\n                try:\n                    warnings.simplefilter(\&#34;error\&#34;, ComplexWarning)\n                    if dtype is not None and xp.isdtype(dtype, \&#34;integral\&#34;):\n                        # Conversion float -&amp;gt; int should not contain NaN or\n                        # inf (numpy#14412). We cannot use casting=&#39;safe&#39; because\n                        # then conversion float -&amp;gt; int would be disallowed.\n                        array = _asarray_with_order(array, order=order, xp=xp)\n                        if xp.isdtype(array.dtype, (\&#34;real floating\&#34;, \&#34;complex floating\&#34;)):\n                            _assert_all_finite(\n                                array,\n                                allow_nan=False,\n                                msg_dtype=dtype,\n                                estimator_name=estimator_name,\n                                input_name=input_name,\n                            )\n                        array = xp.astype(array, dtype, copy=False)\n                    else:\n                        array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n                except ComplexWarning as complex_warning:\n                    raise ValueError(\n                        \&#34;Complex data not supported\\n{}\\n\&#34;.format(array)\n                    ) from complex_warning\n    \n            # It is possible that the np.array(..) gave no warning. This happens\n            # when no dtype conversion happened, for example dtype = None. The\n            # result is that np.array(..) produces an array of complex dtype\n            # and we need to catch and raise exception for such cases.\n            _ensure_no_complex_data(array)\n    \n            if ensure_2d:\n                # If input is scalar raise error\n                if array.ndim == 0:\n                    raise ValueError(\n                        \&#34;Expected 2D array, got scalar array instead:\\narray={}.\\n\&#34;\n                        \&#34;Reshape your data either using array.reshape(-1, 1) if \&#34;\n                        \&#34;your data has a single feature or array.reshape(1, -1) \&#34;\n                        \&#34;if it contains a single sample.\&#34;.format(array)\n                    )\n                # If input is 1D raise error\n                if array.ndim == 1:\n                    # If input is a Series-like object (eg. pandas Series or polars Series)\n                    if type_if_series is not None:\n                        msg = (\n                            f\&#34;Expected a 2-dimensional container but got {type_if_series} \&#34;\n                            \&#34;instead. Pass a DataFrame containing a single row (i.e. \&#34;\n                            \&#34;single sample) or a single column (i.e. single feature) \&#34;\n                            \&#34;instead.\&#34;\n                        )\n                    else:\n                        msg = (\n                            f\&#34;Expected 2D array, got 1D array instead:\\narray={array}.\\n\&#34;\n                            \&#34;Reshape your data either using array.reshape(-1, 1) if \&#34;\n                            \&#34;your data has a single feature or array.reshape(1, -1) \&#34;\n                            \&#34;if it contains a single sample.\&#34;\n                        )\n                    raise ValueError(msg)\n    \n            if dtype_numeric and hasattr(array.dtype, \&#34;kind\&#34;) and array.dtype.kind in \&#34;USV\&#34;:\n                raise ValueError(\n                    \&#34;dtype=&#39;numeric&#39; is not compatible with arrays of bytes/strings.\&#34;\n                    \&#34;Convert your data to numeric values explicitly instead.\&#34;\n                )\n            if not allow_nd and array.ndim &amp;gt;= 3:\n                raise ValueError(\n                    \&#34;Found array with dim %d. %s expected &amp;lt;= 2.\&#34;\n                    % (array.ndim, estimator_name)\n                )\n    \n            if force_all_finite:\n                _assert_all_finite(\n                    array,\n                    input_name=input_name,\n                    estimator_name=estimator_name,\n                    allow_nan=force_all_finite == \&#34;allow-nan\&#34;,\n                )\n    \n            if copy:\n                if _is_numpy_namespace(xp):\n                    # only make a copy if `array` and `array_orig` may share memory`\n                    if np.may_share_memory(array, array_orig):\n                        array = _asarray_with_order(\n                            array, dtype=dtype, order=order, copy=True, xp=xp\n                        )\n                else:\n                    # always make a copy for non-numpy arrays\n                    array = _asarray_with_order(\n                        array, dtype=dtype, order=order, copy=True, xp=xp\n                    )\n    \n        if ensure_min_samples &amp;gt; 0:\n            n_samples = _num_samples(array)\n            if n_samples &amp;lt; ensure_min_samples:\n                raise ValueError(\n                    \&#34;Found array with %d sample(s) (shape=%s) while a\&#34;\n                    \&#34; minimum of %d is required%s.\&#34;\n                    % (n_samples, array.shape, ensure_min_samples, context)\n                )\n    \n        if ensure_min_features &amp;gt; 0 and array.ndim == 2:\n            n_features = array.shape[1]\n            if n_features &amp;lt; ensure_min_features:\n&amp;gt;               raise ValueError(\n                    \&#34;Found array with %d feature(s) (shape=%s) while\&#34;\n                    \&#34; a minimum of %d is required%s.\&#34;\n                    % (n_features, array.shape, ensure_min_features, context)\n                )\nE               ValueError: Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by LassoCV.\n\naccept_large_sparse = False\naccept_sparse = &#39;csc&#39;\nallow_nd   = False\narray      = array([], shape=(10, 0), dtype=float64)\narray_orig = array([], shape=(10, 0), dtype=float64)\ncontext    = &#39; by LassoCV&#39;\ncopy       = False\ndtype      = None\ndtype_numeric = False\ndtype_orig = dtype(&#39;float64&#39;)\ndtypes_orig = None\nensure_2d  = True\nensure_min_features = 1\nensure_min_samples = 1\nestimator  = LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4FF3D91A40)\nestimator_name = &#39;LassoCV&#39;\nforce_all_finite = True\ninput_name = &#39;X&#39;\nis_array_api_compliant = False\nn_features = 0\nn_samples  = 10\norder      = None\npandas_requires_conversion = False\ntype_if_series = None\nxp         = &amp;lt;sklearn.utils._array_api._NumPyAPIWrapper object at 0x7f50011a7a90&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1091: ValueError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ncheck = functools.partial(&amp;lt;function check_fit2d_1feature at 0x7f4ffd4cbd00&amp;gt;, &#39;D0CRT&#39;)\nname = &#39;check_fit2d_1feature&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit2d_1feature at 0x7f4ffd4cbd00&amp;gt;, &#39;D0CRT&#39;)\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nname       = &#39;check_fit2d_1feature&#39;\n\ntest/test_distilled_conditional_randomization_test.py:63: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;D0CRT&#39;, D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None))\n        fn         = &amp;lt;function check_fit2d_1feature at 0x7f4ffd4cbc70&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1672: in check_fit2d_1feature\n    with raises(ValueError, match=msgs, may_pass=True):\n        X          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\n        estimator  = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7F4FF3D92340),\n      la...ate(PCG64) at 0x7F4FF3D91240,\n                              tol=1e-06),\n      random_state=1, screening_threshold=None)\n        estimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n        msgs       = [&#39;1 feature\\\\(s\\\\)&#39;, &#39;n_features = 1&#39;, &#39;n_features=1&#39;]\n        name       = &#39;D0CRT&#39;\n        rnd        = RandomState(MT19937) at 0x7F4FFDFD9440\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4ff3b40fd0&amp;gt;\nexc_type = &amp;lt;class &#39;ValueError&#39;&amp;gt;\nexc_value = ValueError(&#39;Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by LassoCV.&#39;)\n_ = &amp;lt;traceback object at 0x7f4ff3c08800&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f\&#34;Did not raise: {self.expected_exc_types}\&#34;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n                raise AssertionError(self.err_msg) from exc_value\n            else:\n                return False  # will re-raise the original exception\n    \n        if self.matches is not None:\n            err_msg = self.err_msg or (\n                \&#34;The error message should contain one of the following \&#34;\n                \&#34;patterns:\\n{}\\nGot {}\&#34;.format(\&#34;\\n\&#34;.join(self.matches), str(exc_value))\n            )\n            if not any(re.search(match, str(exc_value)) for match in self.matches):\n&amp;gt;               raise AssertionError(err_msg) from exc_value\nE               AssertionError: The error message should contain one of the following patterns:\nE               1 feature\\(s\\)\nE               n_features = 1\nE               n_features=1\nE               Got Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by LassoCV.\n\n_          = &amp;lt;traceback object at 0x7f4ff3c08800&amp;gt;\nerr_msg    = &#39;The error message should contain one of the following patterns:\\n1 feature\\\\(s\\\\)\\nn_features = 1\\nn_features=1\\nGot Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by LassoCV.&#39;\nexc_type   = &amp;lt;class &#39;ValueError&#39;&amp;gt;\nexc_value  = ValueError(&#39;Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by LassoCV.&#39;)\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4ff3b40fd0&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:925: AssertionError\n&#34;}], &#34;test/test_permutation_feature_importance.py::test_permutation_importance&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_permutation_feature_importance.py::test_permutation_importance&#34;, &#34;duration&#34;: &#34;00:00:07&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_permutation_feature_importance.py::test_permutation_importance&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:07&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_permutation_feature_importance.py::test_pfi_cv[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_permutation_feature_importance.py::test_pfi_cv[default data]&#34;, &#34;duration&#34;: &#34;00:00:05&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_permutation_feature_importance.py::test_pfi_cv[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:05&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting estimators for each fold:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting estimators for each fold:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  3.57it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  4.46it/s]\n\u0101\r \r\rFitting importance estimators for each fold:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting importance estimators for each fold:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&lt;00:00,  9.63it/s]\rFitting importance estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 12.02it/s]\n\u0101\r \r\rComputing importance scores over folds:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importance scores over folds:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&lt;00:00,  4.31it/s]\rComputing importance scores over folds: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00,  5.38it/s]\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_reproducibility_with_rng&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_reproducibility_with_rng&#34;, &#34;duration&#34;: &#34;00:00:07&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_d0crt_reproducibility_with_rng&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:07&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator1-check1-check_fit_score_takes_y]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator1-check1-check_fit_score_takes_y]&#34;, &#34;duration&#34;: &#34;308 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator1-check1-check_fit_score_takes_y]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;308 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator1-check1-check_estimators_overwrite_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator1-check1-check_estimators_overwrite_params]&#34;, &#34;duration&#34;: &#34;234 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator1-check1-check_estimators_overwrite_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;234 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ncheck = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4ffd4da9e0&amp;gt;, &#39;D0CRT&#39;)\nname = &#39;check_estimators_overwrite_params&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4ffd4da9e0&amp;gt;, &#39;D0CRT&#39;)\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nname       = &#39;check_estimators_overwrite_params&#39;\n\ntest/test_distilled_conditional_randomization_test.py:63: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;D0CRT&#39;, D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None))\n        fn         = &amp;lt;function check_estimators_overwrite_params at 0x7f4ffd4da950&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;D0CRT&#39;\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\n    @ignore_warnings(category=FutureWarning)\n    def check_estimators_overwrite_params(name, estimator_orig):\n        X, y = make_blobs(random_state=0, n_samples=21)\n        X = _enforce_estimator_tags_X(estimator_orig, X, kernel=rbf_kernel)\n        estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        set_random_state(estimator)\n    \n        # Make a physical copy of the original estimator parameters before fitting.\n        params = estimator.get_params()\n        original_params = deepcopy(params)\n    \n        # Fit the model\n        estimator.fit(X, y)\n    \n        # Compare the state of the model parameters with the original parameters\n        new_params = estimator.get_params()\n        for param_name, original_value in original_params.items():\n            new_value = new_params[param_name]\n    \n            # We should never change or mutate the internal state of input\n            # parameters by default. To check this we use the joblib.hash function\n            # that introspects recursively any subobjects to compute a checksum.\n            # The only exception to this rule of immutable constructor parameters\n            # is possible RandomState instance but in this check we explicitly\n            # fixed the random_state params recursively to be integer seeds.\n&amp;gt;           assert joblib.hash(new_value) == joblib.hash(original_value), (\n                \&#34;Estimator %s should not change or mutate \&#34;\n                \&#34; the parameter %s from %s to %s during fit.\&#34;\n                % (name, param_name, original_value, new_value)\n            )\nE           AssertionError: Estimator D0CRT should not change or mutate  the parameter estimator__random_state from None to RandomState(PCG64) during fit.\n\nX          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7F4FF3D93440),\n      la...ate(PCG64) at 0x7F4FF3D92F40,\n                              tol=1e-06),\n      random_state=0, screening_threshold=None)\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nname       = &#39;D0CRT&#39;\nnew_params = {&#39;centered&#39;: True, &#39;estimated_coef&#39;: None, &#39;estimated_intercept&#39;: None, &#39;estimator&#39;: LassoCV(n_jobs=1, random_state=RandomState(PCG64) at 0x7F4FF3D93440), ...}\nnew_value  = RandomState(PCG64) at 0x7F4FF3D93440\noriginal_params = {&#39;centered&#39;: True, &#39;estimated_coef&#39;: None, &#39;estimated_intercept&#39;: None, &#39;estimator&#39;: LassoCV(n_jobs=1), ...}\noriginal_value = None\nparam_name = &#39;estimator__random_state&#39;\nparams     = {&#39;centered&#39;: True, &#39;estimated_coef&#39;: None, &#39;estimated_intercept&#39;: None, &#39;estimator&#39;: LassoCV(n_jobs=1, random_state=RandomState(PCG64) at 0x7F4FF3D93440), ...}\ny          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3270: AssertionError\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator7-check7-check_pipeline_consistency]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator7-check7-check_pipeline_consistency]&#34;, &#34;duration&#34;: &#34;635 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator7-check7-check_pipeline_consistency]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;635 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_permutation_feature_importance.py::test_permutation_importance_function&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_permutation_feature_importance.py::test_permutation_importance_function&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_permutation_feature_importance.py::test_permutation_importance_function&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_permutation_feature_importance.py::test_pfi_repeatability&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_permutation_feature_importance.py::test_pfi_repeatability&#34;, &#34;duration&#34;: &#34;78 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_permutation_feature_importance.py::test_pfi_repeatability&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;78 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_permutation_feature_importance.py::test_pfi_randomness_with_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_permutation_feature_importance.py::test_pfi_randomness_with_none&#34;, &#34;duration&#34;: &#34;158 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_permutation_feature_importance.py::test_pfi_randomness_with_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;158 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator15-check15-check_methods_subset_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator15-check15-check_methods_subset_invariance]&#34;, &#34;duration&#34;: &#34;359 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator15-check15-check_methods_subset_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;359 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_groups_warning[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_groups_warning[default data]&#34;, &#34;duration&#34;: &#34;239 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_groups_warning[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;239 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_incompatible_imputer[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_incompatible_imputer[default data]&#34;, &#34;duration&#34;: &#34;23 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_incompatible_imputer[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;23 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unfitted_base_perturbation[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unfitted_base_perturbation[default data]&#34;, &#34;duration&#34;: &#34;24 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unfitted_base_perturbation[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;24 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_type[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_type[default data]&#34;, &#34;duration&#34;: &#34;27 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_type[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;27 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_mismatched_features_string[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_mismatched_features_string[default data]&#34;, &#34;duration&#34;: &#34;77 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_mismatched_features_string[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;77 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator4-check4-check_fit_check_is_fitted]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator4-check4-check_fit_check_is_fitted]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator4-check4-check_fit_check_is_fitted]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ncheck = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7f4ffd4dba30&amp;gt;, &#39;D0CRT&#39;)\nname = &#39;check_fit_check_is_fitted&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7f4ffd4dba30&amp;gt;, &#39;D0CRT&#39;)\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nname       = &#39;check_fit_check_is_fitted&#39;\n\ntest/test_distilled_conditional_randomization_test.py:63: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;D0CRT&#39;\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\n    def check_fit_check_is_fitted(name, estimator_orig):\n        # Make sure that estimator doesn&#39;t pass check_is_fitted before calling fit\n        # and that passes check_is_fitted once it&#39;s fit.\n    \n        rng = np.random.RandomState(42)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if \&#34;warm_start\&#34; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if not _safe_tags(estimator).get(\&#34;stateless\&#34;, False):\n            # stateless estimators (such as FunctionTransformer) are always \&#34;fit\&#34;!\n            try:\n                check_is_fitted(estimator)\n&amp;gt;               raise AssertionError(\n                    f\&#34;{estimator.__class__.__name__} passes check_is_fitted before being\&#34;\n                    \&#34; fit!\&#34;\n                )\nE               AssertionError: D0CRT passes check_is_fitted before being fit!\n\nX          = array([[100.49671415,  99.8617357 ],\n       [100.64768854, 101.52302986],\n       [ 99.76584663,  99.76586304],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1),\n      lasso_screening=LassoCV(fit_intercept=False, n_alphas=10,\n                   ...ate(PCG64) at 0x7F4FF3D93040,\n                              tol=1e-06),\n      random_state=0, screening_threshold=None)\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nn_samples  = 100\nname       = &#39;D0CRT&#39;\nrng        = RandomState(MT19937) at 0x7F4FF3D93340\ny          = array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,...1,\n       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3914: AssertionError\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_internal_error[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_internal_error[default data]&#34;, &#34;duration&#34;: &#34;121 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_internal_error[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;121 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_var_type[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_var_type[default data]&#34;, &#34;duration&#34;: &#34;143 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_var_type[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;143 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_no_selection&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_no_selection&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_no_selection&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_not_good_type_X[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_not_good_type_X[default data]&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_not_good_type_X[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unfitted_importance[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unfitted_importance[default data]&#34;, &#34;duration&#34;: &#34;28 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unfitted_importance[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;28 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_fit_with_no_cv&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_fit_with_no_cv&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_fit_with_no_cv&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim with noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim with noise]&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim with noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_RF_classification&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_RF_classification&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_RF_classification&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features and correlated noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features and correlated noise]&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features and correlated noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_covariance&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_covariance&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_covariance&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator12-check12-check_estimators_pickle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator12-check12-check_estimators_pickle]&#34;, &#34;duration&#34;: &#34;520 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator12-check12-check_estimators_pickle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;520 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_center&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_center&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_center&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator11-check11-check_estimators_pickle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator11-check11-check_estimators_pickle]&#34;, &#34;duration&#34;: &#34;314 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator11-check11-check_estimators_pickle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;314 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator0-check0-check_no_attributes_set_in_init]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator0-check0-check_no_attributes_set_in_init]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_invalid[estimator0-check0-check_no_attributes_set_in_init]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ncheck = functools.partial(&amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4dab00&amp;gt;, &#39;D0CRT&#39;)\nname = &#39;check_no_attributes_set_in_init&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4dab00&amp;gt;, &#39;D0CRT&#39;)\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nname       = &#39;check_no_attributes_set_in_init&#39;\n\ntest/test_distilled_conditional_randomization_test.py:63: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;D0CRT&#39;, D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None))\n        fn         = &amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4daa70&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;D0CRT&#39;\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\n    @ignore_warnings(category=FutureWarning)\n    def check_no_attributes_set_in_init(name, estimator_orig):\n        \&#34;\&#34;\&#34;Check setting during init.\&#34;\&#34;\&#34;\n        try:\n            # Clone fails if the estimator does not store\n            # all parameters as an attribute during init\n            estimator = clone(estimator_orig)\n        except AttributeError:\n            raise AttributeError(\n                f\&#34;Estimator {name} should store all parameters as an attribute during init.\&#34;\n            )\n    \n        if hasattr(type(estimator).__init__, \&#34;deprecated_original\&#34;):\n            return\n    \n        init_params = _get_args(type(estimator).__init__)\n        if _IS_PYPY:\n            # __init__ signature has additional objects in PyPy\n            for key in [\&#34;obj\&#34;]:\n                if key in init_params:\n                    init_params.remove(key)\n        parents_init_params = [\n            param\n            for params_parent in (_get_args(parent) for parent in type(estimator).__mro__)\n            for param in params_parent\n        ]\n    \n        # Test for no setting apart from parameters during init\n        invalid_attr = set(vars(estimator)) - set(init_params) - set(parents_init_params)\n        # Ignore private attributes\n        invalid_attr = set([attr for attr in invalid_attr if not attr.startswith(\&#34;_\&#34;)])\n&amp;gt;       assert not invalid_attr, (\n            \&#34;Estimator %s should not set any attribute apart\&#34;\n            \&#34; from parameters during init. Found attributes %s.\&#34;\n            % (name, sorted(invalid_attr))\n        )\nE       AssertionError: Estimator D0CRT should not set any attribute apart from parameters during init. Found attributes [&#39;coefficient_&#39;, &#39;intercept_&#39;, &#39;is_logistic_&#39;, &#39;lasso_weights_&#39;, &#39;model_x_&#39;, &#39;model_y_&#39;, &#39;selection_set_&#39;].\n\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1),\n      lasso_screening=LassoCV(fit_intercept=False, n_alphas=10,\n                   ...m_state=RandomState(PCG64) at 0x7F4FFDFD9440,\n                              tol=1e-06),\n      screening_threshold=None)\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ninit_params = [&#39;self&#39;, &#39;estimator&#39;, &#39;method&#39;, &#39;estimated_coef&#39;, &#39;estimated_intercept&#39;, &#39;sigma_X&#39;, ...]\ninvalid_attr = {&#39;coefficient_&#39;, &#39;intercept_&#39;, &#39;is_logistic_&#39;, &#39;lasso_weights_&#39;, &#39;model_x_&#39;, &#39;model_y_&#39;, ...}\nname       = &#39;D0CRT&#39;\nparents_init_params = [&#39;estimator&#39;, &#39;method&#39;, &#39;estimated_coef&#39;, &#39;estimated_intercept&#39;, &#39;sigma_X&#39;, &#39;lasso_screening&#39;, ...]\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3308: AssertionError\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_linear_data_fail[default_cfi-high level noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_linear_data_fail[default_cfi-high level noise]&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_linear_data_fail[default_cfi-high level noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim]&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features and noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features and noise]&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features and noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_init[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_init[default data]&#34;, &#34;duration&#34;: &#34;17 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIClass::test_init[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;17 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_group[high dimension]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_group[high dimension]&#34;, &#34;duration&#34;: &#34;86 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_group[high dimension]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;86 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_regression_intercept&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_regression_intercept&#34;, &#34;duration&#34;: &#34;00:00:06&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_regression_intercept&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:06&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator6-check6-check_estimators_empty_data_messages]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator6-check6-check_estimators_empty_data_messages]&#34;, &#34;duration&#34;: &#34;9 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator6-check6-check_estimators_empty_data_messages]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;9 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator5-check5-check_dtype_object]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator5-check5-check_dtype_object]&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn_valid[estimator5-check5-check_dtype_object]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_leave_one_covariate_out.py::test_raises_value_error&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_leave_one_covariate_out.py::test_raises_value_error&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_leave_one_covariate_out.py::test_raises_value_error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_leave_one_covariate_out.py::test_loco_function&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_leave_one_covariate_out.py::test_loco_function&#34;, &#34;duration&#34;: &#34;748 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_leave_one_covariate_out.py::test_loco_function&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;748 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_leave_one_covariate_out.py::test_loco_cv[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_leave_one_covariate_out.py::test_loco_cv[default data]&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_leave_one_covariate_out.py::test_loco_cv[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting estimators for each fold:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 66.18it/s]\n\u0101\r \r\rFitting importance estimators for each fold:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting importance estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 2311.17it/s]\n\u0101\r \r\rComputing importance scores over folds:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importance scores over folds: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 3372.17it/s]\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_group_case&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_group_case&#34;, &#34;duration&#34;: &#34;250 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_group_case&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;250 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_classication[HiDim with noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_classication[HiDim with noise]&#34;, &#34;duration&#34;: &#34;00:00:09&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_classication[HiDim with noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:09&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_categorical[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_categorical[default data]&#34;, &#34;duration&#34;: &#34;100 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIClass::test_categorical[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;100 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_sample_categorical&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_sample_categorical&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_sample_categorical&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_continuous_case&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_continuous_case&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_continuous_case&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_error_wrong_type_data&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_error_wrong_type_data&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_error_wrong_type_data&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_binary_case&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_binary_case&#34;, &#34;duration&#34;: &#34;577 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_binary_case&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;577 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_error_no_predic&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_error_no_predic&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_error_no_predic&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_error_no_model_provide&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_error_no_model_provide&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_error_no_model_provide&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_error_no_predic_proba&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_error_no_predic_proba&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_error_no_predic_proba&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_pval_from_cb&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_pval_from_cb&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_pval_from_cb&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_zscore_from_cb&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_zscore_from_cb&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_zscore_from_cb&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_pval&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_pval&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_pval&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_zscore_from_pval&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_zscore_from_pval&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_zscore_from_pval&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test__replace_infinity&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test__replace_infinity&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test__replace_infinity&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_cb&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_cb&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_cb&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_pval_from_scale&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_pval_from_scale&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_pval_from_scale&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_pval_from_two_sided_pval_and_sign&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_pval_from_two_sided_pval_and_sign&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_pval_from_two_sided_pval_and_sign&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_pval_corr_from_pval&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_pval_corr_from_pval&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_pval_corr_from_pval&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_zscore&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_zscore&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_zscore&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_plot_2d_imp[5_features]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_plot_2d_imp[5_features]&#34;, &#34;duration&#34;: &#34;271 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_plot_2d_imp[5_features]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;271 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_plot[10 features]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_plot[10 features]&#34;, &#34;duration&#34;: &#34;62 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_plot[10 features]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;62 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_function_cfi[default_cfi-high level noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_function_cfi[default_cfi-high level noise]&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_function_cfi[default_cfi-high level noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_reproducibility_with_rng&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_reproducibility_with_rng&#34;, &#34;duration&#34;: &#34;224 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_reproducibility_with_rng&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;224 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_repeatibility&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_repeatibility&#34;, &#34;duration&#34;: &#34;86 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_repeatibility&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;86 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_reproducibility_with_integer&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_reproducibility_with_integer&#34;, &#34;duration&#34;: &#34;179 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_reproducibility_with_integer&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;179 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_classication[HiDim]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_classication[HiDim]&#34;, &#34;duration&#34;: &#34;00:00:08&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_classication[HiDim]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:08&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_cv[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_cv[default data]&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_cv[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting importance estimators for each fold:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting importance estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 2071.67it/s]\n\u0101\r \r\rComputing importance scores over folds:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importance scores over folds: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 3487.12it/s]\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_plot_coverage[10-3-1-0.2-0-1.0-1.0-0.0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_plot_coverage[10-3-1-0.2-0-1.0-1.0-0.0]&#34;, &#34;duration&#34;: &#34;249 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_plot_coverage[10-3-1-0.2-0-1.0-1.0-0.0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;249 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_randomness_with_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_randomness_with_none&#34;, &#34;duration&#34;: &#34;369 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_randomness_with_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;369 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_n_permutations[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_n_permutations[default data]&#34;, &#34;duration&#34;: &#34;23 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_n_permutations[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;23 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_mismatched_features[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_mismatched_features[default data]&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_mismatched_features[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_classication[HiDim with correlated noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_classication[HiDim with correlated noise]&#34;, &#34;duration&#34;: &#34;00:00:10&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_classication[HiDim with correlated noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:10&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_assert_dimension_pvalue[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_assert_dimension_pvalue[default data]&#34;, &#34;duration&#34;: &#34;00:00:07&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_assert_dimension_pvalue[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:07&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_groups_format[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_groups_format[default data]&#34;, &#34;duration&#34;: &#34;13 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_groups_format[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;13 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unknown_predict_method[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unknown_predict_method[default data]&#34;, &#34;duration&#34;: &#34;10 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unknown_predict_method[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;10 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator54-check54-check_fit1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator54-check54-check_fit1d]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator54-check54-check_fit1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator53-check53-check_set_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator53-check53-check_set_params]&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator53-check53-check_set_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator16-check16-check_fit2d_1sample]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator16-check16-check_fit2d_1sample]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator16-check16-check_fit2d_1sample]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator6-check6-check_pipeline_consistency]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator6-check6-check_pipeline_consistency]&#34;, &#34;duration&#34;: &#34;8 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator6-check6-check_pipeline_consistency]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;8 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features]&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_fit_group[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_fit_group[default data]&#34;, &#34;duration&#34;: &#34;45 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIClass::test_fit_group[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;45 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator31-check31-check_fit_idempotent]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator31-check31-check_fit_idempotent]&#34;, &#34;duration&#34;: &#34;10 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator31-check31-check_fit_idempotent]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;10 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_fit_idempotent at 0x7f4ffd4db9a0&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_fit_idempotent&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_idempotent at 0x7f4ffd4db9a0&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_fit_idempotent&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3862: in check_fit_idempotent\n    estimator.fit(X_train, y_train)\n        X          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\n        X_test     = array([[ 98.77456448, 100.84436298],\n       [101.86755896, 100.90604466],\n       [100.8644362 ,  99.25783498],\n       ...20353],\n       [100.61407937, 100.92220667],\n       [ 98.92924738, 101.05445173],\n       [100.01050002, 101.78587049]])\n        X_train    = array([[ 99.30543214,  99.85036546],\n       [ 98.82687659, 101.94362119],\n       [ 99.260437  , 101.5430146 ],\n       ...07516],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [ 98.68409259,  99.5384154 ]])\n        check_methods = [&#39;predict&#39;, &#39;transform&#39;, &#39;decision_function&#39;, &#39;predict_proba&#39;]\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        n_samples  = 100\n        name       = &#39;BasePerturbationCV&#39;\n        rng        = RandomState(MT19937) at 0x7F4FF3AA0B40\n        test       = array([82, 55, 11, 63, 90, 92, 47, 99, 18, 65, 64, 88, 61, 75, 54, 31, 16,\n       59, 44, 48])\n        train      = array([62, 52, 94, 89, 22, 57,  9, 84, 87, 50, 45, 66, 13, 42, 15, 20,  2,\n       35, 17, 27, 29,  4, 41, 76, 85, 49, ... 7, 81, 86, 53, 73, 51, 26, 68, 28, 33, 60, 40, 95,  6, 69, 36,\n       93, 24, 39,  0,  1, 58, 12,  3, 43, 97, 98, 74])\n        y          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\n        y_test     = array([0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1])\n        y_train    = array([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,...    1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[ 99.30543214,  99.85036546],\n       [ 98.82687659, 101.94362119],\n       [ 99.260437  , 101.5430146 ],\n       ...07516],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [ 98.68409259,  99.5384154 ]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,...    1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1484190&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1484190&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1484190&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff943dc00&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff943dc00&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff943ef20&amp;gt;\n        dispatch_timestamp = 1770122605.507911\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff943ef20&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff943dc00&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff943f2e0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff943dc00&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff943fa90&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff943dc00&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff943f0a0&amp;gt;\n        args       = (LinearRegression(), array([[ 99.96071718,  98.8319065 ],\n       [101.49407907,  99.79484174],\n       [ 99.50196755, 1...0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 99.96071718,  98.8319065 ],\n       [101.49407907,  99.79484174],\n       [ 99.50196755, 101.92953205],\n       ...07516],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [ 98.68409259,  99.5384154 ]])\ny_train = array([1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 99.96071718,  98.8319065 ],\n       [101.49407907,  99.79484174],\n       [ 99.50196755, 101.92953205],\n       ...07516],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [ 98.68409259,  99.5384154 ]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 259.49it/s]\n\u0101\r \r\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator27-check27-check_estimators_fit_returns_self]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator27-check27-check_estimators_fit_returns_self]&#34;, &#34;duration&#34;: &#34;9 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator27-check27-check_estimators_fit_returns_self]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;9 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator29-check29-check_estimators_empty_data_messages]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator29-check29-check_estimators_empty_data_messages]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator29-check29-check_estimators_empty_data_messages]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_no_implemented_methods&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_no_implemented_methods&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_no_implemented_methods&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator8-check8-check_estimators_overwrite_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator8-check8-check_estimators_overwrite_params]&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator8-check8-check_estimators_overwrite_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbation(estimator=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4ffd4da9e0&amp;gt;, &#39;BasePerturbation&#39;)\nname = &#39;check_estimators_overwrite_params&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4ffd4da9e0&amp;gt;, &#39;BasePerturbation&#39;)\nestimator  = BasePerturbation(estimator=LinearRegression())\nname       = &#39;check_estimators_overwrite_params&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbation&#39;, BasePerturbation(estimator=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_overwrite_params at 0x7f4ffd4da950&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;BasePerturbation&#39;\nestimator_orig = BasePerturbation(estimator=LinearRegression())\n\n    @ignore_warnings(category=FutureWarning)\n    def check_estimators_overwrite_params(name, estimator_orig):\n        X, y = make_blobs(random_state=0, n_samples=21)\n        X = _enforce_estimator_tags_X(estimator_orig, X, kernel=rbf_kernel)\n        estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        set_random_state(estimator)\n    \n        # Make a physical copy of the original estimator parameters before fitting.\n        params = estimator.get_params()\n        original_params = deepcopy(params)\n    \n        # Fit the model\n        estimator.fit(X, y)\n    \n        # Compare the state of the model parameters with the original parameters\n        new_params = estimator.get_params()\n        for param_name, original_value in original_params.items():\n            new_value = new_params[param_name]\n    \n            # We should never change or mutate the internal state of input\n            # parameters by default. To check this we use the joblib.hash function\n            # that introspects recursively any subobjects to compute a checksum.\n            # The only exception to this rule of immutable constructor parameters\n            # is possible RandomState instance but in this check we explicitly\n            # fixed the random_state params recursively to be integer seeds.\n&amp;gt;           assert joblib.hash(new_value) == joblib.hash(original_value), (\n                \&#34;Estimator %s should not change or mutate \&#34;\n                \&#34; the parameter %s from %s to %s during fit.\&#34;\n                % (name, param_name, original_value, new_value)\n            )\nE           AssertionError: Estimator BasePerturbation should not change or mutate  the parameter estimator from LinearRegression() to LinearRegression() during fit.\n\nX          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\nestimator  = BasePerturbation(estimator=LinearRegression(), features_groups={0: [0], 1: [1]},\n                 random_state=0)\nestimator_orig = BasePerturbation(estimator=LinearRegression())\nname       = &#39;BasePerturbation&#39;\nnew_params = {&#39;estimator&#39;: LinearRegression(), &#39;estimator__copy_X&#39;: True, &#39;estimator__fit_intercept&#39;: True, &#39;estimator__n_jobs&#39;: None, ...}\nnew_value  = LinearRegression()\noriginal_params = {&#39;estimator&#39;: LinearRegression(), &#39;estimator__copy_X&#39;: True, &#39;estimator__fit_intercept&#39;: True, &#39;estimator__n_jobs&#39;: None, ...}\noriginal_value = LinearRegression()\nparam_name = &#39;estimator&#39;\nparams     = {&#39;estimator&#39;: LinearRegression(), &#39;estimator__copy_X&#39;: True, &#39;estimator__fit_intercept&#39;: True, &#39;estimator__n_jobs&#39;: None, ...}\ny          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3270: AssertionError\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator6-check6-check_no_attributes_set_in_init]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator6-check6-check_no_attributes_set_in_init]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator6-check6-check_no_attributes_set_in_init]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbation(estimator=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4dab00&amp;gt;, &#39;BasePerturbation&#39;)\nname = &#39;check_no_attributes_set_in_init&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4dab00&amp;gt;, &#39;BasePerturbation&#39;)\nestimator  = BasePerturbation(estimator=LinearRegression())\nname       = &#39;check_no_attributes_set_in_init&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbation&#39;, BasePerturbation(estimator=LinearRegression()))\n        fn         = &amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4daa70&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;BasePerturbation&#39;\nestimator_orig = BasePerturbation(estimator=LinearRegression())\n\n    @ignore_warnings(category=FutureWarning)\n    def check_no_attributes_set_in_init(name, estimator_orig):\n        \&#34;\&#34;\&#34;Check setting during init.\&#34;\&#34;\&#34;\n        try:\n            # Clone fails if the estimator does not store\n            # all parameters as an attribute during init\n            estimator = clone(estimator_orig)\n        except AttributeError:\n            raise AttributeError(\n                f\&#34;Estimator {name} should store all parameters as an attribute during init.\&#34;\n            )\n    \n        if hasattr(type(estimator).__init__, \&#34;deprecated_original\&#34;):\n            return\n    \n        init_params = _get_args(type(estimator).__init__)\n        if _IS_PYPY:\n            # __init__ signature has additional objects in PyPy\n            for key in [\&#34;obj\&#34;]:\n                if key in init_params:\n                    init_params.remove(key)\n        parents_init_params = [\n            param\n            for params_parent in (_get_args(parent) for parent in type(estimator).__mro__)\n            for param in params_parent\n        ]\n    \n        # Test for no setting apart from parameters during init\n        invalid_attr = set(vars(estimator)) - set(init_params) - set(parents_init_params)\n        # Ignore private attributes\n        invalid_attr = set([attr for attr in invalid_attr if not attr.startswith(\&#34;_\&#34;)])\n&amp;gt;       assert not invalid_attr, (\n            \&#34;Estimator %s should not set any attribute apart\&#34;\n            \&#34; from parameters during init. Found attributes %s.\&#34;\n            % (name, sorted(invalid_attr))\n        )\nE       AssertionError: Estimator BasePerturbation should not set any attribute apart from parameters during init. Found attributes [&#39;importances_&#39;, &#39;loss_&#39;, &#39;loss_reference_&#39;, &#39;n_features_groups_&#39;, &#39;pvalues_&#39;].\n\nestimator  = BasePerturbation(estimator=LinearRegression())\nestimator_orig = BasePerturbation(estimator=LinearRegression())\ninit_params = [&#39;self&#39;, &#39;estimator&#39;, &#39;method&#39;, &#39;loss&#39;, &#39;n_permutations&#39;, &#39;statistical_test&#39;, ...]\ninvalid_attr = {&#39;importances_&#39;, &#39;loss_&#39;, &#39;loss_reference_&#39;, &#39;n_features_groups_&#39;, &#39;pvalues_&#39;}\nname       = &#39;BasePerturbation&#39;\nparents_init_params = [&#39;estimator&#39;, &#39;method&#39;, &#39;loss&#39;, &#39;n_permutations&#39;, &#39;statistical_test&#39;, &#39;features_groups&#39;, ...]\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3308: AssertionError\n--------------------------- Captured stderr teardown ---------------------------\n\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator29-check29-check_dict_unchanged]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator29-check29-check_dict_unchanged]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator29-check29-check_dict_unchanged]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_dict_unchanged at 0x7f4ffd4cb520&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_dict_unchanged&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_dict_unchanged at 0x7f4ffd4cb520&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_dict_unchanged&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_dict_unchanged at 0x7f4ffd4cb490&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1409: in check_dict_unchanged\n    estimator.fit(X, y)\n        X          = array([[1.09762701, 1.43037873, 1.20552675],\n       [1.08976637, 0.8473096 , 1.29178823],\n       [0.87517442, 1.783546...03, 1.97674768, 0.20408962],\n       [0.41775351, 0.32261904, 1.30621665],\n       [0.50658321, 0.93262155, 0.48885118]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n        rnd        = RandomState(MT19937) at 0x7F4FF3AA0C40\n        y          = array([1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.09762701, 1.43037873, 1.20552675],\n       [1.08976637, 0.8473096 , 1.29178823],\n       [0.87517442, 1.783546...03, 1.97674768, 0.20408962],\n       [0.41775351, 0.32261904, 1.30621665],\n       [0.50658321, 0.93262155, 0.48885118]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0edc890&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0edc890&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...1, 0.32261904, 1.30621665],\n       [0.50658321, 0.93262155, 0.48885118]]), array([0, 1, 1, 1, 1, 1, 0, 0, 0, 0])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0edc890&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3a8ada0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3a8ada0&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff3a8b370&amp;gt;\n        dispatch_timestamp = 1770122606.6571476\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff3a8b370&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3a8ada0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff3a8b520&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3a8ada0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff3a89270&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3a8ada0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff3a8a6b0&amp;gt;\n        args       = (LinearRegression(), array([[0.52911122, 1.54846738, 0.91230066],\n       [1.1368679 , 0.0375796 , 1.23527099],\n       ...1775351, 0.32261904, 1.30621665],\n       [0.50658321, 0.93262155, 0.48885118]]), array([0, 1, 1, 1, 1, 1, 0, 0, 0, 0]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.52911122, 1.54846738, 0.91230066],\n       [1.1368679 , 0.0375796 , 1.23527099],\n       [1.22419145, 1.233867...03, 1.97674768, 0.20408962],\n       [0.41775351, 0.32261904, 1.30621665],\n       [0.50658321, 0.93262155, 0.48885118]])\ny_train = array([0, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.52911122, 1.54846738, 0.91230066],\n       [1.1368679 , 0.0375796 , 1.23527099],\n       [1.22419145, 1.233867...03, 1.97674768, 0.20408962],\n       [0.41775351, 0.32261904, 1.30621665],\n       [0.50658321, 0.93262155, 0.48885118]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 623.04it/s]\n\u0101\r \r\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator10-check10-check_fit_check_is_fitted]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator10-check10-check_fit_check_is_fitted]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator10-check10-check_fit_check_is_fitted]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbation(estimator=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7f4ffd4dba30&amp;gt;, &#39;BasePerturbation&#39;)\nname = &#39;check_fit_check_is_fitted&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7f4ffd4dba30&amp;gt;, &#39;BasePerturbation&#39;)\nestimator  = BasePerturbation(estimator=LinearRegression())\nname       = &#39;check_fit_check_is_fitted&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;BasePerturbation&#39;\nestimator_orig = BasePerturbation(estimator=LinearRegression())\n\n    def check_fit_check_is_fitted(name, estimator_orig):\n        # Make sure that estimator doesn&#39;t pass check_is_fitted before calling fit\n        # and that passes check_is_fitted once it&#39;s fit.\n    \n        rng = np.random.RandomState(42)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if \&#34;warm_start\&#34; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if not _safe_tags(estimator).get(\&#34;stateless\&#34;, False):\n            # stateless estimators (such as FunctionTransformer) are always \&#34;fit\&#34;!\n            try:\n                check_is_fitted(estimator)\n&amp;gt;               raise AssertionError(\n                    f\&#34;{estimator.__class__.__name__} passes check_is_fitted before being\&#34;\n                    \&#34; fit!\&#34;\n                )\nE               AssertionError: BasePerturbation passes check_is_fitted before being fit!\n\nX          = array([[100.49671415,  99.8617357 ],\n       [100.64768854, 101.52302986],\n       [ 99.76584663,  99.76586304],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\nestimator  = BasePerturbation(estimator=LinearRegression(), random_state=0)\nestimator_orig = BasePerturbation(estimator=LinearRegression())\nn_samples  = 100\nname       = &#39;BasePerturbation&#39;\nrng        = RandomState(MT19937) at 0x7F4FF3AA0A40\ny          = array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,...1,\n       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3914: AssertionError\n--------------------------- Captured stderr teardown ---------------------------\n\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator31-check31-check_estimators_nan_inf]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator31-check31-check_estimators_nan_inf]&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator31-check31-check_estimators_nan_inf]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator5-check5-check_estimators_empty_data_messages]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator5-check5-check_estimators_empty_data_messages]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator5-check5-check_estimators_empty_data_messages]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_importance&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_importance&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_importance&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator26-check26-check_methods_sample_order_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator26-check26-check_methods_sample_order_invariance]&#34;, &#34;duration&#34;: &#34;9 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator26-check26-check_methods_sample_order_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;9 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_methods_sample_order_invariance at 0x7f4ffd4cbac0&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_methods_sample_order_invariance&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_methods_sample_order_invariance at 0x7f4ffd4cbac0&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_methods_sample_order_invariance&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_methods_sample_order_invariance at 0x7f4ffd4cba30&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1579: in check_methods_sample_order_invariance\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n        rnd        = RandomState(MT19937) at 0x7F4FF3AA0E40\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1486ab0&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1486ab0&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...7, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]]), array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1486ab0&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3d141f0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3d141f0&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff3d16320&amp;gt;\n        dispatch_timestamp = 1770122607.3664038\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff3d16320&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3d141f0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff3d158d0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3d141f0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff3d15480&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3d141f0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff3d15090&amp;gt;\n        args       = (LinearRegression(), array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       ...2663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]]), array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\ny_train = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 290.20it/s]\n\u0101\r \r\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator27-check27-check_methods_subset_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator27-check27-check_methods_subset_invariance]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator27-check27-check_methods_subset_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_methods_subset_invariance at 0x7f4ffd4cb9a0&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_methods_subset_invariance&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_methods_subset_invariance at 0x7f4ffd4cb9a0&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_methods_subset_invariance&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_methods_subset_invariance at 0x7f4ffd4cb910&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1540: in check_methods_subset_invariance\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n        rnd        = RandomState(MT19937) at 0x7F4FF3AA1140\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1486960&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1486960&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...7, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]]), array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1486960&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3a1c880&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3a1c880&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff3a1db70&amp;gt;\n        dispatch_timestamp = 1770122607.6426897\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff3a1db70&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3a1c880&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff3a1eaa0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3a1c880&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff3a1e5f0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff3a1c880&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff3a1f4c0&amp;gt;\n        args       = (LinearRegression(), array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       ...2663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]]), array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\ny_train = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\n\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 920.81it/s]\u001b[A\u0101\r \r\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator12-check12-check_estimator_get_tags_default_keys]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator12-check12-check_estimator_get_tags_default_keys]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator12-check12-check_estimator_get_tags_default_keys]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator3-check3-check_dont_overwrite_parameters]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator3-check3-check_dont_overwrite_parameters]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator3-check3-check_dont_overwrite_parameters]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbation(estimator=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_dont_overwrite_parameters at 0x7f4ffd4cb6d0&amp;gt;, &#39;BasePerturbation&#39;)\nname = &#39;check_dont_overwrite_parameters&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_dont_overwrite_parameters at 0x7f4ffd4cb6d0&amp;gt;, &#39;BasePerturbation&#39;)\nestimator  = BasePerturbation(estimator=LinearRegression())\nname       = &#39;check_dont_overwrite_parameters&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbation&#39;, BasePerturbation(estimator=LinearRegression()))\n        fn         = &amp;lt;function check_dont_overwrite_parameters at 0x7f4ffd4cb640&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;BasePerturbation&#39;\nestimator_orig = BasePerturbation(estimator=LinearRegression())\n\n    @ignore_warnings(category=FutureWarning)\n    def check_dont_overwrite_parameters(name, estimator_orig):\n        # check that fit method only changes or sets private attributes\n        if hasattr(estimator_orig.__init__, \&#34;deprecated_original\&#34;):\n            # to not check deprecated classes\n            return\n        estimator = clone(estimator_orig)\n        rnd = np.random.RandomState(0)\n        X = 3 * rnd.uniform(size=(20, 3))\n        X = _enforce_estimator_tags_X(estimator_orig, X)\n        y = X[:, 0].astype(int)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if hasattr(estimator, \&#34;n_components\&#34;):\n            estimator.n_components = 1\n        if hasattr(estimator, \&#34;n_clusters\&#34;):\n            estimator.n_clusters = 1\n    \n        set_random_state(estimator, 1)\n        dict_before_fit = estimator.__dict__.copy()\n        estimator.fit(X, y)\n    \n        dict_after_fit = estimator.__dict__\n    \n        public_keys_after_fit = [\n            key for key in dict_after_fit.keys() if _is_public_parameter(key)\n        ]\n    \n        attrs_added_by_fit = [\n            key for key in public_keys_after_fit if key not in dict_before_fit.keys()\n        ]\n    \n        # check that fit doesn&#39;t add any public attribute\n        assert not attrs_added_by_fit, (\n            \&#34;Estimator adds public attribute(s) during\&#34;\n            \&#34; the fit method.\&#34;\n            \&#34; Estimators are only allowed to add private attributes\&#34;\n            \&#34; either started with _ or ended\&#34;\n            \&#34; with _ but %s added\&#34; % \&#34;, \&#34;.join(attrs_added_by_fit)\n        )\n    \n        # check that fit doesn&#39;t change any public attribute\n        attrs_changed_by_fit = [\n            key\n            for key in public_keys_after_fit\n            if (dict_before_fit[key] is not dict_after_fit[key])\n        ]\n    \n&amp;gt;       assert not attrs_changed_by_fit, (\n            \&#34;Estimator changes public attribute(s) during\&#34;\n            \&#34; the fit method. Estimators are only allowed\&#34;\n            \&#34; to change attributes started\&#34;\n            \&#34; or ended with _, but\&#34;\n            \&#34; %s changed\&#34; % \&#34;, \&#34;.join(attrs_changed_by_fit)\n        )\nE       AssertionError: Estimator changes public attribute(s) during the fit method. Estimators are only allowed to change attributes started or ended with _, but features_groups changed\n\nX          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\nattrs_added_by_fit = []\nattrs_changed_by_fit = [&#39;features_groups&#39;]\ndict_after_fit = {&#39;_features_groups_ids&#39;: array([[0],\n       [1],\n       [2]]), &#39;_groups_ids&#39;: None, &#39;_n_groups&#39;: None, &#39;estimator&#39;: LinearRegression(), ...}\ndict_before_fit = {&#39;_features_groups_ids&#39;: None, &#39;_groups_ids&#39;: None, &#39;_n_groups&#39;: None, &#39;estimator&#39;: LinearRegression(), ...}\nestimator  = BasePerturbation(estimator=LinearRegression(),\n                 features_groups={0: [0], 1: [1], 2: [2]}, random_state=1)\nestimator_orig = BasePerturbation(estimator=LinearRegression())\nname       = &#39;BasePerturbation&#39;\npublic_keys_after_fit = [&#39;features_groups&#39;, &#39;estimator&#39;, &#39;loss&#39;, &#39;method&#39;, &#39;n_permutations&#39;, &#39;statistical_test&#39;, ...]\nrnd        = RandomState(MT19937) at 0x7F4FF3AA1340\ny          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1471: AssertionError\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator26-check26-check_estimators_fit_returns_self]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator26-check26-check_estimators_fit_returns_self]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator26-check26-check_estimators_fit_returns_self]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim with correlated noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim with correlated noise]&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim with correlated noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator18-check18-check_pipeline_consistency]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator18-check18-check_pipeline_consistency]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator18-check18-check_pipeline_consistency]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_pipeline_consistency at 0x7f4ffd4d84c0&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_pipeline_consistency&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_pipeline_consistency at 0x7f4ffd4d84c0&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_pipeline_consistency&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_pipeline_consistency at 0x7f4ffd4d8430&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1873: in check_pipeline_consistency\n    estimator.fit(X, y)\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n        pipeline   = Pipeline(steps=[(&#39;baseperturbationcv&#39;,\n                 BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                                    estimators=LinearRegression()))])\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eef680&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eef680&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...4211503],\n       [-0.03023028, -0.1048553 , -0.14200179]]), array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eef680&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1214bb0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1214bb0&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff1215b10&amp;gt;\n        dispatch_timestamp = 1770122608.0192387\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff1215b10&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1214bb0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff1215c60&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1214bb0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff12166b0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1214bb0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff12153f0&amp;gt;\n        args       = (LinearRegression(), array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n ...,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]]), array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n       [ 0.17640523,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\ny_train = array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n       [ 0.17640523,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\n\n\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 944.66it/s]\u001b[A\u001b[A\u0101\r \r\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\n\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator50-check50-check_estimator_get_tags_default_keys]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator50-check50-check_estimator_get_tags_default_keys]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator50-check50-check_estimator_get_tags_default_keys]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator38-check38-check_methods_sample_order_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator38-check38-check_methods_sample_order_invariance]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator38-check38-check_methods_sample_order_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator25-check25-check_parameters_default_constructible]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator25-check25-check_parameters_default_constructible]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator25-check25-check_parameters_default_constructible]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_parameters_default_constructible at 0x7f4ffd4db010&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_parameters_default_constructible&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_parameters_default_constructible at 0x7f4ffd4db010&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_parameters_default_constructible&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3438: in check_parameters_default_constructible\n    estimator = _construct_instance(Estimator)\n        Estimator  = &amp;lt;class &#39;hidimstat.base_perturbation.BasePerturbationCV&#39;&amp;gt;\n        name       = &#39;BasePerturbationCV&#39;\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nEstimator = &amp;lt;class &#39;hidimstat.base_perturbation.BasePerturbationCV&#39;&amp;gt;\n\n    def _construct_instance(Estimator):\n        \&#34;\&#34;\&#34;Construct Estimator instance if possible.\&#34;\&#34;\&#34;\n        required_parameters = getattr(Estimator, \&#34;_required_parameters\&#34;, [])\n        if len(required_parameters):\n            if required_parameters in ([\&#34;estimator\&#34;], [\&#34;base_estimator\&#34;]):\n                # `RANSACRegressor` will raise an error with any model other\n                # than `LinearRegression` if we don&#39;t fix `min_samples` parameter.\n                # For common test, we can enforce using `LinearRegression` that\n                # is the default estimator in `RANSACRegressor` instead of `Ridge`.\n                if issubclass(Estimator, RANSACRegressor):\n                    estimator = Estimator(LinearRegression())\n                elif issubclass(Estimator, RegressorMixin):\n                    estimator = Estimator(Ridge())\n                elif issubclass(Estimator, SelectFromModel):\n                    # Increases coverage because SGDRegressor has partial_fit\n                    estimator = Estimator(SGDRegressor(random_state=0))\n                else:\n                    estimator = Estimator(LogisticRegression(C=1))\n            elif required_parameters in ([\&#34;estimators\&#34;],):\n                # Heterogeneous ensemble classes (i.e. stacking, voting)\n                if issubclass(Estimator, RegressorMixin):\n                    estimator = Estimator(\n                        estimators=[\n                            (\&#34;est1\&#34;, DecisionTreeRegressor(max_depth=3, random_state=0)),\n                            (\&#34;est2\&#34;, DecisionTreeRegressor(max_depth=3, random_state=1)),\n                        ]\n                    )\n                else:\n                    estimator = Estimator(\n                        estimators=[\n                            (\&#34;est1\&#34;, DecisionTreeClassifier(max_depth=3, random_state=0)),\n                            (\&#34;est2\&#34;, DecisionTreeClassifier(max_depth=3, random_state=1)),\n                        ]\n                    )\n            else:\n                msg = (\n                    f\&#34;Can&#39;t instantiate estimator {Estimator.__name__} \&#34;\n                    f\&#34;parameters {required_parameters}\&#34;\n                )\n                # raise additional warning to be shown by pytest\n                warnings.warn(msg, SkipTestWarning)\n                raise SkipTest(msg)\n        else:\n&amp;gt;           estimator = Estimator()\nE           TypeError: BasePerturbationCV.__init__() missing 2 required positional arguments: &#39;estimators&#39; and &#39;cv&#39;\n\nEstimator  = &amp;lt;class &#39;hidimstat.base_perturbation.BasePerturbationCV&#39;&amp;gt;\nrequired_parameters = []\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:463: TypeError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator12-check12-check_no_attributes_set_in_init]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator12-check12-check_no_attributes_set_in_init]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator12-check12-check_no_attributes_set_in_init]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4dab00&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_no_attributes_set_in_init&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4dab00&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_no_attributes_set_in_init&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4daa70&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;BasePerturbationCV&#39;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\n    @ignore_warnings(category=FutureWarning)\n    def check_no_attributes_set_in_init(name, estimator_orig):\n        \&#34;\&#34;\&#34;Check setting during init.\&#34;\&#34;\&#34;\n        try:\n            # Clone fails if the estimator does not store\n            # all parameters as an attribute during init\n            estimator = clone(estimator_orig)\n        except AttributeError:\n            raise AttributeError(\n                f\&#34;Estimator {name} should store all parameters as an attribute during init.\&#34;\n            )\n    \n        if hasattr(type(estimator).__init__, \&#34;deprecated_original\&#34;):\n            return\n    \n        init_params = _get_args(type(estimator).__init__)\n        if _IS_PYPY:\n            # __init__ signature has additional objects in PyPy\n            for key in [\&#34;obj\&#34;]:\n                if key in init_params:\n                    init_params.remove(key)\n        parents_init_params = [\n            param\n            for params_parent in (_get_args(parent) for parent in type(estimator).__mro__)\n            for param in params_parent\n        ]\n    \n        # Test for no setting apart from parameters during init\n        invalid_attr = set(vars(estimator)) - set(init_params) - set(parents_init_params)\n        # Ignore private attributes\n        invalid_attr = set([attr for attr in invalid_attr if not attr.startswith(\&#34;_\&#34;)])\n&amp;gt;       assert not invalid_attr, (\n            \&#34;Estimator %s should not set any attribute apart\&#34;\n            \&#34; from parameters during init. Found attributes %s.\&#34;\n            % (name, sorted(invalid_attr))\n        )\nE       AssertionError: Estimator BasePerturbationCV should not set any attribute apart from parameters during init. Found attributes [&#39;estimators_&#39;, &#39;importance_estimators_&#39;, &#39;importances_&#39;, &#39;pvalues_&#39;, &#39;test_train_frac_&#39;].\n\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ninit_params = [&#39;self&#39;, &#39;estimators&#39;, &#39;cv&#39;, &#39;statistical_test&#39;, &#39;n_jobs&#39;]\ninvalid_attr = {&#39;estimators_&#39;, &#39;importance_estimators_&#39;, &#39;importances_&#39;, &#39;pvalues_&#39;, &#39;test_train_frac_&#39;}\nname       = &#39;BasePerturbationCV&#39;\nparents_init_params = [&#39;estimators&#39;, &#39;cv&#39;, &#39;statistical_test&#39;, &#39;n_jobs&#39;]\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3308: AssertionError\n--------------------------- Captured stderr teardown ---------------------------\n\n\n\u001b[A\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator22-check22-check_estimator_sparse_matrix]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator22-check22-check_estimator_sparse_matrix]&#34;, &#34;duration&#34;: &#34;19 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator22-check22-check_estimator_sparse_matrix]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;19 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &#39;BasePerturbationCV&#39;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nsparse_type = &amp;lt;class &#39;scipy.sparse._csr.csr_matrix&#39;&amp;gt;\n\n    def _check_estimator_sparse_container(name, estimator_orig, sparse_type):\n        rng = np.random.RandomState(0)\n        X = rng.uniform(size=(40, 3))\n        X[X &amp;lt; 0.8] = 0\n        X = _enforce_estimator_tags_X(estimator_orig, X)\n        y = (4 * rng.uniform(size=40)).astype(int)\n        # catch deprecation warnings\n        with ignore_warnings(category=FutureWarning):\n            estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n        tags = _safe_tags(estimator_orig)\n        for matrix_format, X in _generate_sparse_data(sparse_type(X)):\n            # catch deprecation warnings\n            with ignore_warnings(category=FutureWarning):\n                estimator = clone(estimator_orig)\n                if name in [\&#34;Scaler\&#34;, \&#34;StandardScaler\&#34;]:\n                    estimator.set_params(with_mean=False)\n            # fit and predict\n            if \&#34;64\&#34; in matrix_format:\n                err_msg = (\n                    f\&#34;Estimator {name} doesn&#39;t seem to support {matrix_format} \&#34;\n                    \&#34;matrix, and is not failing gracefully, e.g. by using \&#34;\n                    \&#34;check_array(X, accept_large_sparse=False).\&#34;\n                )\n            else:\n                err_msg = (\n                    f\&#34;Estimator {name} doesn&#39;t seem to fail gracefully on sparse \&#34;\n                    \&#34;data: error message should state explicitly that sparse \&#34;\n                    \&#34;input is not supported if this is not the case, e.g. by using \&#34;\n                    \&#34;check_array(X, accept_sparse=False).\&#34;\n                )\n            with raises(\n                (TypeError, ValueError),\n                match=[\&#34;sparse\&#34;, \&#34;Sparse\&#34;],\n                may_pass=True,\n                err_msg=err_msg,\n            ):\n                with ignore_warnings(category=FutureWarning):\n&amp;gt;                   estimator.fit(X, y)\n\nX          = &amp;lt;40x3 sparse matrix of type &#39;&amp;lt;class &#39;numpy.float64&#39;&amp;gt;&#39;\n\twith 21 stored elements in Compressed Sparse Row format&amp;gt;\nerr_msg    = \&#34;Estimator BasePerturbationCV doesn&#39;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).\&#34;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nmatrix_format = &#39;csr&#39;\nname       = &#39;BasePerturbationCV&#39;\nrng        = RandomState(MT19937) at 0x7F4FF3AA1340\nsparse_type = &amp;lt;class &#39;scipy.sparse._csr.csr_matrix&#39;&amp;gt;\ntags       = {&#39;X_types&#39;: [&#39;2darray&#39;], &#39;_skip_test&#39;: False, &#39;_xfail_checks&#39;: False, &#39;allow_nan&#39;: False, ...}\ny          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1069: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = &amp;lt;40x3 sparse matrix of type &#39;&amp;lt;class &#39;numpy.float64&#39;&amp;gt;&#39;\n\twith 21 stored elements in Compressed Sparse Row format&amp;gt;\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0edfae0&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0edfae0&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...d elements in Compressed Sparse Row format&amp;gt;, array([3, 1, 1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0edfae0&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fcca00&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fcca00&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff0fcd480&amp;gt;\n        dispatch_timestamp = 1770122609.1167731\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff0fcd480&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fcca00&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff0fcd870&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fcca00&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff0fce560&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fcca00&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff0fcfe20&amp;gt;\n        args       = (LinearRegression(), &amp;lt;20x3 sparse matrix of type &#39;&amp;lt;class &#39;numpy.float64&#39;&amp;gt;&#39;\n\twith 12 stored elements in Compressed Sparse Row format&amp;gt;, array([3, 1, 1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = &amp;lt;20x3 sparse matrix of type &#39;&amp;lt;class &#39;numpy.float64&#39;&amp;gt;&#39;\n\twith 12 stored elements in Compressed Sparse Row format&amp;gt;\ny_train = array([3, 1, 1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = &amp;lt;20x3 sparse matrix of type &#39;&amp;lt;class &#39;numpy.float64&#39;&amp;gt;&#39;\n\twith 12 stored elements in Compressed Sparse Row format&amp;gt;\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([3, 1, 1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimator_sparse_matrix at 0x7f4ffd4cab90&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_estimator_sparse_matrix&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimator_sparse_matrix at 0x7f4ffd4cab90&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_estimator_sparse_matrix&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1086: in check_estimator_sparse_matrix\n    _check_estimator_sparse_container(name, estimator_orig, sparse.csr_matrix)\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1062: in _check_estimator_sparse_container\n    with raises(\n        X          = &amp;lt;40x3 sparse matrix of type &#39;&amp;lt;class &#39;numpy.float64&#39;&amp;gt;&#39;\n\twith 21 stored elements in Compressed Sparse Row format&amp;gt;\n        err_msg    = \&#34;Estimator BasePerturbationCV doesn&#39;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).\&#34;\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        matrix_format = &#39;csr&#39;\n        name       = &#39;BasePerturbationCV&#39;\n        rng        = RandomState(MT19937) at 0x7F4FF3AA1340\n        sparse_type = &amp;lt;class &#39;scipy.sparse._csr.csr_matrix&#39;&amp;gt;\n        tags       = {&#39;X_types&#39;: [&#39;2darray&#39;], &#39;_skip_test&#39;: False, &#39;_xfail_checks&#39;: False, &#39;allow_nan&#39;: False, ...}\n        y          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4ff0fcde10&amp;gt;\nexc_type = &amp;lt;class &#39;NotImplementedError&#39;&amp;gt;, exc_value = NotImplementedError()\n_ = &amp;lt;traceback object at 0x7f4ff3dffc80&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f\&#34;Did not raise: {self.expected_exc_types}\&#34;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n&amp;gt;               raise AssertionError(self.err_msg) from exc_value\nE               AssertionError: Estimator BasePerturbationCV doesn&#39;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).\n\n_          = &amp;lt;traceback object at 0x7f4ff3dffc80&amp;gt;\nexc_type   = &amp;lt;class &#39;NotImplementedError&#39;&amp;gt;\nexc_value  = NotImplementedError()\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4ff0fcde10&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:915: AssertionError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 163.29it/s]\n\u0101\r \r\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator32-check32-check_estimator_sparse_array]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator32-check32-check_estimator_sparse_array]&#34;, &#34;duration&#34;: &#34;42 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator32-check32-check_estimator_sparse_array]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;42 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator25-check25-check_fit_score_takes_y]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator25-check25-check_fit_score_takes_y]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator25-check25-check_fit_score_takes_y]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_fit[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_fit[default data]&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIClass::test_fit[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator20-check20-check_estimators_overwrite_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator20-check20-check_estimators_overwrite_params]&#34;, &#34;duration&#34;: &#34;12 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator20-check20-check_estimators_overwrite_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;12 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4ffd4da9e0&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_estimators_overwrite_params&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4ffd4da9e0&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_estimators_overwrite_params&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_overwrite_params at 0x7f4ffd4da950&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3257: in check_estimators_overwrite_params\n    estimator.fit(X, y)\n        X          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n        original_params = {&#39;cv&#39;: KFold(n_splits=2, random_state=None, shuffle=False), &#39;estimators&#39;: LinearRegression(), &#39;estimators__copy_X&#39;: True, &#39;estimators__fit_intercept&#39;: True, ...}\n        params     = {&#39;cv&#39;: KFold(n_splits=2, random_state=None, shuffle=False), &#39;estimators&#39;: LinearRegression(), &#39;estimators__copy_X&#39;: True, &#39;estimators__fit_intercept&#39;: True, ...}\n        y          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff3a48b30&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff3a48b30&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]]), array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff3a48b30&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1214bb0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1214bb0&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff1215450&amp;gt;\n        dispatch_timestamp = 1770122609.9963067\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff1215450&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1214bb0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff1217040&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1214bb0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff1216bc0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1214bb0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff12166b0&amp;gt;\n        args       = (LinearRegression(), array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.556...537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]]), array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.55670201],\n       [ 2.47...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\ny_train = array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.55670201],\n       [ 2.47...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\n\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 332.02it/s]\u001b[A\u0101\r \r\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator4-check4-check_complex_data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator4-check4-check_complex_data]&#34;, &#34;duration&#34;: &#34;9 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator4-check4-check_complex_data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;9 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator0-check0-check_estimators_dtypes]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator0-check0-check_estimators_dtypes]&#34;, &#34;duration&#34;: &#34;16 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator0-check0-check_estimators_dtypes]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;16 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator52-check52-check_get_params_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator52-check52-check_get_params_invariance]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator52-check52-check_get_params_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator15-check15-check_estimators_fit_returns_self]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator15-check15-check_estimators_fit_returns_self]&#34;, &#34;duration&#34;: &#34;15 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator15-check15-check_estimators_fit_returns_self]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;15 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_fit_returns_self at 0x7f4ffd4d9d80&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_estimators_fit_returns_self&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_fit_returns_self at 0x7f4ffd4d9d80&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_estimators_fit_returns_self&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_fit_returns_self at 0x7f4ffd4d9cf0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2871: in check_estimators_fit_returns_self\n    assert estimator.fit(X, y) is estimator\n        X          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n        readonly_memmap = False\n        y          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0edea40&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0edea40&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]]), array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0edea40&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0efa290&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0efa290&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff0efa830&amp;gt;\n        dispatch_timestamp = 1770122610.485372\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff0efa830&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0efa290&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff0ef99c0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0efa290&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff0efa9b0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0efa290&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff0ef9150&amp;gt;\n        args       = (LinearRegression(), array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.556...537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]]), array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.55670201],\n       [ 2.47...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\ny_train = array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.55670201],\n       [ 2.47...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\n\n\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 348.28it/s]\u001b[A\u001b[A\u0101\r \r\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\n\n\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator36-check36-check_estimator_get_tags_default_keys]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator36-check36-check_estimator_get_tags_default_keys]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator36-check36-check_estimator_get_tags_default_keys]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator33-check33-check_n_features_in]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator33-check33-check_n_features_in]&#34;, &#34;duration&#34;: &#34;9 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator33-check33-check_n_features_in]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;9 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_n_features_in at 0x7f4ffd4dbac0&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_n_features_in&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_n_features_in at 0x7f4ffd4dbac0&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_n_features_in&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3950: in check_n_features_in\n    estimator.fit(X, y)\n        X          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        n_samples  = 100\n        name       = &#39;BasePerturbationCV&#39;\n        rng        = RandomState(MT19937) at 0x7F4FF3AA1040\n        y          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff14846d0&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff14846d0&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu..., 1, 0, 1, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n       1, 1, 1, 1, 0, 0])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff14846d0&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff97def20&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff97def20&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff97dc670&amp;gt;\n        dispatch_timestamp = 1770122611.1003807\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff97dc670&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff97def20&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff97dcbb0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff97def20&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff97dcca0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff97def20&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff97defe0&amp;gt;\n        args       = (LinearRegression(), array([[101.8831507 ,  98.65224094],\n       [ 98.729515  , 100.96939671],\n       [ 98.82687659, 1..., 0, 0, 1, 0, 1, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n       1, 1, 1, 1, 0, 0]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[101.8831507 ,  98.65224094],\n       [ 98.729515  , 100.96939671],\n       [ 98.82687659, 101.94362119],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\ny_train = array([1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n       1, 1, 1, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[101.8831507 ,  98.65224094],\n       [ 98.729515  , 100.96939671],\n       [ 98.82687659, 101.94362119],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n       1, 1, 1, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A\n\n\n\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 331.30it/s]\u001b[A\u001b[A\u001b[A\u0101\r \r\n\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator11-check11-check_estimators_pickle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator11-check11-check_estimators_pickle]&#34;, &#34;duration&#34;: &#34;16 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator11-check11-check_estimators_pickle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;16 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator3-check3-check_estimators_fit_returns_self]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator3-check3-check_estimators_fit_returns_self]&#34;, &#34;duration&#34;: &#34;11 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator3-check3-check_estimators_fit_returns_self]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;11 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator22-check22-check_fit1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator22-check22-check_fit1d]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator22-check22-check_fit1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator7-check7-check_estimators_nan_inf]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator7-check7-check_estimators_nan_inf]&#34;, &#34;duration&#34;: &#34;12 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator7-check7-check_estimators_nan_inf]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;12 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator24-check24-check_estimators_pickle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator24-check24-check_estimators_pickle]&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator24-check24-check_estimators_pickle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_pickle at 0x7f4ffd4d8c10&amp;gt;, &#39;BasePerturbationCV&#39;, readonly_memmap=True)\nname = &#39;check_estimators_pickle&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_pickle at 0x7f4ffd4d8c10&amp;gt;, &#39;BasePerturbationCV&#39;, readonly_memmap=True)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_estimators_pickle&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_pickle at 0x7f4ffd4d8b80&amp;gt;\n        kwargs     = {&#39;readonly_memmap&#39;: True}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2089: in check_estimators_pickle\n    estimator.fit(X, y)\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        check_methods = [&#39;predict&#39;, &#39;transform&#39;, &#39;decision_function&#39;, &#39;predict_proba&#39;]\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n        readonly_memmap = True\n        tags       = {&#39;X_types&#39;: [&#39;2darray&#39;], &#39;_skip_test&#39;: False, &#39;_xfail_checks&#39;: False, &#39;allow_nan&#39;: False, ...}\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eec270&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eec270&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...4211503],\n       [-0.03023028, -0.1048553 , -0.14200179]]), array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eec270&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fc6380&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fc6380&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff0fc60b0&amp;gt;\n        dispatch_timestamp = 1770122611.5979125\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff0fc60b0&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fc6380&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff0fc4970&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fc6380&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff0fc7640&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fc6380&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff0fc7940&amp;gt;\n        args       = (LinearRegression(), array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n ...,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]]), array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n       [ 0.17640523,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\ny_train = array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n       [ 0.17640523,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\n\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 584.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u0101\r \r\n\n\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\n\n\u001b[A\u001b[A\n\n\n\u001b[A\u001b[A\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator20-check20-check_dict_unchanged]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator20-check20-check_dict_unchanged]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator20-check20-check_dict_unchanged]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator46-check46-check_fit1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator46-check46-check_fit1d]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator46-check46-check_fit1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator21-check21-check_fit_idempotent]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator21-check21-check_fit_idempotent]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator21-check21-check_fit_idempotent]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator47-check47-check_fit2d_predict1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator47-check47-check_fit2d_predict1d]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator47-check47-check_fit2d_predict1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator51-check51-check_fit2d_1sample]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator51-check51-check_fit2d_1sample]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator51-check51-check_fit2d_1sample]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\n\n\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator34-check34-check_estimators_pickle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator34-check34-check_estimators_pickle]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator34-check34-check_estimators_pickle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator35-check35-check_estimators_pickle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator35-check35-check_estimators_pickle]&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator35-check35-check_estimators_pickle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator1-check1-check_fit_score_takes_y]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator1-check1-check_fit_score_takes_y]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator1-check1-check_fit_score_takes_y]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator15-check15-check_methods_subset_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator15-check15-check_methods_subset_invariance]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator15-check15-check_methods_subset_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator18-check18-check_get_params_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator18-check18-check_get_params_invariance]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator18-check18-check_get_params_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator48-check48-check_complex_data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator48-check48-check_complex_data]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator48-check48-check_complex_data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\n\n\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator24-check24-check_estimators_dtypes]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator24-check24-check_estimators_dtypes]&#34;, &#34;duration&#34;: &#34;10 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator24-check24-check_estimators_dtypes]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;10 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator43-check43-check_set_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator43-check43-check_set_params]&#34;, &#34;duration&#34;: &#34;28 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator43-check43-check_set_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;28 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator28-check28-check_fit2d_1feature]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator28-check28-check_fit2d_1feature]&#34;, &#34;duration&#34;: &#34;15 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator28-check28-check_fit2d_1feature]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;15 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_fit2d_1feature at 0x7f4ffd4cbd00&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_fit2d_1feature&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit2d_1feature at 0x7f4ffd4cbd00&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_fit2d_1feature&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_fit2d_1feature at 0x7f4ffd4cbc70&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1673: in check_fit2d_1feature\n    estimator.fit(X, y)\n        X          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        msgs       = [&#39;1 feature\\\\(s\\\\)&#39;, &#39;n_features = 1&#39;, &#39;n_features=1&#39;]\n        name       = &#39;BasePerturbationCV&#39;\n        rnd        = RandomState(MT19937) at 0x7F4FF3AA1640\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eecf20&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eecf20&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...4],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]]), array([1, 1, 2, 2, 1])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eecf20&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f5015cbb8b0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f5015cbb8b0&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f5015cba590&amp;gt;\n        dispatch_timestamp = 1770122612.354209\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f5015cba590&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f5015cbb8b0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f5015cbb610&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f5015cbb8b0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f5015cbac50&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f5015cbb8b0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f5015cba620&amp;gt;\n        args       = (LinearRegression(), array([[1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]]), array([1, 1, 2, 2, 1]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\ny_train = array([1, 1, 2, 2, 1])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 1, 2, 2, 1])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\n\n\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 300.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u0101\r \r\n\n\n\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator34-check34-check_fit2d_predict1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator34-check34-check_fit2d_predict1d]&#34;, &#34;duration&#34;: &#34;11 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator34-check34-check_fit2d_predict1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;11 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_fit2d_predict1d at 0x7f4ffd4cb7f0&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_fit2d_predict1d&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit2d_predict1d at 0x7f4ffd4cb7f0&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_fit2d_predict1d&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_fit2d_predict1d at 0x7f4ffd4cb760&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1496: in check_fit2d_predict1d\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n        rnd        = RandomState(MT19937) at 0x7F4FF3AA1840\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eec740&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eec740&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...7, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]]), array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eec740&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0ef99f0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0ef99f0&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff0efa830&amp;gt;\n        dispatch_timestamp = 1770122612.9775896\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff0efa830&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0ef99f0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff0ef9750&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0ef99f0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff0efa9b0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0ef99f0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff0efa1d0&amp;gt;\n        args       = (LinearRegression(), array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       ...2663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]]), array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\ny_train = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\n\n\n\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 335.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u0101\r \r\n\n\n\n\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator28-check28-check_complex_data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator28-check28-check_complex_data]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator28-check28-check_complex_data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator42-check42-check_get_params_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator42-check42-check_get_params_invariance]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator42-check42-check_get_params_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator7-check7-check_dtype_object]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator7-check7-check_dtype_object]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator7-check7-check_dtype_object]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbation(estimator=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_dtype_object at 0x7f4ffd4cb370&amp;gt;, &#39;BasePerturbation&#39;)\nname = &#39;check_dtype_object&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_dtype_object at 0x7f4ffd4cb370&amp;gt;, &#39;BasePerturbation&#39;)\nestimator  = BasePerturbation(estimator=LinearRegression())\nname       = &#39;check_dtype_object&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbation&#39;, BasePerturbation(estimator=LinearRegression()))\n        fn         = &amp;lt;function check_dtype_object at 0x7f4ffd4cb2e0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1355: in check_dtype_object\n    with raises(TypeError, match=msg):\n        X          = array([[{&#39;foo&#39;: &#39;bar&#39;}, 0.7151893663724195, 0.6027633760716439,\n        0.5448831829968969, 0.4236547993389047, 0.6458...4736,\n        0.3553688484719296, 0.3567068904025429, 0.01632850268370789,\n        0.18523232523618394]], dtype=object)\n        estimator  = BasePerturbation(estimator=LinearRegression(),\n                 features_groups={0: [0], 1: [1], 2: [2], 3: [3], 4: [4],\n                                  5: [5], 6: [6], 7: [7], 8: [8], 9: [9]})\n        estimator_orig = BasePerturbation(estimator=LinearRegression())\n        msg        = &#39;argument must be .* string.* number&#39;\n        name       = &#39;BasePerturbation&#39;\n        rng        = RandomState(MT19937) at 0x7F4FF3AA1340\n        tags       = {&#39;X_types&#39;: [&#39;2darray&#39;], &#39;_skip_test&#39;: False, &#39;_xfail_checks&#39;: False, &#39;allow_nan&#39;: False, ...}\n        y          = array([2, 3, 3, 1, 1, 2, 0, 3, 1, 1, 2, 1, 2, 2, 3, 0, 2, 2, 0, 1, 1, 3,\n       2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4ff946ce20&amp;gt;\nexc_type = None, exc_value = None, _ = None\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f\&#34;Did not raise: {self.expected_exc_types}\&#34;\n&amp;gt;               raise AssertionError(err_msg)\nE               AssertionError: Did not raise: [&amp;lt;class &#39;TypeError&#39;&amp;gt;]\n\n_          = None\nerr_msg    = \&#34;Did not raise: [&amp;lt;class &#39;TypeError&#39;&amp;gt;]\&#34;\nexc_type   = None\nexc_value  = None\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4ff946ce20&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:908: AssertionError\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n--------------------------- Captured stderr teardown ---------------------------\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator30-check30-check_dont_overwrite_parameters]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator30-check30-check_dont_overwrite_parameters]&#34;, &#34;duration&#34;: &#34;12 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator30-check30-check_dont_overwrite_parameters]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;12 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_dont_overwrite_parameters at 0x7f4ffd4cb6d0&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_dont_overwrite_parameters&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_dont_overwrite_parameters at 0x7f4ffd4cb6d0&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_dont_overwrite_parameters&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_dont_overwrite_parameters at 0x7f4ffd4cb640&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1443: in check_dont_overwrite_parameters\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        dict_before_fit = {&#39;cv&#39;: KFold(n_splits=2, random_state=None, shuffle=False), &#39;estimators&#39;: LinearRegression(), &#39;estimators_&#39;: None, &#39;importance_estimators_&#39;: None, ...}\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n        rnd        = RandomState(MT19937) at 0x7F4FF3AA1640\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1486ab0&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1486ab0&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...7, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]]), array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1486ab0&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fcdf60&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fcdf60&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff0fcf9a0&amp;gt;\n        dispatch_timestamp = 1770122613.8736513\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff0fcf9a0&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fcdf60&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff0fcc340&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fcdf60&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff0fcded0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0fcdf60&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff0fcfe80&amp;gt;\n        args       = (LinearRegression(), array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       ...2663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]]), array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\ny_train = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 331.76it/s]\n\u0101\r \r\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator17-check17-check_fit2d_1feature]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator17-check17-check_fit2d_1feature]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator17-check17-check_fit2d_1feature]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator0-check0-check_no_attributes_set_in_init]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator0-check0-check_no_attributes_set_in_init]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator0-check0-check_no_attributes_set_in_init]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbation(estimator=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4dab00&amp;gt;, &#39;BasePerturbation&#39;)\nname = &#39;check_no_attributes_set_in_init&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4dab00&amp;gt;, &#39;BasePerturbation&#39;)\nestimator  = BasePerturbation(estimator=LinearRegression())\nname       = &#39;check_no_attributes_set_in_init&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbation&#39;, BasePerturbation(estimator=LinearRegression()))\n        fn         = &amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4daa70&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;BasePerturbation&#39;\nestimator_orig = BasePerturbation(estimator=LinearRegression())\n\n    @ignore_warnings(category=FutureWarning)\n    def check_no_attributes_set_in_init(name, estimator_orig):\n        \&#34;\&#34;\&#34;Check setting during init.\&#34;\&#34;\&#34;\n        try:\n            # Clone fails if the estimator does not store\n            # all parameters as an attribute during init\n            estimator = clone(estimator_orig)\n        except AttributeError:\n            raise AttributeError(\n                f\&#34;Estimator {name} should store all parameters as an attribute during init.\&#34;\n            )\n    \n        if hasattr(type(estimator).__init__, \&#34;deprecated_original\&#34;):\n            return\n    \n        init_params = _get_args(type(estimator).__init__)\n        if _IS_PYPY:\n            # __init__ signature has additional objects in PyPy\n            for key in [\&#34;obj\&#34;]:\n                if key in init_params:\n                    init_params.remove(key)\n        parents_init_params = [\n            param\n            for params_parent in (_get_args(parent) for parent in type(estimator).__mro__)\n            for param in params_parent\n        ]\n    \n        # Test for no setting apart from parameters during init\n        invalid_attr = set(vars(estimator)) - set(init_params) - set(parents_init_params)\n        # Ignore private attributes\n        invalid_attr = set([attr for attr in invalid_attr if not attr.startswith(\&#34;_\&#34;)])\n&amp;gt;       assert not invalid_attr, (\n            \&#34;Estimator %s should not set any attribute apart\&#34;\n            \&#34; from parameters during init. Found attributes %s.\&#34;\n            % (name, sorted(invalid_attr))\n        )\nE       AssertionError: Estimator BasePerturbation should not set any attribute apart from parameters during init. Found attributes [&#39;importances_&#39;, &#39;loss_&#39;, &#39;loss_reference_&#39;, &#39;n_features_groups_&#39;, &#39;pvalues_&#39;].\n\nestimator  = BasePerturbation(estimator=LinearRegression())\nestimator_orig = BasePerturbation(estimator=LinearRegression())\ninit_params = [&#39;self&#39;, &#39;estimator&#39;, &#39;method&#39;, &#39;loss&#39;, &#39;n_permutations&#39;, &#39;statistical_test&#39;, ...]\ninvalid_attr = {&#39;importances_&#39;, &#39;loss_&#39;, &#39;loss_reference_&#39;, &#39;n_features_groups_&#39;, &#39;pvalues_&#39;}\nname       = &#39;BasePerturbation&#39;\nparents_init_params = [&#39;estimator&#39;, &#39;method&#39;, &#39;loss&#39;, &#39;n_permutations&#39;, &#39;statistical_test&#39;, &#39;features_groups&#39;, ...]\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3308: AssertionError\n--------------------------- Captured stderr teardown ---------------------------\n\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator2-check2-check_estimators_fit_returns_self]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator2-check2-check_estimators_fit_returns_self]&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator2-check2-check_estimators_fit_returns_self]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator13-check13-check_parameters_default_constructible]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator13-check13-check_parameters_default_constructible]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator13-check13-check_parameters_default_constructible]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator10-check10-check_estimators_pickle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator10-check10-check_estimators_pickle]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator10-check10-check_estimators_pickle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator23-check23-check_fit2d_predict1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator23-check23-check_fit2d_predict1d]&#34;, &#34;duration&#34;: &#34;9 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator23-check23-check_fit2d_predict1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;9 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator41-check41-check_fit2d_1feature]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator41-check41-check_fit2d_1feature]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator41-check41-check_fit2d_1feature]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator19-check19-check_set_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator19-check19-check_set_params]&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator19-check19-check_set_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator13-check13-check_estimators_dtypes]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator13-check13-check_estimators_dtypes]&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator13-check13-check_estimators_dtypes]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_dtypes at 0x7f4ffd4d8700&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_estimators_dtypes&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_dtypes at 0x7f4ffd4d8700&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_estimators_dtypes&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_dtypes at 0x7f4ffd4d8670&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1933: in check_estimators_dtypes\n    estimator.fit(X_train, y)\n        X_train    = array([[1.6464405 , 2.145568  , 1.80829   , 1.6346495 , 1.2709644 ],\n       [1.9376824 , 1.3127615 , 2.675319  , 2.890...6 , 2.1489816 , 0.8682183 ],\n       [0.5495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32)\n        X_train_32 = array([[1.6464405 , 2.145568  , 1.80829   , 1.6346495 , 1.2709644 ],\n       [1.9376824 , 1.3127615 , 2.675319  , 2.890...6 , 2.1489816 , 0.8682183 ],\n       [0.5495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32)\n        X_train_64 = array([[1.64644051, 2.14556789, 1.80829   , 1.63464952, 1.27096438],\n       [1.93768239, 1.31276155, 2.67531896, 2.890... 2.00223112, 0.39539361, 2.14898157, 0.8682183 ],\n       [0.54957408, 1.75953877, 0.06032264, 2.48682022, 0.01408643]])\n        X_train_int_32 = array([[1, 2, 1, 1, 1],\n       [1, 1, 2, 2, 1],\n       [2, 1, 1, 2, 0],\n       [0, 0, 2, 2, 2],\n       [2, 2, 1, 2, 0]...0, 0, 0],\n       [0, 1, 0, 2, 1],\n       [0, 1, 0, 1, 2],\n       [0, 2, 0, 2, 0],\n       [0, 1, 0, 2, 0]], dtype=int32)\n        X_train_int_64 = array([[1, 2, 1, 1, 1],\n       [1, 1, 2, 2, 1],\n       [2, 1, 1, 2, 0],\n       [0, 0, 2, 2, 2],\n       [2, 2, 1, 2, 0]...      [0, 0, 0, 0, 0],\n       [0, 1, 0, 2, 1],\n       [0, 1, 0, 1, 2],\n       [0, 2, 0, 2, 0],\n       [0, 1, 0, 2, 0]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        methods    = [&#39;predict&#39;, &#39;transform&#39;, &#39;decision_function&#39;, &#39;predict_proba&#39;]\n        name       = &#39;BasePerturbationCV&#39;\n        rnd        = RandomState(MT19937) at 0x7F4FF3AA2040\n        y          = array([1, 1, 2, 0, 2, 1, 0, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.6464405 , 2.145568  , 1.80829   , 1.6346495 , 1.2709644 ],\n       [1.9376824 , 1.3127615 , 2.675319  , 2.890...6 , 2.1489816 , 0.8682183 ],\n       [0.5495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32)\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 2, 0, 2, 1, 0, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0edfae0&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0edfae0&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu... , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32), array([1, 0, 0, 1, 2, 0, 0, 0, 0, 0])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0edfae0&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff11a9990&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff11a9990&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff11a98a0&amp;gt;\n        dispatch_timestamp = 1770122614.782942\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff11a98a0&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff11a9990&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff11a8490&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff11a9990&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff11a87c0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff11a9990&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff11a9690&amp;gt;\n        args       = (LinearRegression(), array([[1.7105902 , 1.3158046 , 2.9651215 , 0.30613443, 0.6266303 ],\n       [0.48392853, 1.959324...495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32), array([1, 0, 0, 1, 2, 0, 0, 0, 0, 0]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[1.7105902 , 1.3158046 , 2.9651215 , 0.30613443, 0.6266303 ],\n       [0.48392853, 1.9593248 , 0.7598748 , 1.398...6 , 2.1489816 , 0.8682183 ],\n       [0.5495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32)\ny_train = array([1, 0, 0, 1, 2, 0, 0, 0, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[1.7105902 , 1.3158046 , 2.9651215 , 0.30613443, 0.6266303 ],\n       [0.48392853, 1.9593248 , 0.7598748 , 1.398...6 , 2.1489816 , 0.8682183 ],\n       [0.5495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32)\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 0, 0, 1, 2, 0, 0, 0, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 220.48it/s]\n\u0101\r \r\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator14-check14-check_fit_score_takes_y]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator14-check14-check_fit_score_takes_y]&#34;, &#34;duration&#34;: &#34;10 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator14-check14-check_fit_score_takes_y]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;10 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_fit_score_takes_y at 0x7f4ffd4d85e0&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_fit_score_takes_y&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_score_takes_y at 0x7f4ffd4d85e0&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_fit_score_takes_y&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_fit_score_takes_y at 0x7f4ffd4d8550&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1904: in check_fit_score_takes_y\n    func(X, y)\n        X          = array([[0.5488135 , 0.71518937, 0.60276338],\n       [0.54488318, 0.4236548 , 0.64589411],\n       [0.43758721, 0.891773...99, 0.0641475 , 0.69247212],\n       [0.56660145, 0.26538949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        func       = &amp;lt;bound method BasePerturbationCV.fit of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        func_name  = &#39;fit&#39;\n        funcs      = [&#39;fit&#39;, &#39;score&#39;, &#39;partial_fit&#39;, &#39;fit_predict&#39;, &#39;fit_transform&#39;]\n        n_samples  = 30\n        name       = &#39;BasePerturbationCV&#39;\n        rnd        = RandomState(MT19937) at 0x7F4FF3AA2140\n        y          = array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n       1, 2, 0, 1, 2, 0, 1, 2])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[0.5488135 , 0.71518937, 0.60276338],\n       [0.54488318, 0.4236548 , 0.64589411],\n       [0.43758721, 0.891773...99, 0.0641475 , 0.69247212],\n       [0.56660145, 0.26538949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n       1, 2, 0, 1, 2, 0, 1, 2])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eedd20&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eedd20&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]]), array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff0eedd20&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff144bcd0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff144bcd0&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff144bd90&amp;gt;\n        dispatch_timestamp = 1770122615.1595178\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff144bd90&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff144bcd0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff1448580&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff144bcd0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff1449420&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff144bcd0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff144b430&amp;gt;\n        args       = (LinearRegression(), array([[0.67063787, 0.21038256, 0.1289263 ],\n       [0.31542835, 0.36371077, 0.57019677],\n       ...8949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]]), array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.67063787, 0.21038256, 0.1289263 ],\n       [0.31542835, 0.36371077, 0.57019677],\n       [0.43860151, 0.988373...99, 0.0641475 , 0.69247212],\n       [0.56660145, 0.26538949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]])\ny_train = array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.67063787, 0.21038256, 0.1289263 ],\n       [0.31542835, 0.36371077, 0.57019677],\n       [0.43860151, 0.988373...99, 0.0641475 , 0.69247212],\n       [0.56660145, 0.26538949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\n\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 405.80it/s]\u001b[A\u0101\r \r\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator17-check17-check_dtype_object]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator17-check17-check_dtype_object]&#34;, &#34;duration&#34;: &#34;11 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator17-check17-check_dtype_object]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;11 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_dtype_object at 0x7f4ffd4cb370&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_dtype_object&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_dtype_object at 0x7f4ffd4cb370&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_dtype_object&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_dtype_object at 0x7f4ffd4cb2e0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1339: in check_dtype_object\n    estimator.fit(X, y)\n        X          = array([[0.5488135039273248, 0.7151893663724195, 0.6027633760716439,\n        0.5448831829968969, 0.4236547993389047, 0....4736,\n        0.3553688484719296, 0.3567068904025429, 0.01632850268370789,\n        0.18523232523618394]], dtype=object)\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n        rng        = RandomState(MT19937) at 0x7F4FF3AA2240\n        tags       = {&#39;X_types&#39;: [&#39;2darray&#39;], &#39;_skip_test&#39;: False, &#39;_xfail_checks&#39;: False, &#39;allow_nan&#39;: False, ...}\n        y          = array([2, 3, 3, 1, 1, 2, 0, 3, 1, 1, 2, 1, 2, 2, 3, 0, 2, 2, 0, 1, 1, 3,\n       2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[0.5488135039273248, 0.7151893663724195, 0.6027633760716439,\n        0.5448831829968969, 0.4236547993389047, 0....4736,\n        0.3553688484719296, 0.3567068904025429, 0.01632850268370789,\n        0.18523232523618394]], dtype=object)\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([2, 3, 3, 1, 1, 2, 0, 3, 1, 1, 2, 1, 2, 2, 3, 0, 2, 2, 0, 1, 1, 3,\n       2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1484350&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1484350&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...       0.18523232523618394]], dtype=object), array([1, 3, 2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff1484350&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff19fe380&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff19fe380&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff19fdb10&amp;gt;\n        dispatch_timestamp = 1770122615.7708912\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff19fdb10&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff19fe380&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff19fe920&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff19fe380&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff19ff460&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff19fe380&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff19fd2d0&amp;gt;\n        args       = (LinearRegression(), array([[0.3117958819941026, 0.6963434888154595, 0.3777518392924809,\n        0.1796036775596348, 0...789,\n        0.18523232523618394]], dtype=object), array([1, 3, 2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.3117958819941026, 0.6963434888154595, 0.3777518392924809,\n        0.1796036775596348, 0.02467872839133123, 0...4736,\n        0.3553688484719296, 0.3567068904025429, 0.01632850268370789,\n        0.18523232523618394]], dtype=object)\ny_train = array([1, 3, 2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.3117958819941026, 0.6963434888154595, 0.3777518392924809,\n        0.1796036775596348, 0.02467872839133123, 0...4736,\n        0.3553688484719296, 0.3567068904025429, 0.01632850268370789,\n        0.18523232523618394]], dtype=object)\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 3, 2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\n\n\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 325.14it/s]\u001b[A\u001b[A\u0101\r \r\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\n\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator33-check33-check_estimator_sparse_matrix]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator33-check33-check_estimator_sparse_matrix]&#34;, &#34;duration&#34;: &#34;45 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator33-check33-check_estimator_sparse_matrix]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;45 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator39-check39-check_methods_subset_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator39-check39-check_methods_subset_invariance]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator39-check39-check_methods_subset_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator30-check30-check_pipeline_consistency]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator30-check30-check_pipeline_consistency]&#34;, &#34;duration&#34;: &#34;10 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator30-check30-check_pipeline_consistency]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;10 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator21-check21-check_estimator_sparse_array]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator21-check21-check_estimator_sparse_array]&#34;, &#34;duration&#34;: &#34;19 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator21-check21-check_estimator_sparse_array]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;19 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &#39;BasePerturbationCV&#39;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nsparse_type = &amp;lt;class &#39;scipy.sparse._arrays.csr_array&#39;&amp;gt;\n\n    def _check_estimator_sparse_container(name, estimator_orig, sparse_type):\n        rng = np.random.RandomState(0)\n        X = rng.uniform(size=(40, 3))\n        X[X &amp;lt; 0.8] = 0\n        X = _enforce_estimator_tags_X(estimator_orig, X)\n        y = (4 * rng.uniform(size=40)).astype(int)\n        # catch deprecation warnings\n        with ignore_warnings(category=FutureWarning):\n            estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n        tags = _safe_tags(estimator_orig)\n        for matrix_format, X in _generate_sparse_data(sparse_type(X)):\n            # catch deprecation warnings\n            with ignore_warnings(category=FutureWarning):\n                estimator = clone(estimator_orig)\n                if name in [\&#34;Scaler\&#34;, \&#34;StandardScaler\&#34;]:\n                    estimator.set_params(with_mean=False)\n            # fit and predict\n            if \&#34;64\&#34; in matrix_format:\n                err_msg = (\n                    f\&#34;Estimator {name} doesn&#39;t seem to support {matrix_format} \&#34;\n                    \&#34;matrix, and is not failing gracefully, e.g. by using \&#34;\n                    \&#34;check_array(X, accept_large_sparse=False).\&#34;\n                )\n            else:\n                err_msg = (\n                    f\&#34;Estimator {name} doesn&#39;t seem to fail gracefully on sparse \&#34;\n                    \&#34;data: error message should state explicitly that sparse \&#34;\n                    \&#34;input is not supported if this is not the case, e.g. by using \&#34;\n                    \&#34;check_array(X, accept_sparse=False).\&#34;\n                )\n            with raises(\n                (TypeError, ValueError),\n                match=[\&#34;sparse\&#34;, \&#34;Sparse\&#34;],\n                may_pass=True,\n                err_msg=err_msg,\n            ):\n                with ignore_warnings(category=FutureWarning):\n&amp;gt;                   estimator.fit(X, y)\n\nX          = &amp;lt;40x3 sparse array of type &#39;&amp;lt;class &#39;numpy.float64&#39;&amp;gt;&#39;\n\twith 21 stored elements in Compressed Sparse Row format&amp;gt;\nerr_msg    = \&#34;Estimator BasePerturbationCV doesn&#39;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).\&#34;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nmatrix_format = &#39;csr&#39;\nname       = &#39;BasePerturbationCV&#39;\nrng        = RandomState(MT19937) at 0x7F4FF3AA2340\nsparse_type = &amp;lt;class &#39;scipy.sparse._arrays.csr_array&#39;&amp;gt;\ntags       = {&#39;X_types&#39;: [&#39;2darray&#39;], &#39;_skip_test&#39;: False, &#39;_xfail_checks&#39;: False, &#39;allow_nan&#39;: False, ...}\ny          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1069: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = &amp;lt;40x3 sparse array of type &#39;&amp;lt;class &#39;numpy.float64&#39;&amp;gt;&#39;\n\twith 21 stored elements in Compressed Sparse Row format&amp;gt;\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff19e5cb0&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff19e5cb0&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...d elements in Compressed Sparse Row format&amp;gt;, array([3, 1, 1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff19e5cb0&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1182fe0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1182fe0&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff1182d70&amp;gt;\n        dispatch_timestamp = 1770122616.359618\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff1182d70&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1182fe0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff11831c0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1182fe0&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff1182dd0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff1182fe0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff1182e90&amp;gt;\n        args       = (LinearRegression(), &amp;lt;20x3 sparse array of type &#39;&amp;lt;class &#39;numpy.float64&#39;&amp;gt;&#39;\n\twith 12 stored elements in Compressed Sparse Row format&amp;gt;, array([3, 1, 1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = &amp;lt;20x3 sparse array of type &#39;&amp;lt;class &#39;numpy.float64&#39;&amp;gt;&#39;\n\twith 12 stored elements in Compressed Sparse Row format&amp;gt;\ny_train = array([3, 1, 1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = &amp;lt;20x3 sparse array of type &#39;&amp;lt;class &#39;numpy.float64&#39;&amp;gt;&#39;\n\twith 12 stored elements in Compressed Sparse Row format&amp;gt;\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([3, 1, 1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimator_sparse_array at 0x7f4ffd4cac20&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_estimator_sparse_array&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimator_sparse_array at 0x7f4ffd4cac20&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_estimator_sparse_array&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1091: in check_estimator_sparse_array\n    _check_estimator_sparse_container(name, estimator_orig, sparse.csr_array)\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1062: in _check_estimator_sparse_container\n    with raises(\n        X          = &amp;lt;40x3 sparse array of type &#39;&amp;lt;class &#39;numpy.float64&#39;&amp;gt;&#39;\n\twith 21 stored elements in Compressed Sparse Row format&amp;gt;\n        err_msg    = \&#34;Estimator BasePerturbationCV doesn&#39;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).\&#34;\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        matrix_format = &#39;csr&#39;\n        name       = &#39;BasePerturbationCV&#39;\n        rng        = RandomState(MT19937) at 0x7F4FF3AA2340\n        sparse_type = &amp;lt;class &#39;scipy.sparse._arrays.csr_array&#39;&amp;gt;\n        tags       = {&#39;X_types&#39;: [&#39;2darray&#39;], &#39;_skip_test&#39;: False, &#39;_xfail_checks&#39;: False, &#39;allow_nan&#39;: False, ...}\n        y          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4ff11836a0&amp;gt;\nexc_type = &amp;lt;class &#39;NotImplementedError&#39;&amp;gt;, exc_value = NotImplementedError()\n_ = &amp;lt;traceback object at 0x7f4ff11c69c0&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f\&#34;Did not raise: {self.expected_exc_types}\&#34;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n&amp;gt;               raise AssertionError(self.err_msg) from exc_value\nE               AssertionError: Estimator BasePerturbationCV doesn&#39;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).\n\n_          = &amp;lt;traceback object at 0x7f4ff11c69c0&amp;gt;\nexc_type   = &amp;lt;class &#39;NotImplementedError&#39;&amp;gt;\nexc_value  = NotImplementedError()\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4ff11836a0&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:915: AssertionError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A\n\n\n\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 246.83it/s]\u001b[A\u001b[A\u001b[A\u0101\r \r\n\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator40-check40-check_fit2d_1sample]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator40-check40-check_fit2d_1sample]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator40-check40-check_fit2d_1sample]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator19-check19-check_estimators_nan_inf]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator19-check19-check_estimators_nan_inf]&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator19-check19-check_estimators_nan_inf]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_nan_inf at 0x7f4ffd4d89d0&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_estimators_nan_inf&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_nan_inf at 0x7f4ffd4d89d0&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_estimators_nan_inf&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_nan_inf at 0x7f4ffd4d8940&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2024: in check_estimators_nan_inf\n    estimator.fit(X_train_finite, y)\n        X_train    = array([[       nan, 0.77423369, 0.45615033],\n       [0.56843395, 0.0187898 , 0.6176355 ],\n       [0.61209572, 0.616934...51, 0.98837384, 0.10204481],\n       [0.20887676, 0.16130952, 0.65310833],\n       [0.2532916 , 0.46631077, 0.24442559]])\n        X_train_finite = array([[0.5488135 , 0.71518937, 0.60276338],\n       [0.54488318, 0.4236548 , 0.64589411],\n       [0.43758721, 0.891773...56, 0.46147936, 0.78052918],\n       [0.11827443, 0.63992102, 0.14335329],\n       [0.94466892, 0.52184832, 0.41466194]])\n        X_train_inf = array([[       inf, 0.11037514, 0.65632959],\n       [0.13818295, 0.19658236, 0.36872517],\n       [0.82099323, 0.097101...99, 0.0641475 , 0.69247212],\n       [0.56660145, 0.26538949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]])\n        X_train_nan = array([[       nan, 0.77423369, 0.45615033],\n       [0.56843395, 0.0187898 , 0.6176355 ],\n       [0.61209572, 0.616934...51, 0.98837384, 0.10204481],\n       [0.20887676, 0.16130952, 0.65310833],\n       [0.2532916 , 0.46631077, 0.24442559]])\n        error_string_fit = \&#34;Estimator BasePerturbationCV doesn&#39;t check for NaN and inf in fit.\&#34;\n        error_string_predict = \&#34;Estimator BasePerturbationCV doesn&#39;t check for NaN and inf in predict.\&#34;\n        error_string_transform = \&#34;Estimator BasePerturbationCV doesn&#39;t check for NaN and inf in transform.\&#34;\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n        rnd        = RandomState(MT19937) at 0x7F4FF3AA2140\n        y          = array([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[0.5488135 , 0.71518937, 0.60276338],\n       [0.54488318, 0.4236548 , 0.64589411],\n       [0.43758721, 0.891773...56, 0.46147936, 0.78052918],\n       [0.11827443, 0.63992102, 0.14335329],\n       [0.94466892, 0.52184832, 0.41466194]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff19e7d10&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff19e7d10&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...[0.11827443, 0.63992102, 0.14335329],\n       [0.94466892, 0.52184832, 0.41466194]]), array([1., 1., 1., 1., 1.])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff19e7d10&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0ebb820&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0ebb820&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff0ebbac0&amp;gt;\n        dispatch_timestamp = 1770122617.3008015\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff0ebbac0&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0ebb820&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff3d15de0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0ebb820&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff0eb84c0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff0ebb820&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff0eb9420&amp;gt;\n        args       = (LinearRegression(), array([[0.0871293 , 0.0202184 , 0.83261985],\n       [0.77815675, 0.87001215, 0.97861834],\n       ...      [0.11827443, 0.63992102, 0.14335329],\n       [0.94466892, 0.52184832, 0.41466194]]), array([1., 1., 1., 1., 1.]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.0871293 , 0.0202184 , 0.83261985],\n       [0.77815675, 0.87001215, 0.97861834],\n       [0.79915856, 0.46147936, 0.78052918],\n       [0.11827443, 0.63992102, 0.14335329],\n       [0.94466892, 0.52184832, 0.41466194]])\ny_train = array([1., 1., 1., 1., 1.])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.0871293 , 0.0202184 , 0.83261985],\n       [0.77815675, 0.87001215, 0.97861834],\n       [0.79915856, 0.46147936, 0.78052918],\n       [0.11827443, 0.63992102, 0.14335329],\n       [0.94466892, 0.52184832, 0.41466194]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1., 1., 1., 1., 1.])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\n\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u0101\r \r\n\n\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 345.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u0101\r \r\n\n\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\n\n\u001b[A\u001b[A\n\n\n\u001b[A\u001b[A\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator14-check14-check_methods_sample_order_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator14-check14-check_methods_sample_order_invariance]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator14-check14-check_methods_sample_order_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator9-check9-check_estimator_sparse_matrix]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator9-check9-check_estimator_sparse_matrix]&#34;, &#34;duration&#34;: &#34;55 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator9-check9-check_estimator_sparse_matrix]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;55 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator11-check11-check_n_features_in]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator11-check11-check_n_features_in]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator11-check11-check_n_features_in]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbation(estimator=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_n_features_in at 0x7f4ffd4dbac0&amp;gt;, &#39;BasePerturbation&#39;)\nname = &#39;check_n_features_in&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_n_features_in at 0x7f4ffd4dbac0&amp;gt;, &#39;BasePerturbation&#39;)\nestimator  = BasePerturbation(estimator=LinearRegression())\nname       = &#39;check_n_features_in&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;BasePerturbation&#39;\nestimator_orig = BasePerturbation(estimator=LinearRegression())\n\n    def check_n_features_in(name, estimator_orig):\n        # Make sure that n_features_in_ attribute doesn&#39;t exist until fit is\n        # called, and that its value is correct.\n    \n        rng = np.random.RandomState(0)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if \&#34;warm_start\&#34; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        assert not hasattr(estimator, \&#34;n_features_in_\&#34;)\n        estimator.fit(X, y)\n&amp;gt;       assert hasattr(estimator, \&#34;n_features_in_\&#34;)\nE       AssertionError\n\nX          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\nestimator  = BasePerturbation(estimator=LinearRegression(), features_groups={0: [0], 1: [1]},\n                 random_state=0)\nestimator_orig = BasePerturbation(estimator=LinearRegression())\nn_samples  = 100\nname       = &#39;BasePerturbation&#39;\nrng        = RandomState(MT19937) at 0x7F4FF3AA2740\ny          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3951: AssertionError\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator5-check5-check_n_features_in]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator5-check5-check_n_features_in]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator5-check5-check_n_features_in]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbation(estimator=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_n_features_in at 0x7f4ffd4dbac0&amp;gt;, &#39;BasePerturbation&#39;)\nname = &#39;check_n_features_in&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_n_features_in at 0x7f4ffd4dbac0&amp;gt;, &#39;BasePerturbation&#39;)\nestimator  = BasePerturbation(estimator=LinearRegression())\nname       = &#39;check_n_features_in&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;BasePerturbation&#39;\nestimator_orig = BasePerturbation(estimator=LinearRegression())\n\n    def check_n_features_in(name, estimator_orig):\n        # Make sure that n_features_in_ attribute doesn&#39;t exist until fit is\n        # called, and that its value is correct.\n    \n        rng = np.random.RandomState(0)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if \&#34;warm_start\&#34; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        assert not hasattr(estimator, \&#34;n_features_in_\&#34;)\n        estimator.fit(X, y)\n&amp;gt;       assert hasattr(estimator, \&#34;n_features_in_\&#34;)\nE       AssertionError\n\nX          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\nestimator  = BasePerturbation(estimator=LinearRegression(), features_groups={0: [0], 1: [1]},\n                 random_state=0)\nestimator_orig = BasePerturbation(estimator=LinearRegression())\nn_samples  = 100\nname       = &#39;BasePerturbation&#39;\nrng        = RandomState(MT19937) at 0x7F4FF3AA1D40\ny          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3951: AssertionError\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n--------------------------- Captured stderr teardown ---------------------------\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator49-check49-check_estimators_empty_data_messages]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator49-check49-check_estimators_empty_data_messages]&#34;, &#34;duration&#34;: &#34;8 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator49-check49-check_estimators_empty_data_messages]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;8 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\n\u0101\r \r\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator45-check45-check_fit_idempotent]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator45-check45-check_fit_idempotent]&#34;, &#34;duration&#34;: &#34;11 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator45-check45-check_fit_idempotent]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;11 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator4-check4-check_fit_check_is_fitted]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator4-check4-check_fit_check_is_fitted]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator4-check4-check_fit_check_is_fitted]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbation(estimator=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7f4ffd4dba30&amp;gt;, &#39;BasePerturbation&#39;)\nname = &#39;check_fit_check_is_fitted&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7f4ffd4dba30&amp;gt;, &#39;BasePerturbation&#39;)\nestimator  = BasePerturbation(estimator=LinearRegression())\nname       = &#39;check_fit_check_is_fitted&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;BasePerturbation&#39;\nestimator_orig = BasePerturbation(estimator=LinearRegression())\n\n    def check_fit_check_is_fitted(name, estimator_orig):\n        # Make sure that estimator doesn&#39;t pass check_is_fitted before calling fit\n        # and that passes check_is_fitted once it&#39;s fit.\n    \n        rng = np.random.RandomState(42)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if \&#34;warm_start\&#34; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if not _safe_tags(estimator).get(\&#34;stateless\&#34;, False):\n            # stateless estimators (such as FunctionTransformer) are always \&#34;fit\&#34;!\n            try:\n                check_is_fitted(estimator)\n&amp;gt;               raise AssertionError(\n                    f\&#34;{estimator.__class__.__name__} passes check_is_fitted before being\&#34;\n                    \&#34; fit!\&#34;\n                )\nE               AssertionError: BasePerturbation passes check_is_fitted before being fit!\n\nX          = array([[100.49671415,  99.8617357 ],\n       [100.64768854, 101.52302986],\n       [ 99.76584663,  99.76586304],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\nestimator  = BasePerturbation(estimator=LinearRegression(), random_state=0)\nestimator_orig = BasePerturbation(estimator=LinearRegression())\nn_samples  = 100\nname       = &#39;BasePerturbation&#39;\nrng        = RandomState(MT19937) at 0x7F4FF3AA1A40\ny          = array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,...1,\n       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3914: AssertionError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator44-check44-check_dict_unchanged]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator44-check44-check_dict_unchanged]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator44-check44-check_dict_unchanged]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_base_cv_errors&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_base_cv_errors&#34;, &#34;duration&#34;: &#34;12 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_base_cv_errors&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;12 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 322.32it/s]\n\u0101\r \r\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\n&#34;}], &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[less]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[less]&#34;, &#34;duration&#34;: &#34;12 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[less]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;12 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_result_attributes&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_result_attributes&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_result_attributes&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[two-sided]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[two-sided]&#34;, &#34;duration&#34;: &#34;9 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[two-sided]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;9 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::test_ttest_1samp_corrected_NB[100-6-2-0.2-0-1.0-10.0-0.0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::test_ttest_1samp_corrected_NB[100-6-2-0.2-0-1.0-10.0-0.0]&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_nadeau_bengio_ttest.py::test_ttest_1samp_corrected_NB[100-6-2-0.2-0-1.0-10.0-0.0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[greater]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[greater]&#34;, &#34;duration&#34;: &#34;11 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[greater]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;11 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative_exception&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative_exception&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative_exception&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_version.py::test_version&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_version.py::test_version&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_version.py::test_version&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_generated_attributes&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_generated_attributes&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_generated_attributes&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_check_test_statistic_warning&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_check_test_statistic_warning&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_check_test_statistic_warning&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_rng&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_rng&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_rng&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_random_state&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_random_state&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_random_state&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_none&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_check_test_statistic&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_check_test_statistic&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_check_test_statistic&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_error&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_error&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_integer&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_integer&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_integer&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_multiple_testing.py::test_fdr_threshold&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_multiple_testing.py::test_fdr_threshold&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_multiple_testing.py::test_fdr_threshold&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_multiple_testing.py::test_aggregate_docstring&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_multiple_testing.py::test_aggregate_docstring&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_multiple_testing.py::test_aggregate_docstring&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_multiple_testing.py::test_fdr_threshold_extreme_values&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_multiple_testing.py::test_fdr_threshold_extreme_values&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_multiple_testing.py::test_fdr_threshold_extreme_values&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_multiple_testing.py::test_fdp_power&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_multiple_testing.py::test_fdp_power&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_multiple_testing.py::test_fdp_power&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_rgn&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_rgn&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_rgn&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_s_equi_not_definite_positive&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_s_equi_not_definite_positive&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_s_equi_not_definite_positive&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_no_seed_repeat&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_no_seed_repeat&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_no_seed_repeat&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_gaussian_equi&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_gaussian_equi&#34;, &#34;duration&#34;: &#34;121 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_gaussian_equi&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;121 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_gaussian_error&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_gaussian_error&#34;, &#34;duration&#34;: &#34;13 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_gaussian_error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;13 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_reproducibility_sample_repeat&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_reproducibility_sample_repeat&#34;, &#34;duration&#34;: &#34;21 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_reproducibility_sample_repeat&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;21 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_no_seed&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_no_seed&#34;, &#34;duration&#34;: &#34;13 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_no_seed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;13 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_reproducibility_sample&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_reproducibility_sample&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_reproducibility_sample&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_rgn_repeat&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_rgn_repeat&#34;, &#34;duration&#34;: &#34;13 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_rgn_repeat&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;13 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator3-check3-check_estimators_fit_returns_self]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator3-check3-check_estimators_fit_returns_self]&#34;, &#34;duration&#34;: &#34;150 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator3-check3-check_estimators_fit_returns_self]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;150 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator10-check10-check_estimator_sparse_matrix]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator10-check10-check_estimator_sparse_matrix]&#34;, &#34;duration&#34;: &#34;23 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator10-check10-check_estimator_sparse_matrix]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;23 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator5-check5-check_dtype_object]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator5-check5-check_dtype_object]&#34;, &#34;duration&#34;: &#34;156 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator5-check5-check_dtype_object]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;156 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_dl_reproducibility_with_integer&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_dl_reproducibility_with_integer&#34;, &#34;duration&#34;: &#34;00:00:05&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_dl_reproducibility_with_integer&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:05&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_ensemble_clustered_inference.py::test_encludl_spatial&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_ensemble_clustered_inference.py::test_encludl_spatial&#34;, &#34;duration&#34;: &#34;00:00:18&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_ensemble_clustered_inference.py::test_encludl_spatial&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:18&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.49it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.75it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.76it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.76it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.82it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 576.00it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.90it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.91it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.80it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.69it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.91it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 654.91it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.37it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.51it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.73it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.88it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.03it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 701.58it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  3.27it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  3.04it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  3.13it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.97it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.01it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 708.23it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  3.16it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  3.14it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  3.28it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  3.24it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.25it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 701.51it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  3.11it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  3.01it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.87it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.56it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.40it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 703.27it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.63it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.61it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.88it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.59it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.55it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 549.06it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.42it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.58it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.62it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.63it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.84it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 703.48it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  3.49it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  3.30it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  3.42it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.97it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.01it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 553.98it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  3.22it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  3.26it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  3.26it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  3.25it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.20it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 705.85it/s]\n&#34;}], &#34;test/test_desparsified_lasso.py::test_dl_randomness_with_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_dl_randomness_with_none&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_dl_randomness_with_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator4-check4-check_complex_data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator4-check4-check_complex_data]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator4-check4-check_complex_data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator15-check15-check_methods_subset_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator15-check15-check_methods_subset_invariance]&#34;, &#34;duration&#34;: &#34;74 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator15-check15-check_methods_subset_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;74 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator6-check6-check_estimators_empty_data_messages]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator6-check6-check_estimators_empty_data_messages]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator6-check6-check_estimators_empty_data_messages]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator2-check2-check_parameters_default_constructible]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator2-check2-check_parameters_default_constructible]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator2-check2-check_parameters_default_constructible]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = DesparsifiedLasso(confidence=0.9, random_state=0)\ncheck = functools.partial(&amp;lt;function check_parameters_default_constructible at 0x7f4ffd4db010&amp;gt;, &#39;DesparsifiedLasso&#39;)\nname = &#39;check_parameters_default_constructible&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_parameters_default_constructible at 0x7f4ffd4db010&amp;gt;, &#39;DesparsifiedLasso&#39;)\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\nname       = &#39;check_parameters_default_constructible&#39;\n\ntest/test_desparsified_lasso.py:70: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;DesparsifiedLasso&#39;\nEstimator = &amp;lt;class &#39;hidimstat.desparsified_lasso.DesparsifiedLasso&#39;&amp;gt;\n\n    def check_parameters_default_constructible(name, Estimator):\n        # test default-constructibility\n        # get rid of deprecation warnings\n    \n        Estimator = Estimator.__class__\n    \n        with ignore_warnings(category=FutureWarning):\n            estimator = _construct_instance(Estimator)\n            # test cloning\n            clone(estimator)\n            # test __repr__\n            repr(estimator)\n            # test that set_params returns self\n            assert estimator.set_params() is estimator\n    \n            # test if init does nothing but set parameters\n            # this is important for grid_search etc.\n            # We get the default parameters from init and then\n            # compare these against the actual values of the attributes.\n    \n            # this comes from getattr. Gets rid of deprecation decorator.\n            init = getattr(estimator.__init__, \&#34;deprecated_original\&#34;, estimator.__init__)\n    \n            try:\n    \n                def param_filter(p):\n                    \&#34;\&#34;\&#34;Identify hyper parameters of an estimator.\&#34;\&#34;\&#34;\n                    return (\n                        p.name != \&#34;self\&#34;\n                        and p.kind != p.VAR_KEYWORD\n                        and p.kind != p.VAR_POSITIONAL\n                    )\n    \n                init_params = [\n                    p for p in signature(init).parameters.values() if param_filter(p)\n                ]\n    \n            except (TypeError, ValueError):\n                # init is not a python function.\n                # true for mixins\n                return\n            params = estimator.get_params()\n            # they can need a non-default argument\n            init_params = init_params[len(getattr(estimator, \&#34;_required_parameters\&#34;, [])) :]\n    \n            for init_param in init_params:\n                assert (\n                    init_param.default != init_param.empty\n                ), \&#34;parameter %s for %s has no default value\&#34; % (\n                    init_param.name,\n                    type(estimator).__name__,\n                )\n                allowed_types = {\n                    str,\n                    int,\n                    float,\n                    bool,\n                    tuple,\n                    type(None),\n                    type,\n                }\n                # Any numpy numeric such as np.int32.\n                allowed_types.update(np.sctypeDict.values())\n    \n                allowed_value = (\n                    type(init_param.default) in allowed_types\n                    or\n                    # Although callables are mutable, we accept them as argument\n                    # default value and trust that neither the implementation of\n                    # the callable nor of the estimator changes the state of the\n                    # callable.\n                    callable(init_param.default)\n                )\n    \n&amp;gt;               assert allowed_value, (\n                    f\&#34;Parameter &#39;{init_param.name}&#39; of estimator \&#34;\n                    f\&#34;&#39;{Estimator.__name__}&#39; is of type \&#34;\n                    f\&#34;{type(init_param.default).__name__} which is not allowed. \&#34;\n                    f\&#34;&#39;{init_param.name}&#39; must be a callable or must be of type \&#34;\n                    f\&#34;{set(type.__name__ for type in allowed_types)}.\&#34;\n                )\nE               AssertionError: Parameter &#39;estimator&#39; of estimator &#39;DesparsifiedLasso&#39; is of type LassoCV which is not allowed. &#39;estimator&#39; must be a callable or must be of type {&#39;int&#39;, &#39;int8&#39;, &#39;uint64&#39;, &#39;timedelta64&#39;, &#39;bytes_&#39;, &#39;tuple&#39;, &#39;NoneType&#39;, &#39;longdouble&#39;, &#39;str&#39;, &#39;void&#39;, &#39;type&#39;, &#39;int16&#39;, &#39;longlong&#39;, &#39;datetime64&#39;, &#39;complex128&#39;, &#39;str_&#39;, &#39;complex64&#39;, &#39;bool&#39;, &#39;bool_&#39;, &#39;float&#39;, &#39;float32&#39;, &#39;float16&#39;, &#39;float64&#39;, &#39;uint8&#39;, &#39;object_&#39;, &#39;clongdouble&#39;, &#39;int32&#39;, &#39;uint16&#39;, &#39;uint32&#39;, &#39;ulonglong&#39;, &#39;int64&#39;}.\n\nEstimator  = &amp;lt;class &#39;hidimstat.desparsified_lasso.DesparsifiedLasso&#39;&amp;gt;\nallowed_types = {&amp;lt;class &#39;numpy.int8&#39;&amp;gt;, &amp;lt;class &#39;numpy.void&#39;&amp;gt;, &amp;lt;class &#39;numpy.complex64&#39;&amp;gt;, &amp;lt;class &#39;numpy.ulonglong&#39;&amp;gt;, &amp;lt;class &#39;numpy.longlong&#39;&amp;gt;, &amp;lt;class &#39;numpy.bool_&#39;&amp;gt;, ...}\nallowed_value = False\nestimator  = DesparsifiedLasso()\ninit       = &amp;lt;bound method DesparsifiedLasso.__init__ of DesparsifiedLasso()&amp;gt;\ninit_param = &amp;lt;Parameter \&#34;estimator=LassoCV(eps=0.01, fit_intercept=False)\&#34;&amp;gt;\ninit_params = [&amp;lt;Parameter \&#34;estimator=LassoCV(eps=0.01, fit_intercept=False)\&#34;&amp;gt;, &amp;lt;Parameter \&#34;centered=True\&#34;&amp;gt;, &amp;lt;Parameter \&#34;dof_ajdustem...Parameter \&#34;model_x=Lasso()\&#34;&amp;gt;, &amp;lt;Parameter \&#34;preconfigure_model_x_path=True\&#34;&amp;gt;, &amp;lt;Parameter \&#34;alpha_max_fraction=0.01\&#34;&amp;gt;, ...]\nname       = &#39;DesparsifiedLasso&#39;\nparam_filter = &amp;lt;function check_parameters_default_constructible.&amp;lt;locals&amp;gt;.param_filter at 0x7f4ff1101e10&amp;gt;\nparams     = {&#39;alpha_max_fraction&#39;: 0.01, &#39;centered&#39;: True, &#39;confidence&#39;: 0.95, &#39;covariance&#39;: None, ...}\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3505: AssertionError\n&#34;}], &#34;test/test_desparsified_lasso.py::test_exception&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_exception&#34;, &#34;duration&#34;: &#34;761 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_exception&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;761 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator11-check11-check_estimators_pickle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator11-check11-check_estimators_pickle]&#34;, &#34;duration&#34;: &#34;135 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator11-check11-check_estimators_pickle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;135 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator13-check13-check_estimator_get_tags_default_keys]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator13-check13-check_estimator_get_tags_default_keys]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator13-check13-check_estimator_get_tags_default_keys]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator1-check1-check_estimators_overwrite_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator1-check1-check_estimators_overwrite_params]&#34;, &#34;duration&#34;: &#34;75 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator1-check1-check_estimators_overwrite_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;75 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = DesparsifiedLasso(confidence=0.9, random_state=0)\ncheck = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4ffd4da9e0&amp;gt;, &#39;DesparsifiedLasso&#39;)\nname = &#39;check_estimators_overwrite_params&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4ffd4da9e0&amp;gt;, &#39;DesparsifiedLasso&#39;)\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\nname       = &#39;check_estimators_overwrite_params&#39;\n\ntest/test_desparsified_lasso.py:70: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;DesparsifiedLasso&#39;, DesparsifiedLasso(confidence=0.9, random_state=0))\n        fn         = &amp;lt;function check_estimators_overwrite_params at 0x7f4ffd4da950&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;DesparsifiedLasso&#39;\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n\n    @ignore_warnings(category=FutureWarning)\n    def check_estimators_overwrite_params(name, estimator_orig):\n        X, y = make_blobs(random_state=0, n_samples=21)\n        X = _enforce_estimator_tags_X(estimator_orig, X, kernel=rbf_kernel)\n        estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        set_random_state(estimator)\n    \n        # Make a physical copy of the original estimator parameters before fitting.\n        params = estimator.get_params()\n        original_params = deepcopy(params)\n    \n        # Fit the model\n        estimator.fit(X, y)\n    \n        # Compare the state of the model parameters with the original parameters\n        new_params = estimator.get_params()\n        for param_name, original_value in original_params.items():\n            new_value = new_params[param_name]\n    \n            # We should never change or mutate the internal state of input\n            # parameters by default. To check this we use the joblib.hash function\n            # that introspects recursively any subobjects to compute a checksum.\n            # The only exception to this rule of immutable constructor parameters\n            # is possible RandomState instance but in this check we explicitly\n            # fixed the random_state params recursively to be integer seeds.\n&amp;gt;           assert joblib.hash(new_value) == joblib.hash(original_value), (\n                \&#34;Estimator %s should not change or mutate \&#34;\n                \&#34; the parameter %s from %s to %s during fit.\&#34;\n                % (name, param_name, original_value, new_value)\n            )\nE           AssertionError: Estimator DesparsifiedLasso should not change or mutate  the parameter estimator__n_jobs from None to 1 during fit.\n\nX          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\nestimator  = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7F4FF3AA2140),\n                  random_state=0)\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\nname       = &#39;DesparsifiedLasso&#39;\nnew_params = {&#39;alpha_max_fraction&#39;: 0.01, &#39;centered&#39;: True, &#39;confidence&#39;: 0.9, &#39;covariance&#39;: None, ...}\nnew_value  = 1\noriginal_params = {&#39;alpha_max_fraction&#39;: 0.01, &#39;centered&#39;: True, &#39;confidence&#39;: 0.9, &#39;covariance&#39;: None, ...}\noriginal_value = None\nparam_name = &#39;estimator__n_jobs&#39;\nparams     = {&#39;alpha_max_fraction&#39;: 0.01, &#39;centered&#39;: True, &#39;confidence&#39;: 0.9, &#39;covariance&#39;: None, ...}\ny          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3270: AssertionError\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator8-check8-check_estimators_nan_inf]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator8-check8-check_estimators_nan_inf]&#34;, &#34;duration&#34;: &#34;147 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator8-check8-check_estimators_nan_inf]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;147 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_ensemble_clustered_inference.py::test_encludl_independence&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_ensemble_clustered_inference.py::test_encludl_independence&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_ensemble_clustered_inference.py::test_encludl_independence&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/20 [00:00&lt;?, ?it/s]\rFitting clustered inferences:   5%|\u258c         | 1/20 [00:00&lt;00:03,  4.77it/s]\rFitting clustered inferences:  10%|\u2588         | 2/20 [00:00&lt;00:03,  5.08it/s]\rFitting clustered inferences:  15%|\u2588\u258c        | 3/20 [00:00&lt;00:03,  5.32it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 4/20 [00:00&lt;00:02,  5.56it/s]\rFitting clustered inferences:  25%|\u2588\u2588\u258c       | 5/20 [00:00&lt;00:02,  5.70it/s]\rFitting clustered inferences:  30%|\u2588\u2588\u2588       | 6/20 [00:01&lt;00:02,  5.76it/s]\rFitting clustered inferences:  35%|\u2588\u2588\u2588\u258c      | 7/20 [00:01&lt;00:02,  5.95it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 8/20 [00:01&lt;00:02,  5.94it/s]\rFitting clustered inferences:  45%|\u2588\u2588\u2588\u2588\u258c     | 9/20 [00:01&lt;00:01,  6.06it/s]\rFitting clustered inferences:  50%|\u2588\u2588\u2588\u2588\u2588     | 10/20 [00:01&lt;00:01,  6.13it/s]\rFitting clustered inferences:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 11/20 [00:01&lt;00:01,  6.18it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 12/20 [00:02&lt;00:01,  5.94it/s]\rFitting clustered inferences:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 13/20 [00:02&lt;00:01,  5.77it/s]\rFitting clustered inferences:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 14/20 [00:02&lt;00:01,  5.33it/s]\rFitting clustered inferences:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 15/20 [00:02&lt;00:01,  4.86it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 16/20 [00:02&lt;00:00,  4.46it/s]\rFitting clustered inferences:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 17/20 [00:03&lt;00:00,  4.66it/s]\rFitting clustered inferences:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 18/20 [00:03&lt;00:00,  4.94it/s]\rFitting clustered inferences:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 19/20 [00:03&lt;00:00,  5.17it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:03&lt;00:00,  5.36it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/20 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 1026.71it/s]\n&#34;}], &#34;test/test_desparsified_lasso.py::test_dl_repeatibility&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_dl_repeatibility&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_dl_repeatibility&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator3-check3-check_fit2d_1feature]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator3-check3-check_fit2d_1feature]&#34;, &#34;duration&#34;: &#34;120 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator3-check3-check_fit2d_1feature]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;120 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &#39;DesparsifiedLasso&#39;\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n\n    @ignore_warnings\n    def check_fit2d_1feature(name, estimator_orig):\n        # check fitting a 2d array with only 1 feature either works or returns\n        # informative message\n        rnd = np.random.RandomState(0)\n        X = 3 * rnd.uniform(size=(10, 1))\n        X = _enforce_estimator_tags_X(estimator_orig, X)\n        y = X[:, 0].astype(int)\n        estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if hasattr(estimator, \&#34;n_components\&#34;):\n            estimator.n_components = 1\n        if hasattr(estimator, \&#34;n_clusters\&#34;):\n            estimator.n_clusters = 1\n        # ensure two labels in subsample for RandomizedLogisticRegression\n        if name == \&#34;RandomizedLogisticRegression\&#34;:\n            estimator.sample_fraction = 1\n        # ensure non skipped trials for RANSACRegressor\n        if name == \&#34;RANSACRegressor\&#34;:\n            estimator.residual_threshold = 0.5\n    \n        y = _enforce_estimator_tags_y(estimator, y)\n        set_random_state(estimator, 1)\n    \n        msgs = [r\&#34;1 feature\\(s\\)\&#34;, \&#34;n_features = 1\&#34;, \&#34;n_features=1\&#34;]\n    \n        with raises(ValueError, match=msgs, may_pass=True):\n&amp;gt;           estimator.fit(X, y)\n\nX          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\nestimator  = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7F4FF3AA2240),\n                  random_state=1)\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\nmsgs       = [&#39;1 feature\\\\(s\\\\)&#39;, &#39;n_features = 1&#39;, &#39;n_features=1&#39;]\nname       = &#39;DesparsifiedLasso&#39;\nrnd        = RandomState(MT19937) at 0x7F4FF3AA1C40\ny          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1673: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/desparsified_lasso.py:260: in fit\n    results = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(\n        X          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\n        X_         = array([[-0.20085834],\n       [ 0.29826925],\n       [-0.03900872],\n       [-0.2126493 ],\n       [-0.57633445],\n       [ 0.09038349],\n       [-0.53453722],\n       [ 0.82802015],\n       [ 1.04368943],\n       [-0.69697429]])\n        gram       = array([[3.0627888]])\n        list_model_x = [Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7F4FF3AA2440)]\n        memory     = Memory(location=None)\n        n_features = 1\n        rng        = Generator(PCG64) at 0x7F4FF13A3760\n        self       = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7F4FF3AA2240),\n                  random_state=1)\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n        y_         = array([-0.3,  0.7, -0.3, -0.3, -0.3, -0.3, -0.3,  0.7,  0.7, -0.3])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object DesparsifiedLasso.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff16228f0&amp;gt;\n        iterator   = &amp;lt;generator object DesparsifiedLasso.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff16228f0&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;function _joblib_compute_residuals at 0x7f4ffb095d80&amp;gt;, (), {&#39;X&#39;: array([[-0.20085834],\n       [ 0.29826925],\n      ...loat64),\n      random_state=RandomState(PCG64) at 0x7F4FF3AA2440), &#39;gram&#39;: array([[3.0627888]]), &#39;id_column&#39;: 0, ...})]\n        iterator   = &amp;lt;generator object DesparsifiedLasso.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4ff16228f0&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff13f7a90&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff13f7a90&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff13f6c50&amp;gt;\n        dispatch_timestamp = 1770122633.021655\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7f4ff13f6c50&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff13f7a90&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7f4ff13f63b0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff13f7a90&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7f4ff13f6620&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7f4ff13f7a90&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7f4ff13f76a0&amp;gt;\n        args       = ()\n        func       = &amp;lt;function _joblib_compute_residuals at 0x7f4ffb095d80&amp;gt;\n        kwargs     = {&#39;X&#39;: array([[-0.20085834],\n       [ 0.29826925],\n       [-0.03900872],\n       [-0.2126493 ],\n       [-0.57633445],\n  ...=float64),\n      random_state=RandomState(PCG64) at 0x7F4FF3AA2440), &#39;gram&#39;: array([[3.0627888]]), &#39;id_column&#39;: 0, ...}\nsrc/hidimstat/desparsified_lasso.py:497: in _joblib_compute_residuals\n    clf.fit(X_minus_i, X_i)\n        X          = array([[-0.20085834],\n       [ 0.29826925],\n       [-0.03900872],\n       [-0.2126493 ],\n       [-0.57633445],\n       [ 0.09038349],\n       [-0.53453722],\n       [ 0.82802015],\n       [ 1.04368943],\n       [-0.69697429]])\n        X_i        = array([-0.20085834,  0.29826925, -0.03900872, -0.2126493 , -0.57633445,\n        0.09038349, -0.53453722,  0.82802015,  1.04368943, -0.69697429])\n        X_minus_i  = array([], shape=(10, 0), dtype=float64)\n        _          = 1\n        clf        = Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7F4FF3AA2440)\n        gram       = array([[3.0627888]])\n        id_column  = 0\n        n_samples  = 10\n        return_clf = False\n.venv/lib/python3.10/site-packages/sklearn/base.py:1473: in wrapper\n    return fit_method(estimator, *args, **kwargs)\n        args       = (array([], shape=(10, 0), dtype=float64), array([-0.20085834,  0.29826925, -0.03900872, -0.2126493 , -0.57633445,\n        0.09038349, -0.53453722,  0.82802015,  1.04368943, -0.69697429]))\n        estimator  = Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7F4FF3AA2440)\n        fit_method = &amp;lt;function ElasticNet.fit at 0x7f4ffe057be0&amp;gt;\n        global_skip_validation = False\n        kwargs     = {}\n        partial_fit_and_fitted = False\n        prefer_skip_nested_validation = True\n.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:980: in fit\n    X, y = self._validate_data(\n        X          = array([], shape=(10, 0), dtype=float64)\n        X_copied   = True\n        check_input = True\n        sample_weight = None\n        self       = Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7F4FF3AA2440)\n        y          = array([-0.20085834,  0.29826925, -0.03900872, -0.2126493 , -0.57633445,\n        0.09038349, -0.53453722,  0.82802015,  1.04368943, -0.69697429])\n.venv/lib/python3.10/site-packages/sklearn/base.py:650: in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n        X          = array([], shape=(10, 0), dtype=float64)\n        cast_to_ndarray = True\n        check_params = {&#39;accept_large_sparse&#39;: False, &#39;accept_sparse&#39;: &#39;csc&#39;, &#39;copy&#39;: True, &#39;dtype&#39;: [&amp;lt;class &#39;numpy.float64&#39;&amp;gt;, &amp;lt;class &#39;numpy.float32&#39;&amp;gt;], ...}\n        default_check_params = {&#39;estimator&#39;: Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7F4FF3AA2440)}\n        no_val_X   = False\n        no_val_y   = False\n        reset      = True\n        self       = Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7F4FF3AA2440)\n        validate_separately = False\n        y          = array([-0.20085834,  0.29826925, -0.03900872, -0.2126493 , -0.57633445,\n        0.09038349, -0.53453722,  0.82802015,  1.04368943, -0.69697429])\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1273: in check_X_y\n    X = check_array(\n        X          = array([], shape=(10, 0), dtype=float64)\n        accept_large_sparse = False\n        accept_sparse = &#39;csc&#39;\n        allow_nd   = False\n        copy       = True\n        dtype      = [&amp;lt;class &#39;numpy.float64&#39;&amp;gt;, &amp;lt;class &#39;numpy.float32&#39;&amp;gt;]\n        ensure_2d  = True\n        ensure_min_features = 1\n        ensure_min_samples = 1\n        estimator  = Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7F4FF3AA2440)\n        force_all_finite = True\n        multi_output = True\n        order      = &#39;F&#39;\n        y          = array([-0.20085834,  0.29826925, -0.03900872, -0.2126493 , -0.57633445,\n        0.09038349, -0.53453722,  0.82802015,  1.04368943, -0.69697429])\n        y_numeric  = True\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\narray = array([], shape=(10, 0), dtype=float64), accept_sparse = &#39;csc&#39;\n\n    def check_array(\n        array,\n        accept_sparse=False,\n        *,\n        accept_large_sparse=True,\n        dtype=\&#34;numeric\&#34;,\n        order=None,\n        copy=False,\n        force_all_finite=True,\n        ensure_2d=True,\n        allow_nd=False,\n        ensure_min_samples=1,\n        ensure_min_features=1,\n        estimator=None,\n        input_name=\&#34;\&#34;,\n    ):\n        \&#34;\&#34;\&#34;Input validation on an array, list, sparse matrix or similar.\n    \n        By default, the input is checked to be a non-empty 2D array containing\n        only finite values. If the dtype of the array is object, attempt\n        converting to float, raising on failure.\n    \n        Parameters\n        ----------\n        array : object\n            Input object to check / convert.\n    \n        accept_sparse : str, bool or list/tuple of str, default=False\n            String[s] representing allowed sparse matrix formats, such as &#39;csc&#39;,\n            &#39;csr&#39;, etc. If the input is sparse but not in the allowed format,\n            it will be converted to the first listed format. True allows the input\n            to be any format. False means that a sparse matrix input will\n            raise an error.\n    \n        accept_large_sparse : bool, default=True\n            If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\n            accept_sparse, accept_large_sparse=False will cause it to be accepted\n            only if its indices are stored with a 32-bit dtype.\n    \n            .. versionadded:: 0.20\n    \n        dtype : &#39;numeric&#39;, type, list of type or None, default=&#39;numeric&#39;\n            Data type of result. If None, the dtype of the input is preserved.\n            If \&#34;numeric\&#34;, dtype is preserved unless array.dtype is object.\n            If dtype is a list of types, conversion on the first type is only\n            performed if the dtype of the input is not in the list.\n    \n        order : {&#39;F&#39;, &#39;C&#39;} or None, default=None\n            Whether an array will be forced to be fortran or c-style.\n            When order is None (default), then if copy=False, nothing is ensured\n            about the memory layout of the output array; otherwise (copy=True)\n            the memory layout of the returned array is kept as close as possible\n            to the original array.\n    \n        copy : bool, default=False\n            Whether a forced copy will be triggered. If copy=False, a copy might\n            be triggered by a conversion.\n    \n        force_all_finite : bool or &#39;allow-nan&#39;, default=True\n            Whether to raise an error on np.inf, np.nan, pd.NA in array. The\n            possibilities are:\n    \n            - True: Force all values of array to be finite.\n            - False: accepts np.inf, np.nan, pd.NA in array.\n            - &#39;allow-nan&#39;: accepts only np.nan and pd.NA values in array. Values\n              cannot be infinite.\n    \n            .. versionadded:: 0.20\n               ``force_all_finite`` accepts the string ``&#39;allow-nan&#39;``.\n    \n            .. versionchanged:: 0.23\n               Accepts `pd.NA` and converts it into `np.nan`\n    \n        ensure_2d : bool, default=True\n            Whether to raise a value error if array is not 2D.\n    \n        allow_nd : bool, default=False\n            Whether to allow array.ndim &amp;gt; 2.\n    \n        ensure_min_samples : int, default=1\n            Make sure that the array has a minimum number of samples in its first\n            axis (rows for a 2D array). Setting to 0 disables this check.\n    \n        ensure_min_features : int, default=1\n            Make sure that the 2D array has some minimum number of features\n            (columns). The default value of 1 rejects empty datasets.\n            This check is only enforced when the input data has effectively 2\n            dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0\n            disables this check.\n    \n        estimator : str or estimator instance, default=None\n            If passed, include the name of the estimator in warning messages.\n    \n        input_name : str, default=\&#34;\&#34;\n            The data name used to construct the error message. In particular\n            if `input_name` is \&#34;X\&#34; and the data has NaN values and\n            allow_nan is False, the error message will link to the imputer\n            documentation.\n    \n            .. versionadded:: 1.1.0\n    \n        Returns\n        -------\n        array_converted : object\n            The converted and validated array.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_array\n        &amp;gt;&amp;gt;&amp;gt; X = [[1, 2, 3], [4, 5, 6]]\n        &amp;gt;&amp;gt;&amp;gt; X_checked = check_array(X)\n        &amp;gt;&amp;gt;&amp;gt; X_checked\n        array([[1, 2, 3], [4, 5, 6]])\n        \&#34;\&#34;\&#34;\n        if isinstance(array, np.matrix):\n            raise TypeError(\n                \&#34;np.matrix is not supported. Please convert to a numpy array with \&#34;\n                \&#34;np.asarray. For more information see: \&#34;\n                \&#34;https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\&#34;\n            )\n    \n        xp, is_array_api_compliant = get_namespace(array)\n    \n        # store reference to original array to check if copy is needed when\n        # function returns\n        array_orig = array\n    \n        # store whether originally we wanted numeric dtype\n        dtype_numeric = isinstance(dtype, str) and dtype == \&#34;numeric\&#34;\n    \n        dtype_orig = getattr(array, \&#34;dtype\&#34;, None)\n        if not is_array_api_compliant and not hasattr(dtype_orig, \&#34;kind\&#34;):\n            # not a data type (e.g. a column named dtype in a pandas DataFrame)\n            dtype_orig = None\n    \n        # check if the object contains several dtypes (typically a pandas\n        # DataFrame), and store them. If not, store None.\n        dtypes_orig = None\n        pandas_requires_conversion = False\n        # track if we have a Series-like object to raise a better error message\n        type_if_series = None\n        if hasattr(array, \&#34;dtypes\&#34;) and hasattr(array.dtypes, \&#34;__array__\&#34;):\n            # throw warning if columns are sparse. If all columns are sparse, then\n            # array.sparse exists and sparsity will be preserved (later).\n            with suppress(ImportError):\n                from pandas import SparseDtype\n    \n                def is_sparse(dtype):\n                    return isinstance(dtype, SparseDtype)\n    \n                if not hasattr(array, \&#34;sparse\&#34;) and array.dtypes.apply(is_sparse).any():\n                    warnings.warn(\n                        \&#34;pandas.DataFrame with sparse columns found.\&#34;\n                        \&#34;It will be converted to a dense numpy array.\&#34;\n                    )\n    \n            dtypes_orig = list(array.dtypes)\n            pandas_requires_conversion = any(\n                _pandas_dtype_needs_early_conversion(i) for i in dtypes_orig\n            )\n            if all(isinstance(dtype_iter, np.dtype) for dtype_iter in dtypes_orig):\n                dtype_orig = np.result_type(*dtypes_orig)\n            elif pandas_requires_conversion and any(d == object for d in dtypes_orig):\n                # Force object if any of the dtypes is an object\n                dtype_orig = object\n    \n        elif (_is_extension_array_dtype(array) or hasattr(array, \&#34;iloc\&#34;)) and hasattr(\n            array, \&#34;dtype\&#34;\n        ):\n            # array is a pandas series\n            type_if_series = type(array)\n            pandas_requires_conversion = _pandas_dtype_needs_early_conversion(array.dtype)\n            if isinstance(array.dtype, np.dtype):\n                dtype_orig = array.dtype\n            else:\n                # Set to None to let array.astype work out the best dtype\n                dtype_orig = None\n    \n        if dtype_numeric:\n            if (\n                dtype_orig is not None\n                and hasattr(dtype_orig, \&#34;kind\&#34;)\n                and dtype_orig.kind == \&#34;O\&#34;\n            ):\n                # if input is object, convert to float.\n                dtype = xp.float64\n            else:\n                dtype = None\n    \n        if isinstance(dtype, (list, tuple)):\n            if dtype_orig is not None and dtype_orig in dtype:\n                # no dtype conversion required\n                dtype = None\n            else:\n                # dtype conversion required. Let&#39;s select the first element of the\n                # list of accepted types.\n                dtype = dtype[0]\n    \n        if pandas_requires_conversion:\n            # pandas dataframe requires conversion earlier to handle extension dtypes with\n            # nans\n            # Use the original dtype for conversion if dtype is None\n            new_dtype = dtype_orig if dtype is None else dtype\n            array = array.astype(new_dtype)\n            # Since we converted here, we do not need to convert again later\n            dtype = None\n    \n        if force_all_finite not in (True, False, \&#34;allow-nan\&#34;):\n            raise ValueError(\n                &#39;force_all_finite should be a bool or \&#34;allow-nan\&#34;. Got {!r} instead&#39;.format(\n                    force_all_finite\n                )\n            )\n    \n        if dtype is not None and _is_numpy_namespace(xp):\n            # convert to dtype object to conform to Array API to be use `xp.isdtype` later\n            dtype = np.dtype(dtype)\n    \n        estimator_name = _check_estimator_name(estimator)\n        context = \&#34; by %s\&#34; % estimator_name if estimator is not None else \&#34;\&#34;\n    \n        # When all dataframe columns are sparse, convert to a sparse array\n        if hasattr(array, \&#34;sparse\&#34;) and array.ndim &amp;gt; 1:\n            with suppress(ImportError):\n                from pandas import SparseDtype  # noqa: F811\n    \n                def is_sparse(dtype):\n                    return isinstance(dtype, SparseDtype)\n    \n                if array.dtypes.apply(is_sparse).all():\n                    # DataFrame.sparse only supports `to_coo`\n                    array = array.sparse.to_coo()\n                    if array.dtype == np.dtype(\&#34;object\&#34;):\n                        unique_dtypes = set([dt.subtype.name for dt in array_orig.dtypes])\n                        if len(unique_dtypes) &amp;gt; 1:\n                            raise ValueError(\n                                \&#34;Pandas DataFrame with mixed sparse extension arrays \&#34;\n                                \&#34;generated a sparse matrix with object dtype which \&#34;\n                                \&#34;can not be converted to a scipy sparse matrix.\&#34;\n                                \&#34;Sparse extension arrays should all have the same \&#34;\n                                \&#34;numeric type.\&#34;\n                            )\n    \n        if sp.issparse(array):\n            _ensure_no_complex_data(array)\n            array = _ensure_sparse_format(\n                array,\n                accept_sparse=accept_sparse,\n                dtype=dtype,\n                copy=copy,\n                force_all_finite=force_all_finite,\n                accept_large_sparse=accept_large_sparse,\n                estimator_name=estimator_name,\n                input_name=input_name,\n            )\n            if ensure_2d and array.ndim &amp;lt; 2:\n                raise ValueError(\n                    f\&#34;Expected 2D input, got input with shape {array.shape}.\\n\&#34;\n                    \&#34;Reshape your data either using array.reshape(-1, 1) if \&#34;\n                    \&#34;your data has a single feature or array.reshape(1, -1) \&#34;\n                    \&#34;if it contains a single sample.\&#34;\n                )\n        else:\n            # If np.array(..) gives ComplexWarning, then we convert the warning\n            # to an error. This is needed because specifying a non complex\n            # dtype to the function converts complex to real dtype,\n            # thereby passing the test made in the lines following the scope\n            # of warnings context manager.\n            with warnings.catch_warnings():\n                try:\n                    warnings.simplefilter(\&#34;error\&#34;, ComplexWarning)\n                    if dtype is not None and xp.isdtype(dtype, \&#34;integral\&#34;):\n                        # Conversion float -&amp;gt; int should not contain NaN or\n                        # inf (numpy#14412). We cannot use casting=&#39;safe&#39; because\n                        # then conversion float -&amp;gt; int would be disallowed.\n                        array = _asarray_with_order(array, order=order, xp=xp)\n                        if xp.isdtype(array.dtype, (\&#34;real floating\&#34;, \&#34;complex floating\&#34;)):\n                            _assert_all_finite(\n                                array,\n                                allow_nan=False,\n                                msg_dtype=dtype,\n                                estimator_name=estimator_name,\n                                input_name=input_name,\n                            )\n                        array = xp.astype(array, dtype, copy=False)\n                    else:\n                        array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n                except ComplexWarning as complex_warning:\n                    raise ValueError(\n                        \&#34;Complex data not supported\\n{}\\n\&#34;.format(array)\n                    ) from complex_warning\n    \n            # It is possible that the np.array(..) gave no warning. This happens\n            # when no dtype conversion happened, for example dtype = None. The\n            # result is that np.array(..) produces an array of complex dtype\n            # and we need to catch and raise exception for such cases.\n            _ensure_no_complex_data(array)\n    \n            if ensure_2d:\n                # If input is scalar raise error\n                if array.ndim == 0:\n                    raise ValueError(\n                        \&#34;Expected 2D array, got scalar array instead:\\narray={}.\\n\&#34;\n                        \&#34;Reshape your data either using array.reshape(-1, 1) if \&#34;\n                        \&#34;your data has a single feature or array.reshape(1, -1) \&#34;\n                        \&#34;if it contains a single sample.\&#34;.format(array)\n                    )\n                # If input is 1D raise error\n                if array.ndim == 1:\n                    # If input is a Series-like object (eg. pandas Series or polars Series)\n                    if type_if_series is not None:\n                        msg = (\n                            f\&#34;Expected a 2-dimensional container but got {type_if_series} \&#34;\n                            \&#34;instead. Pass a DataFrame containing a single row (i.e. \&#34;\n                            \&#34;single sample) or a single column (i.e. single feature) \&#34;\n                            \&#34;instead.\&#34;\n                        )\n                    else:\n                        msg = (\n                            f\&#34;Expected 2D array, got 1D array instead:\\narray={array}.\\n\&#34;\n                            \&#34;Reshape your data either using array.reshape(-1, 1) if \&#34;\n                            \&#34;your data has a single feature or array.reshape(1, -1) \&#34;\n                            \&#34;if it contains a single sample.\&#34;\n                        )\n                    raise ValueError(msg)\n    \n            if dtype_numeric and hasattr(array.dtype, \&#34;kind\&#34;) and array.dtype.kind in \&#34;USV\&#34;:\n                raise ValueError(\n                    \&#34;dtype=&#39;numeric&#39; is not compatible with arrays of bytes/strings.\&#34;\n                    \&#34;Convert your data to numeric values explicitly instead.\&#34;\n                )\n            if not allow_nd and array.ndim &amp;gt;= 3:\n                raise ValueError(\n                    \&#34;Found array with dim %d. %s expected &amp;lt;= 2.\&#34;\n                    % (array.ndim, estimator_name)\n                )\n    \n            if force_all_finite:\n                _assert_all_finite(\n                    array,\n                    input_name=input_name,\n                    estimator_name=estimator_name,\n                    allow_nan=force_all_finite == \&#34;allow-nan\&#34;,\n                )\n    \n            if copy:\n                if _is_numpy_namespace(xp):\n                    # only make a copy if `array` and `array_orig` may share memory`\n                    if np.may_share_memory(array, array_orig):\n                        array = _asarray_with_order(\n                            array, dtype=dtype, order=order, copy=True, xp=xp\n                        )\n                else:\n                    # always make a copy for non-numpy arrays\n                    array = _asarray_with_order(\n                        array, dtype=dtype, order=order, copy=True, xp=xp\n                    )\n    \n        if ensure_min_samples &amp;gt; 0:\n            n_samples = _num_samples(array)\n            if n_samples &amp;lt; ensure_min_samples:\n                raise ValueError(\n                    \&#34;Found array with %d sample(s) (shape=%s) while a\&#34;\n                    \&#34; minimum of %d is required%s.\&#34;\n                    % (n_samples, array.shape, ensure_min_samples, context)\n                )\n    \n        if ensure_min_features &amp;gt; 0 and array.ndim == 2:\n            n_features = array.shape[1]\n            if n_features &amp;lt; ensure_min_features:\n&amp;gt;               raise ValueError(\n                    \&#34;Found array with %d feature(s) (shape=%s) while\&#34;\n                    \&#34; a minimum of %d is required%s.\&#34;\n                    % (n_features, array.shape, ensure_min_features, context)\n                )\nE               ValueError: Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by Lasso.\n\naccept_large_sparse = False\naccept_sparse = &#39;csc&#39;\nallow_nd   = False\narray      = array([], shape=(10, 0), dtype=float64)\narray_orig = array([], shape=(10, 0), dtype=float64)\ncontext    = &#39; by Lasso&#39;\ncopy       = True\ndtype      = None\ndtype_numeric = False\ndtype_orig = dtype(&#39;float64&#39;)\ndtypes_orig = None\nensure_2d  = True\nensure_min_features = 1\nensure_min_samples = 1\nestimator  = Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7F4FF3AA2440)\nestimator_name = &#39;Lasso&#39;\nforce_all_finite = True\ninput_name = &#39;X&#39;\nis_array_api_compliant = False\nn_features = 0\nn_samples  = 10\norder      = &#39;F&#39;\npandas_requires_conversion = False\ntype_if_series = None\nxp         = &amp;lt;sklearn.utils._array_api._NumPyAPIWrapper object at 0x7f50011a7a90&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1091: ValueError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = DesparsifiedLasso(confidence=0.9, random_state=0)\ncheck = functools.partial(&amp;lt;function check_fit2d_1feature at 0x7f4ffd4cbd00&amp;gt;, &#39;DesparsifiedLasso&#39;)\nname = &#39;check_fit2d_1feature&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit2d_1feature at 0x7f4ffd4cbd00&amp;gt;, &#39;DesparsifiedLasso&#39;)\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\nname       = &#39;check_fit2d_1feature&#39;\n\ntest/test_desparsified_lasso.py:70: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;DesparsifiedLasso&#39;, DesparsifiedLasso(confidence=0.9, random_state=0))\n        fn         = &amp;lt;function check_fit2d_1feature at 0x7f4ffd4cbc70&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1672: in check_fit2d_1feature\n    with raises(ValueError, match=msgs, may_pass=True):\n        X          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\n        estimator  = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7F4FF3AA2240),\n                  random_state=1)\n        estimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n        msgs       = [&#39;1 feature\\\\(s\\\\)&#39;, &#39;n_features = 1&#39;, &#39;n_features=1&#39;]\n        name       = &#39;DesparsifiedLasso&#39;\n        rnd        = RandomState(MT19937) at 0x7F4FF3AA1C40\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4ff0f9cf40&amp;gt;\nexc_type = &amp;lt;class &#39;ValueError&#39;&amp;gt;\nexc_value = ValueError(&#39;Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by Lasso.&#39;)\n_ = &amp;lt;traceback object at 0x7f4ff1541f00&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f\&#34;Did not raise: {self.expected_exc_types}\&#34;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n                raise AssertionError(self.err_msg) from exc_value\n            else:\n                return False  # will re-raise the original exception\n    \n        if self.matches is not None:\n            err_msg = self.err_msg or (\n                \&#34;The error message should contain one of the following \&#34;\n                \&#34;patterns:\\n{}\\nGot {}\&#34;.format(\&#34;\\n\&#34;.join(self.matches), str(exc_value))\n            )\n            if not any(re.search(match, str(exc_value)) for match in self.matches):\n&amp;gt;               raise AssertionError(err_msg) from exc_value\nE               AssertionError: The error message should contain one of the following patterns:\nE               1 feature\\(s\\)\nE               n_features = 1\nE               n_features=1\nE               Got Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by Lasso.\n\n_          = &amp;lt;traceback object at 0x7f4ff1541f00&amp;gt;\nerr_msg    = &#39;The error message should contain one of the following patterns:\\n1 feature\\\\(s\\\\)\\nn_features = 1\\nn_features=1\\nGot Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by Lasso.&#39;\nexc_type   = &amp;lt;class &#39;ValueError&#39;&amp;gt;\nexc_value  = ValueError(&#39;Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by Lasso.&#39;)\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4ff0f9cf40&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:925: AssertionError\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator16-check16-check_fit2d_1sample]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator16-check16-check_fit2d_1sample]&#34;, &#34;duration&#34;: &#34;12 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator16-check16-check_fit2d_1sample]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;12 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator4-check4-check_fit_check_is_fitted]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator4-check4-check_fit_check_is_fitted]&#34;, &#34;duration&#34;: &#34;10 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator4-check4-check_fit_check_is_fitted]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;10 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = DesparsifiedLasso(confidence=0.9, random_state=0)\ncheck = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7f4ffd4dba30&amp;gt;, &#39;DesparsifiedLasso&#39;)\nname = &#39;check_fit_check_is_fitted&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7f4ffd4dba30&amp;gt;, &#39;DesparsifiedLasso&#39;)\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\nname       = &#39;check_fit_check_is_fitted&#39;\n\ntest/test_desparsified_lasso.py:70: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;DesparsifiedLasso&#39;\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n\n    def check_fit_check_is_fitted(name, estimator_orig):\n        # Make sure that estimator doesn&#39;t pass check_is_fitted before calling fit\n        # and that passes check_is_fitted once it&#39;s fit.\n    \n        rng = np.random.RandomState(42)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if \&#34;warm_start\&#34; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if not _safe_tags(estimator).get(\&#34;stateless\&#34;, False):\n            # stateless estimators (such as FunctionTransformer) are always \&#34;fit\&#34;!\n            try:\n                check_is_fitted(estimator)\n&amp;gt;               raise AssertionError(\n                    f\&#34;{estimator.__class__.__name__} passes check_is_fitted before being\&#34;\n                    \&#34; fit!\&#34;\n                )\nE               AssertionError: DesparsifiedLasso passes check_is_fitted before being fit!\n\nX          = array([[100.49671415,  99.8617357 ],\n       [100.64768854, 101.52302986],\n       [ 99.76584663,  99.76586304],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\nn_samples  = 100\nname       = &#39;DesparsifiedLasso&#39;\nrng        = RandomState(MT19937) at 0x7F4FF3AA2940\ny          = array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,...1,\n       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3914: AssertionError\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator21-check21-check_fit_idempotent]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator21-check21-check_fit_idempotent]&#34;, &#34;duration&#34;: &#34;193 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator21-check21-check_fit_idempotent]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;193 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_ensemble_clustered_inference.py::test_cludl_spatial&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_ensemble_clustered_inference.py::test_cludl_spatial&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_ensemble_clustered_inference.py::test_cludl_spatial&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator0-check0-check_estimators_dtypes]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator0-check0-check_estimators_dtypes]&#34;, &#34;duration&#34;: &#34;757 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator0-check0-check_estimators_dtypes]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;757 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator2-check2-check_estimators_fit_returns_self]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator2-check2-check_estimators_fit_returns_self]&#34;, &#34;duration&#34;: &#34;106 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator2-check2-check_estimators_fit_returns_self]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;106 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_function_not_center&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_function_not_center&#34;, &#34;duration&#34;: &#34;207 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_function_not_center&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;207 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator18-check18-check_set_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator18-check18-check_set_params]&#34;, &#34;duration&#34;: &#34;44 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator18-check18-check_set_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;44 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator12-check12-check_estimators_pickle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator12-check12-check_estimators_pickle]&#34;, &#34;duration&#34;: &#34;150 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator12-check12-check_estimators_pickle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;150 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_reid_exception&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_reid_exception&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_reid_exception&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nGroup reid: AR1 cov estimation\nGroup reid: AR10000.0 cov estimation\n&#34;}], &#34;test/test_desparsified_lasso.py::test_reid&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_reid&#34;, &#34;duration&#34;: &#34;322 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_reid&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;322 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator1-check1-check_fit_score_takes_y]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator1-check1-check_fit_score_takes_y]&#34;, &#34;duration&#34;: &#34;140 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator1-check1-check_fit_score_takes_y]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;140 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_group_reid_2&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_group_reid_2&#34;, &#34;duration&#34;: &#34;454 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_group_reid_2&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;454 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nGroup reid: simple cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: simple cov estimation\n&#34;}], &#34;test/test_desparsified_lasso.py::test_dl_reproducibility_with_rng&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_dl_reproducibility_with_rng&#34;, &#34;duration&#34;: &#34;00:00:05&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_dl_reproducibility_with_rng&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:05&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator5-check5-check_n_features_in]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator5-check5-check_n_features_in]&#34;, &#34;duration&#34;: &#34;103 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator5-check5-check_n_features_in]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;103 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = DesparsifiedLasso(confidence=0.9, random_state=0)\ncheck = functools.partial(&amp;lt;function check_n_features_in at 0x7f4ffd4dbac0&amp;gt;, &#39;DesparsifiedLasso&#39;)\nname = &#39;check_n_features_in&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_n_features_in at 0x7f4ffd4dbac0&amp;gt;, &#39;DesparsifiedLasso&#39;)\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\nname       = &#39;check_n_features_in&#39;\n\ntest/test_desparsified_lasso.py:70: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;DesparsifiedLasso&#39;\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n\n    def check_n_features_in(name, estimator_orig):\n        # Make sure that n_features_in_ attribute doesn&#39;t exist until fit is\n        # called, and that its value is correct.\n    \n        rng = np.random.RandomState(0)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if \&#34;warm_start\&#34; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        assert not hasattr(estimator, \&#34;n_features_in_\&#34;)\n        estimator.fit(X, y)\n&amp;gt;       assert hasattr(estimator, \&#34;n_features_in_\&#34;)\nE       AssertionError\n\nX          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\nestimator  = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7F4FF3AA2440),\n                  random_state=0)\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\nn_samples  = 100\nname       = &#39;DesparsifiedLasso&#39;\nrng        = RandomState(MT19937) at 0x7F4FF3AA1B40\ny          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3951: AssertionError\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator23-check23-check_fit2d_predict1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator23-check23-check_fit2d_predict1d]&#34;, &#34;duration&#34;: &#34;108 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator23-check23-check_fit2d_predict1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;108 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator17-check17-check_get_params_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator17-check17-check_get_params_invariance]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator17-check17-check_get_params_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator0-check0-check_no_attributes_set_in_init]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator0-check0-check_no_attributes_set_in_init]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_invalid[estimator0-check0-check_no_attributes_set_in_init]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = DesparsifiedLasso(confidence=0.9, random_state=0)\ncheck = functools.partial(&amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4dab00&amp;gt;, &#39;DesparsifiedLasso&#39;)\nname = &#39;check_no_attributes_set_in_init&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4dab00&amp;gt;, &#39;DesparsifiedLasso&#39;)\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\nname       = &#39;check_no_attributes_set_in_init&#39;\n\ntest/test_desparsified_lasso.py:70: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;DesparsifiedLasso&#39;, DesparsifiedLasso(confidence=0.9, random_state=0))\n        fn         = &amp;lt;function check_no_attributes_set_in_init at 0x7f4ffd4daa70&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;DesparsifiedLasso&#39;\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n\n    @ignore_warnings(category=FutureWarning)\n    def check_no_attributes_set_in_init(name, estimator_orig):\n        \&#34;\&#34;\&#34;Check setting during init.\&#34;\&#34;\&#34;\n        try:\n            # Clone fails if the estimator does not store\n            # all parameters as an attribute during init\n            estimator = clone(estimator_orig)\n        except AttributeError:\n            raise AttributeError(\n                f\&#34;Estimator {name} should store all parameters as an attribute during init.\&#34;\n            )\n    \n        if hasattr(type(estimator).__init__, \&#34;deprecated_original\&#34;):\n            return\n    \n        init_params = _get_args(type(estimator).__init__)\n        if _IS_PYPY:\n            # __init__ signature has additional objects in PyPy\n            for key in [\&#34;obj\&#34;]:\n                if key in init_params:\n                    init_params.remove(key)\n        parents_init_params = [\n            param\n            for params_parent in (_get_args(parent) for parent in type(estimator).__mro__)\n            for param in params_parent\n        ]\n    \n        # Test for no setting apart from parameters during init\n        invalid_attr = set(vars(estimator)) - set(init_params) - set(parents_init_params)\n        # Ignore private attributes\n        invalid_attr = set([attr for attr in invalid_attr if not attr.startswith(\&#34;_\&#34;)])\n&amp;gt;       assert not invalid_attr, (\n            \&#34;Estimator %s should not set any attribute apart\&#34;\n            \&#34; from parameters during init. Found attributes %s.\&#34;\n            % (name, sorted(invalid_attr))\n        )\nE       AssertionError: Estimator DesparsifiedLasso should not set any attribute apart from parameters during init. Found attributes [&#39;clf_&#39;, &#39;confidence_bound_max_&#39;, &#39;confidence_bound_min_&#39;, &#39;importances_&#39;, &#39;n_samples_&#39;, &#39;n_task_&#39;, &#39;precision_diagonal_&#39;, &#39;pvalues_&#39;, &#39;pvalues_corr_&#39;, &#39;sigma_hat_&#39;].\n\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\ninit_params = [&#39;self&#39;, &#39;estimator&#39;, &#39;centered&#39;, &#39;dof_ajdustement&#39;, &#39;model_x&#39;, &#39;preconfigure_model_x_path&#39;, ...]\ninvalid_attr = {&#39;clf_&#39;, &#39;confidence_bound_max_&#39;, &#39;confidence_bound_min_&#39;, &#39;importances_&#39;, &#39;n_samples_&#39;, &#39;n_task_&#39;, ...}\nname       = &#39;DesparsifiedLasso&#39;\nparents_init_params = [&#39;estimator&#39;, &#39;centered&#39;, &#39;dof_ajdustement&#39;, &#39;model_x&#39;, &#39;preconfigure_model_x_path&#39;, &#39;alpha_max_fraction&#39;, ...]\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3308: AssertionError\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator20-check20-check_dont_overwrite_parameters]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator20-check20-check_dont_overwrite_parameters]&#34;, &#34;duration&#34;: &#34;152 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator20-check20-check_dont_overwrite_parameters]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;152 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_group_reid&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_group_reid&#34;, &#34;duration&#34;: &#34;427 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_group_reid&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;427 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nGroup reid: simple cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: simple cov estimation\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator7-check7-check_pipeline_consistency]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator7-check7-check_pipeline_consistency]&#34;, &#34;duration&#34;: &#34;210 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator7-check7-check_pipeline_consistency]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;210 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator9-check9-check_estimator_sparse_array]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator9-check9-check_estimator_sparse_array]&#34;, &#34;duration&#34;: &#34;44 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator9-check9-check_estimator_sparse_array]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;44 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator22-check22-check_fit1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator22-check22-check_fit1d]&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator22-check22-check_fit1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator14-check14-check_methods_sample_order_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator14-check14-check_methods_sample_order_invariance]&#34;, &#34;duration&#34;: &#34;214 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator14-check14-check_methods_sample_order_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;214 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_ensemble_clustered_inference.py::test_encludl_temporal&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_ensemble_clustered_inference.py::test_encludl_temporal&#34;, &#34;duration&#34;: &#34;00:00:15&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_ensemble_clustered_inference.py::test_encludl_temporal&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:15&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  3.70it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  3.79it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  3.94it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&lt;00:00,  3.96it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  4.06it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 627.59it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  3.57it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  3.53it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  3.57it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  3.58it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.85it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 808.21it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:00,  4.70it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  3.96it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  4.03it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  4.07it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  4.11it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 753.45it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:00,  4.44it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  4.51it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  4.06it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&lt;00:00,  4.08it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.99it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 703.27it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:00,  4.07it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  4.01it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  4.06it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&lt;00:00,  4.18it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  4.20it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 808.99it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  3.03it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  3.32it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  3.46it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  3.55it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.33it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 758.82it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:00,  4.45it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  4.23it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  3.68it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  3.11it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.93it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 714.09it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.95it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.91it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  3.01it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.92it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.99it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 727.93it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.33it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.48it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.56it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.53it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.50it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 740.86it/s]\n\u0101\r \r\rFitting clustered inferences:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.30it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.47it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.63it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.66it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.83it/s]\n\u0101\r \r\rComputing importances:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 732.71it/s]\n&#34;}], &#34;test/test_ensemble_clustered_inference.py::test_cludl_independence&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_ensemble_clustered_inference.py::test_cludl_independence&#34;, &#34;duration&#34;: &#34;417 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_ensemble_clustered_inference.py::test_cludl_independence&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;417 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_desparsified_group_lasso&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_desparsified_group_lasso&#34;, &#34;duration&#34;: &#34;00:00:10&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_desparsified_group_lasso&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:10&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator19-check19-check_dict_unchanged]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator19-check19-check_dict_unchanged]&#34;, &#34;duration&#34;: &#34;179 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn_valid[estimator19-check19-check_dict_unchanged]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;179 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_desparsified_lasso&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_desparsified_lasso&#34;, &#34;duration&#34;: &#34;00:00:05&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_desparsified_lasso&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:05&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_ensemble_clustered_inference.py::test_cludl_temporal&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_ensemble_clustered_inference.py::test_cludl_temporal&#34;, &#34;duration&#34;: &#34;00:00:09&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_ensemble_clustered_inference.py::test_cludl_temporal&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:09&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\n&#34;}], &#34;test/statistical_tools/test_aggregation.py::test_adaptive_quantiles&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_aggregation.py::test_adaptive_quantiles&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_aggregation.py::test_adaptive_quantiles&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_aggregation.py::test_fixed_aggregate_quantiles&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_aggregation.py::test_fixed_aggregate_quantiles&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_aggregation.py::test_fixed_aggregate_quantiles&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_aggregation.py::test_quantile_aggregation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_aggregation.py::test_quantile_aggregation&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_aggregation.py::test_quantile_aggregation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::test_preconfigure_LassoCV&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_preconfigure_LassoCV&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_preconfigure_LassoCV&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_warning[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_warning[default data]&#34;, &#34;duration&#34;: &#34;671 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::TestModelXKnockoffExceptions::test_warning[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;671 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_error_lasso_statistic_with_sampling_with_bad_config[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_error_lasso_statistic_with_sampling_with_bad_config[default data]&#34;, &#34;duration&#34;: &#34;9 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::TestModelXKnockoffExceptions::test_error_lasso_statistic_with_sampling_with_bad_config[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;9 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::test_model_x_knockoff_estimator&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_model_x_knockoff_estimator&#34;, &#34;duration&#34;: &#34;159 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_model_x_knockoff_estimator&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;159 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_invalid_n_samplings[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_invalid_n_samplings[default data]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::TestModelXKnockoffExceptions::test_invalid_n_samplings[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::test_knockoff_bootstrap_quantile&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_knockoff_bootstrap_quantile&#34;, &#34;duration&#34;: &#34;00:00:05&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_knockoff_bootstrap_quantile&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:05&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 112.95256047077078, tolerance: 0.22229032839135854\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 114.87682722841942, tolerance: 0.2161246437414636\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.78422331751017, tolerance: 0.22229032839135854\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.92456651142993, tolerance: 0.22832688394028866\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.670613795850386, tolerance: 0.2161246437414636\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.91595692890405, tolerance: 0.22832688394028866\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57.21064596189626, tolerance: 0.22229032839135854\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 115.9933046765259, tolerance: 0.1822639018684545\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54.68354100692295, tolerance: 0.22229032839135854\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71.63998052735383, tolerance: 0.1822639018684545\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 73.89722248231851, tolerance: 0.2161246437414636\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.499557631967264, tolerance: 0.20895890060676517\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 119.88212671440692, tolerance: 0.20895890060676517\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68.66606232209733, tolerance: 0.2161246437414636\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.4035298816043, tolerance: 0.22832688394028866\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75.26213746411963, tolerance: 0.1822639018684545\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.72478631157037, tolerance: 0.22832688394028866\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 67.89590272570399, tolerance: 0.20895890060676517\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 73.75501996823823, tolerance: 0.1822639018684545\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 67.93952005130018, tolerance: 0.20895890060676517\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.35777295634807, tolerance: 0.22229032839135854\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55.55202484942902, tolerance: 0.2161246437414636\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.00081043043019, tolerance: 0.22832688394028866\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55.78819102467969, tolerance: 0.1822639018684545\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57.499132972907546, tolerance: 0.20895890060676517\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56.20663868030306, tolerance: 0.21930396750823547\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.7177266264896, tolerance: 0.21930396750823547\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56.60290219086255, tolerance: 0.21930396750823547\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.57363347943942, tolerance: 0.19355899838464666\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56.85748517914499, tolerance: 0.21930396750823547\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.114516490456026, tolerance: 0.21930396750823547\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65.10695368820006, tolerance: 0.19355899838464666\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69.27485604835101, tolerance: 0.19375650161978822\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 110.3515009035766, tolerance: 0.19355899838464666\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.97538150748733, tolerance: 0.19569270189069238\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65.52242115169315, tolerance: 0.19375650161978822\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.05562622092498, tolerance: 0.19355899838464666\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 114.16761346641988, tolerance: 0.19375650161978822\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.42113689759549, tolerance: 0.19355899838464666\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.14542228305504, tolerance: 0.20075698118461463\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 62.74236278826697, tolerance: 0.19375650161978822\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104.47434668194137, tolerance: 0.19569270189069238\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54.68331041699662, tolerance: 0.19569270189069238\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 73.14701268527847, tolerance: 0.19375650161978822\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 62.48293760403749, tolerance: 0.19569270189069238\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104.88210046724862, tolerance: 0.20075698118461463\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60.17337019216825, tolerance: 0.20075698118461463\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.27454708405412, tolerance: 0.19569270189069238\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.31982775937672, tolerance: 0.20075698118461463\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.62161080008696, tolerance: 0.20075698118461463\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.99914892434526, tolerance: 0.17258613850725232\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 113.78670253791779, tolerance: 0.17258613850725232\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.7669447364558, tolerance: 0.17258613850725232\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60.28448144833715, tolerance: 0.17258613850725232\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69.17686843071488, tolerance: 0.17258613850725232\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 119.38039486546495, tolerance: 0.17658630668272918\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.71270567527199, tolerance: 0.17658630668272918\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.400919189920614, tolerance: 0.17658630668272918\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 72.92203451218847, tolerance: 0.17658630668272918\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.63588054874026, tolerance: 0.17658630668272918\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.10659264792707, tolerance: 0.1850691522238255\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.07820654159127, tolerance: 0.1850691522238255\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.1308351956834, tolerance: 0.1850691522238255\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 121.01882350857477, tolerance: 0.1850691522238255\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.481992854765394, tolerance: 0.17501699206078336\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66.50739536516244, tolerance: 0.17501699206078336\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.825406774911016, tolerance: 0.17501699206078336\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 67.15270582649805, tolerance: 0.1850691522238255\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 131.4328028869843, tolerance: 0.17501699206078336\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.40050586607367, tolerance: 0.19059368525916895\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.6953264208496, tolerance: 0.19059368525916895\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66.652391393485, tolerance: 0.19059368525916895\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 85.35175135314284, tolerance: 0.17501699206078336\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 124.42090859900372, tolerance: 0.19059368525916895\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56.54952981077713, tolerance: 0.19059368525916895\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60.72670172781591, tolerance: 0.19269159009818052\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.6900340711868, tolerance: 0.19269159009818052\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.65482718310818, tolerance: 0.19269159009818052\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.06473181610659, tolerance: 0.19269159009818052\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.87849996238879, tolerance: 0.19269159009818052\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68.0368972862102, tolerance: 0.17459903681564132\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.193845630855094, tolerance: 0.17459903681564132\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65.81275929634035, tolerance: 0.17459903681564132\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55.72454372343418, tolerance: 0.17459903681564132\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 107.04177418225436, tolerance: 0.17459903681564132\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.311906790270996, tolerance: 0.17248820396645378\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.18339119713937, tolerance: 0.17248820396645378\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55.076675432587535, tolerance: 0.17248820396645378\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 99.7179617496879, tolerance: 0.17248820396645378\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70.94091056242814, tolerance: 0.19348377099586647\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.07803523433927, tolerance: 0.17248820396645378\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68.48492907975947, tolerance: 0.19348377099586647\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 103.69684053077299, tolerance: 0.19348377099586647\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 62.6832923683412, tolerance: 0.19396617379393974\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.96288270783771, tolerance: 0.19348377099586647\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 76.27251803947479, tolerance: 0.19396617379393974\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.54645699855223, tolerance: 0.19348377099586647\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 114.26257977348632, tolerance: 0.19396617379393974\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.96831828728159, tolerance: 0.19396617379393974\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 72.37342842702378, tolerance: 0.19396617379393974\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 126.92820191900273, tolerance: 0.20347695927607304\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 62.85460046147409, tolerance: 0.20347695927607304\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65.34195461208469, tolerance: 0.20347695927607304\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 76.5469431415263, tolerance: 0.20347695927607304\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 74.88484610896285, tolerance: 0.20347695927607304\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.47557432377789, tolerance: 0.22262009111570083\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 124.81770191412215, tolerance: 0.22262009111570083\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 83.31659750491417, tolerance: 0.22262009111570083\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.919809363047534, tolerance: 0.22262009111570083\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71.39909642507382, tolerance: 0.22262009111570083\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75.4002091326106, tolerance: 0.21857597160830256\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69.03902192916416, tolerance: 0.21857597160830256\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71.26904506259643, tolerance: 0.21857597160830256\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.499956518242925, tolerance: 0.1943221940202922\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.39221666840899, tolerance: 0.1943221940202922\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 67.93159178191218, tolerance: 0.1943221940202922\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 123.89374443287761, tolerance: 0.21857597160830256\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 72.71739227882381, tolerance: 0.21857597160830256\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66.16622655668084, tolerance: 0.21007157107559316\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 85.17898757304988, tolerance: 0.21007157107559316\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 74.09082817526678, tolerance: 0.21007157107559316\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.60621481969292, tolerance: 0.1943221940202922\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 116.76895158903403, tolerance: 0.1943221940202922\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 76.8405791082348, tolerance: 0.21007157107559316\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 137.9848995458699, tolerance: 0.21007157107559316\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 113.8371199653584, tolerance: 0.2029221802062962\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68.9775998355858, tolerance: 0.2029221802062962\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 62.40917800378497, tolerance: 0.2029221802062962\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65.95605402245292, tolerance: 0.2029221802062962\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 76.80907757655655, tolerance: 0.2029221802062962\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75.84168292128288, tolerance: 0.2074824058261318\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.33283662154645, tolerance: 0.2074824058261318\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69.3308583694793, tolerance: 0.2074824058261318\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 81.37591428547739, tolerance: 0.2074824058261318\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 126.95376074050364, tolerance: 0.2074824058261318\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68.06094880256046, tolerance: 0.2027564361440529\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 67.41160940936311, tolerance: 0.2027564361440529\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80.21766359856724, tolerance: 0.2027564361440529\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71.78705489634467, tolerance: 0.20853210955384485\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69.011499932064, tolerance: 0.20853210955384485\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.84831138118648, tolerance: 0.2027564361440529\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.62784088654848, tolerance: 0.20853210955384485\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 120.64246018228982, tolerance: 0.2027564361440529\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 73.608937756037, tolerance: 0.19983808776725426\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57.77539323311021, tolerance: 0.19983808776725426\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77.48027820509515, tolerance: 0.19983808776725426\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.10495140509147, tolerance: 0.20853210955384485\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 125.23867590047666, tolerance: 0.20853210955384485\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68.18769749461853, tolerance: 0.19983808776725426\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 124.7880009710691, tolerance: 0.19983808776725426\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57.2040468015025, tolerance: 0.17971947954667786\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.2169905474841, tolerance: 0.17971947954667786\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.18497708242694, tolerance: 0.17971947954667786\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 93.03427852090886, tolerance: 0.17971947954667786\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.47829885989381, tolerance: 0.17971947954667786\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.472397309258895, tolerance: 0.17089484341707026\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.073239736235564, tolerance: 0.17089484341707026\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.778247724894754, tolerance: 0.17089484341707026\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.257135459728715, tolerance: 0.16835108015350148\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.81196955031896, tolerance: 0.16835108015350148\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.953970727378874, tolerance: 0.17089484341707026\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54.09887746878212, tolerance: 0.16835108015350148\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 108.2907810185095, tolerance: 0.17089484341707026\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.568373229552435, tolerance: 0.16553031406342014\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.16996229771121, tolerance: 0.16553031406342014\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.91854801939212, tolerance: 0.15381964194551695\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55.98360057656896, tolerance: 0.16835108015350148\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.2592731513389, tolerance: 0.15381964194551695\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 105.46255536152603, tolerance: 0.16835108015350148\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.788627424072274, tolerance: 0.16553031406342014\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.325137123730656, tolerance: 0.16553031406342014\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 109.15779175415673, tolerance: 0.16553031406342014\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.42211217589238, tolerance: 0.15381964194551695\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.14221081202368, tolerance: 0.15381964194551695\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 87.2958694363208, tolerance: 0.15381964194551695\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.76922474187313, tolerance: 0.16825563739144342\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65.50613015248132, tolerance: 0.16825563739144342\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57.493386081619974, tolerance: 0.16825563739144342\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104.4386106606321, tolerance: 0.16825563739144342\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.5421247701604, tolerance: 0.16825563739144342\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.71638317600218, tolerance: 0.18502972660802203\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.09244904493903, tolerance: 0.18502972660802203\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 62.97377675496432, tolerance: 0.18502972660802203\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55.760978610927395, tolerance: 0.1728288669153154\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60.285373651267946, tolerance: 0.1728288669153154\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69.58515207467894, tolerance: 0.1728288669153154\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.31986106111617, tolerance: 0.18502972660802203\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 116.60405299590843, tolerance: 0.18502972660802203\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.24981667889119, tolerance: 0.1892715172091438\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55.615541947265, tolerance: 0.1892715172091438\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.961384181807944, tolerance: 0.1892715172091438\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54.42244018917836, tolerance: 0.18921961489842384\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 67.98321037262849, tolerance: 0.1728288669153154\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70.7007673803962, tolerance: 0.18921961489842384\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 120.0950034032569, tolerance: 0.1728288669153154\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70.89958543764533, tolerance: 0.18921961489842384\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60.844507810304094, tolerance: 0.1892715172091438\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.86875746149667, tolerance: 0.1892715172091438\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66.05835624733254, tolerance: 0.18921961489842384\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 116.86118945651083, tolerance: 0.18921961489842384\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.32676289028336, tolerance: 0.17799572325430127\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.56228379945128, tolerance: 0.17799572325430127\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65.08055972576312, tolerance: 0.17799572325430127\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 105.24321078716434, tolerance: 0.17799572325430127\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56.79345422474921, tolerance: 0.17799572325430127\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.1787951356323, tolerance: 0.1605586119381105\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.47778196065451, tolerance: 0.1605586119381105\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 82.22333929706247, tolerance: 0.1605586119381105\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68.55720464532374, tolerance: 0.17355649667602566\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.585492279976734, tolerance: 0.17355649667602566\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.693332907067315, tolerance: 0.1605586119381105\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 110.18954663406066, tolerance: 0.17355649667602566\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.49298989334284, tolerance: 0.1709393543627404\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.24255714907986, tolerance: 0.1605586119381105\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56.09845050389572, tolerance: 0.1709393543627404\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 106.04104771150946, tolerance: 0.1709393543627404\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55.595821447533126, tolerance: 0.17074416457646904\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.6622135521136, tolerance: 0.17355649667602566\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.598887249906966, tolerance: 0.17355649667602566\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.89308575763198, tolerance: 0.17074416457646904\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.0841592566062, tolerance: 0.17074416457646904\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54.969143856392975, tolerance: 0.1709393543627404\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.99040333499056, tolerance: 0.1709393543627404\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.10095483346481, tolerance: 0.17074416457646904\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.381815260949224, tolerance: 0.17074416457646904\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.458676581220516, tolerance: 0.15525696934554442\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.34074867262114594, tolerance: 0.15525696934554442\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.65238543354326, tolerance: 0.15525696934554442\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.05270035446574, tolerance: 0.15525696934554442\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.87649036988819, tolerance: 0.15525696934554442\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 110.88959588176908, tolerance: 0.15525696934554442\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60.6644927088837, tolerance: 0.17784736480024718\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 67.92274222892365, tolerance: 0.17784736480024718\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.81406319450866, tolerance: 0.17784736480024718\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54.24334902175838, tolerance: 0.17908115965387902\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.40461827944205, tolerance: 0.17908115965387902\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.93124253507585, tolerance: 0.17784736480024718\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 110.92543624353857, tolerance: 0.17784736480024718\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.564247234935465, tolerance: 0.17908115965387902\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56.107034831690044, tolerance: 0.18454118333860883\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65.6890272679309, tolerance: 0.18454118333860883\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55.38837695049233, tolerance: 0.18454118333860883\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54.362022185310025, tolerance: 0.1847103993165802\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.057210796873505, tolerance: 0.17908115965387902\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.23808109435595, tolerance: 0.1847103993165802\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 103.07084831536258, tolerance: 0.17908115965387902\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.65417088701861, tolerance: 0.1847103993165802\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.6046034123101, tolerance: 0.18454118333860883\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 100.68131160464372, tolerance: 0.18454118333860883\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.555179327616315, tolerance: 0.1847103993165802\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3057660958074848, tolerance: 0.1847103993165802\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6964318601395121, tolerance: 0.1847103993165802\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 110.73926254426465, tolerance: 0.1847103993165802\n  model = cd_fast.enet_coordinate_descent_gram(\n&#34;}], &#34;test/test_knockoff.py::test_invariant_with_bootstrap&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_invariant_with_bootstrap&#34;, &#34;duration&#34;: &#34;915 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_invariant_with_bootstrap&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;915 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::test_knockoff_bootstrap_e_values&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_knockoff_bootstrap_e_values&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_knockoff_bootstrap_e_values&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.939163431546831, tolerance: 0.19198785172796848\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.64883757355642, tolerance: 0.19198785172796848\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.185034893360125, tolerance: 0.19198785172796848\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.544303282331612, tolerance: 0.19198785172796848\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.462152024430452, tolerance: 0.19198785172796848\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.073533405601665, tolerance: 0.1837129996979553\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.72907223782704, tolerance: 0.1837129996979553\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.949504254440853, tolerance: 0.1837129996979553\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.546441012862715, tolerance: 0.1837129996979553\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.174368270141258, tolerance: 0.19355897623205728\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.519497861181662, tolerance: 0.19355897623205728\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.68000388272344, tolerance: 0.1837129996979553\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.519463517411168, tolerance: 0.19355897623205728\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.19374695739998, tolerance: 0.15114460390078313\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.52422187003549, tolerance: 0.15114460390078313\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.250551544001155, tolerance: 0.19355897623205728\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.123953855706986, tolerance: 0.15114460390078313\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.203055879994281, tolerance: 0.17417606044076614\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.615550008013997, tolerance: 0.17417606044076614\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.125126629756096, tolerance: 0.19355897623205728\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.759708978768458, tolerance: 0.15114460390078313\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.731582299126103, tolerance: 0.17417606044076614\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.608734800890716, tolerance: 0.17417606044076614\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.716904847603928, tolerance: 0.15114460390078313\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.984239527014324, tolerance: 0.17417606044076614\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.782287293796117, tolerance: 0.18038936671366881\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.844203467320767, tolerance: 0.18038936671366881\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.883982059240225, tolerance: 0.18038936671366881\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.26839478538841, tolerance: 0.18038936671366881\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.08963023116371, tolerance: 0.1594364829953304\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.299143201635161, tolerance: 0.18038936671366881\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.172961513780365, tolerance: 0.1594364829953304\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.227441597018924, tolerance: 0.1594364829953304\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.24242201618449, tolerance: 0.1594364829953304\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.824196257554377, tolerance: 0.16502051096891793\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.803494185667205, tolerance: 0.16502051096891793\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.284552640249103, tolerance: 0.1594364829953304\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.838689604127467, tolerance: 0.16502051096891793\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.237878304950982, tolerance: 0.16502051096891793\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.996153360546032, tolerance: 0.15911019228595638\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.429220732075692, tolerance: 0.16502051096891793\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.762959000628598, tolerance: 0.15911019228595638\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.32411666905432, tolerance: 0.15911019228595638\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.268723087402577, tolerance: 0.17074497588244117\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.544267252657164, tolerance: 0.15911019228595638\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.387828198008947, tolerance: 0.17074497588244117\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.855397981883243, tolerance: 0.15911019228595638\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.585222231727812, tolerance: 0.17074497588244117\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.402089092526921, tolerance: 0.17074497588244117\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.097126687512173, tolerance: 0.17074497588244117\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.119835115069918, tolerance: 0.15701040222262108\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.12486701942953, tolerance: 0.15701040222262108\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.419450226302843, tolerance: 0.15701040222262108\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.808885692299327, tolerance: 0.15701040222262108\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.39406789252962, tolerance: 0.15538205449414222\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.779172271550124, tolerance: 0.15701040222262108\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.099356335741504, tolerance: 0.15538205449414222\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.187643623423355, tolerance: 0.15538205449414222\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.17386026176223, tolerance: 0.15538205449414222\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.855969772122535, tolerance: 0.16820147308360395\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.301692999326178, tolerance: 0.16820147308360395\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.547905101235756, tolerance: 0.16820147308360395\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.65318669773046, tolerance: 0.15538205449414222\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.606561383556482, tolerance: 0.15733494183275876\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.492610285391038, tolerance: 0.16820147308360395\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.34771980858045, tolerance: 0.15733494183275876\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.391780525807235, tolerance: 0.15733494183275876\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.90919117321414, tolerance: 0.16820147308360395\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.062579041575418, tolerance: 0.1756486762718648\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20.536375451091544, tolerance: 0.15733494183275876\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.336211148926623, tolerance: 0.15733494183275876\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.9211447532559305, tolerance: 0.1756486762718648\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.414436155231897, tolerance: 0.1756486762718648\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.835864032935433, tolerance: 0.1756486762718648\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.440766968595426, tolerance: 0.1756486762718648\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.289816747359055, tolerance: 0.16298812538487364\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.666364346266164, tolerance: 0.16298812538487364\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.311538379820831, tolerance: 0.14419348813466207\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.488547144970198, tolerance: 0.16298812538487364\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.1703178236221, tolerance: 0.16298812538487364\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.918515619122672, tolerance: 0.16298812538487364\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.706959956786477, tolerance: 0.14419348813466207\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.309904874554832, tolerance: 0.14513451557560786\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.283243640052206, tolerance: 0.14419348813466207\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.668443005365361, tolerance: 0.14513451557560786\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.806700423099983, tolerance: 0.16615234908604834\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.605730536343344, tolerance: 0.14513451557560786\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.630765200972064, tolerance: 0.14419348813466207\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.725277215977712, tolerance: 0.14419348813466207\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.99504973238777, tolerance: 0.16106068251174135\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.929133906024163, tolerance: 0.16615234908604834\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.70077016871278, tolerance: 0.16615234908604834\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.580931523388927, tolerance: 0.14513451557560786\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.267485435978415, tolerance: 0.14513451557560786\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.308348191722871, tolerance: 0.16106068251174135\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.9175809436681, tolerance: 0.16106068251174135\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.084517275379312, tolerance: 0.16615234908604834\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.202631332932697, tolerance: 0.16615234908604834\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.794264432553746, tolerance: 0.16106068251174135\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.85352808960829, tolerance: 0.16106068251174135\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.010e-01, tolerance: 1.949e-01\n  model = cd_fast.enet_coordinate_descent(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.209680408137956, tolerance: 0.1739820729928647\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.700757204526099, tolerance: 0.1739820729928647\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.821031322106364, tolerance: 0.1739820729928647\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.960459865862958, tolerance: 0.1739820729928647\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.832531549843452, tolerance: 0.1739820729928647\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.605558488090992, tolerance: 0.19006877874819392\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.268720212977087, tolerance: 0.19006877874819392\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.156108816419419, tolerance: 0.19006877874819392\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.781282676970477, tolerance: 0.18907847284111046\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.135788291030167, tolerance: 0.18907847284111046\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.362092543565268, tolerance: 0.18907847284111046\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.018218360143237, tolerance: 0.19006877874819392\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.50276592408136, tolerance: 0.19006877874819392\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.29686820597658, tolerance: 0.15937683330776942\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.625971065576778, tolerance: 0.15937683330776942\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.61431121592409, tolerance: 0.15937683330776942\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.338472899481985, tolerance: 0.17815844442523024\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.00634048566235, tolerance: 0.17815844442523024\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.309216808288966, tolerance: 0.17815844442523024\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.787347176431467, tolerance: 0.18907847284111046\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.358397567635166, tolerance: 0.18907847284111046\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.905033854438443, tolerance: 0.15937683330776942\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.245148685786944, tolerance: 0.15937683330776942\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.576691902386074, tolerance: 0.17815844442523024\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21.560140554042164, tolerance: 0.17815844442523024\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.284e-01, tolerance: 2.229e-01\n  model = cd_fast.enet_coordinate_descent(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.305633441009377, tolerance: 0.17450521735295732\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.777749974309927, tolerance: 0.17450521735295732\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.001418371337195, tolerance: 0.17450521735295732\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.751434063091665, tolerance: 0.17450521735295732\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.787049994588415, tolerance: 0.17450521735295732\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.832946620230587, tolerance: 0.17602099468497773\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.850262956449114, tolerance: 0.17602099468497773\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.714986607106084, tolerance: 0.17602099468497773\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.53306397021197, tolerance: 0.17060224172283706\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.132548653308277, tolerance: 0.17060224172283706\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.534009937277006, tolerance: 0.17060224172283706\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.052005722116519, tolerance: 0.17602099468497773\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.783046864384687, tolerance: 0.17218236434616205\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.83652511570358, tolerance: 0.17602099468497773\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.547648657045556, tolerance: 0.17218236434616205\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.63452325039998, tolerance: 0.17060224172283706\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.027405192673768, tolerance: 0.1684143007800728\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.160600138523705, tolerance: 0.17218236434616205\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.654327733534728, tolerance: 0.1684143007800728\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.216727327553372, tolerance: 0.17218236434616205\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.850384403481485, tolerance: 0.17060224172283706\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.10629346954488, tolerance: 0.1684143007800728\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.501396524379743, tolerance: 0.1684143007800728\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.56854310945141, tolerance: 0.17218236434616205\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.498125151728573, tolerance: 0.1684143007800728\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.990e-01, tolerance: 2.158e-01\n  model = cd_fast.enet_coordinate_descent(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.262234196858799, tolerance: 0.15675170475835154\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.533904773044469, tolerance: 0.15675170475835154\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.938132312734297, tolerance: 0.15675170475835154\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.372652669130275, tolerance: 0.15675170475835154\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.536606018892599, tolerance: 0.15675170475835154\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.042562079572235, tolerance: 0.1477263570399635\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.180307926152636, tolerance: 0.1477263570399635\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.136443708786373, tolerance: 0.1477263570399635\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.00892741558323, tolerance: 0.14706247833508646\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.747437590088566, tolerance: 0.14706247833508646\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.126870242237374, tolerance: 0.14706247833508646\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.184101207014919, tolerance: 0.1477263570399635\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.588808317119174, tolerance: 0.1426191962065482\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.920434534142032, tolerance: 0.1477263570399635\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.894552675583554, tolerance: 0.1426191962065482\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.452949604495188, tolerance: 0.14706247833508646\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.331023128029528, tolerance: 0.13684249273442567\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.940955027483369, tolerance: 0.13684249273442567\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.307806609016552, tolerance: 0.1426191962065482\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.478524275235714, tolerance: 0.14706247833508646\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.915511429896469, tolerance: 0.13684249273442567\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.654473035012643, tolerance: 0.1426191962065482\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.05590496158584, tolerance: 0.1426191962065482\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.240970439378543, tolerance: 0.13684249273442567\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.639979599424123, tolerance: 0.13684249273442567\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.980e-01, tolerance: 1.829e-01\n  model = cd_fast.enet_coordinate_descent(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.2139413659176626, tolerance: 0.1474290182402497\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.053456995338365, tolerance: 0.1474290182402497\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.235332836322868, tolerance: 0.1474290182402497\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.98334157525278, tolerance: 0.1474290182402497\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.31853291572179, tolerance: 0.1474290182402497\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.768184871248877, tolerance: 0.1566029463658833\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.018728290800254, tolerance: 0.1566029463658833\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.219383280612647, tolerance: 0.1566029463658833\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.98319516327274, tolerance: 0.1566029463658833\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.712652907958727, tolerance: 0.1539464761795357\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.62237662072198, tolerance: 0.1539464761795357\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.839652617962429, tolerance: 0.1566029463658833\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.76484428175786, tolerance: 0.1539464761795357\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.007783856075548, tolerance: 0.1596986673382372\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.506954345361692, tolerance: 0.1596986673382372\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.135743353359203, tolerance: 0.1596986673382372\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.41958963300931, tolerance: 0.1539464761795357\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.503506279558906, tolerance: 0.16616406697118874\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.872680011667626, tolerance: 0.1539464761795357\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.32161816364578, tolerance: 0.16616406697118874\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.25956085258008, tolerance: 0.16616406697118874\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.21271627840838, tolerance: 0.1596986673382372\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.68992842925877, tolerance: 0.1596986673382372\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.07806022463069, tolerance: 0.16616406697118874\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.04699490318626, tolerance: 0.16616406697118874\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.873977222616759, tolerance: 0.15750480628235905\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.16883745714972, tolerance: 0.15750480628235905\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.332306701607877, tolerance: 0.15750480628235905\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.900356843663303, tolerance: 0.15750480628235905\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.44425168549401, tolerance: 0.15750480628235905\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.850399554543628, tolerance: 0.1422109641877848\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.608333266730597, tolerance: 0.1422109641877848\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.74668673994006, tolerance: 0.1422109641877848\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.624826132798262, tolerance: 0.1522285206597915\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.228470867518354, tolerance: 0.1522285206597915\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.847396765163921, tolerance: 0.1422109641877848\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.712063225831344, tolerance: 0.1522285206597915\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.043403431352772, tolerance: 0.1422109641877848\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.65475052109241, tolerance: 0.15125602080645648\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.217116661570344, tolerance: 0.1522285206597915\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.202029670834008, tolerance: 0.15125602080645648\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.588928727561552, tolerance: 0.15125602080645648\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.590908634523203, tolerance: 0.1498263098885298\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.37273316874689, tolerance: 0.1522285206597915\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.568913704922124, tolerance: 0.15125602080645648\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.686847101177818, tolerance: 0.1498263098885298\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.765382891232548, tolerance: 0.15125602080645648\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.07827419272894, tolerance: 0.1498263098885298\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.983294649628306, tolerance: 0.1498263098885298\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.411e-01, tolerance: 1.883e-01\n  model = cd_fast.enet_coordinate_descent(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.0443998838441075, tolerance: 0.1498263098885298\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.352918215811997, tolerance: 0.1383987137078588\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.53948443038189, tolerance: 0.1383987137078588\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.271152842818978, tolerance: 0.1383987137078588\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.326499356525346, tolerance: 0.1383987137078588\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.949451620297168, tolerance: 0.1383987137078588\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.383185223991404, tolerance: 0.1383987137078588\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.478826985761998, tolerance: 0.15243622592852504\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.61292847326854, tolerance: 0.15243622592852504\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.4892566461044225, tolerance: 0.15243622592852504\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.33209941305404, tolerance: 0.15243622592852504\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.25219737414227, tolerance: 0.15243622592852504\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.475523284649398, tolerance: 0.15854369856027145\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.03197160616196, tolerance: 0.15854369856027145\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.431913630458666, tolerance: 0.15854369856027145\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.766724192451193, tolerance: 0.16416980860241842\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.26391051061455, tolerance: 0.16416980860241842\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.104820049276213, tolerance: 0.15854369856027145\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.35268918701081, tolerance: 0.15854369856027145\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.654433898515663, tolerance: 0.16416980860241842\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.494065966453718, tolerance: 0.16729896704292974\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.880950170993401, tolerance: 0.16729896704292974\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.731454938226989, tolerance: 0.16416980860241842\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.219469283173112, tolerance: 0.16416980860241842\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.602214201096331, tolerance: 0.16729896704292974\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4605175155886414, tolerance: 0.16729896704292974\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.303009772541827, tolerance: 0.16729896704292974\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.367996769939055, tolerance: 0.16729896704292974\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.236e-01, tolerance: 1.953e-01\n  model = cd_fast.enet_coordinate_descent(\n&#34;}], &#34;test/test_knockoff.py::test_estimate_distribution&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_estimate_distribution&#34;, &#34;duration&#34;: &#34;598 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_estimate_distribution&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;598 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::test_model_x_knockoff&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_model_x_knockoff&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_model_x_knockoff&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_error_lasso_statistic_with_sampling[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_error_lasso_statistic_with_sampling[default data]&#34;, &#34;duration&#34;: &#34;25 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::TestModelXKnockoffExceptions::test_error_lasso_statistic_with_sampling[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;25 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_unfitted_importance[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_unfitted_importance[default data]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::TestModelXKnockoffExceptions::test_unfitted_importance[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::test_knockoff_function_not_centered&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_knockoff_function_not_centered&#34;, &#34;duration&#34;: &#34;00:00:07&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_knockoff_function_not_centered&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:07&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator32-check32-check_fit_check_is_fitted]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator32-check32-check_fit_check_is_fitted]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator32-check32-check_fit_check_is_fitted]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7ff219feba30&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_fit_check_is_fitted&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7ff219feba30&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_fit_check_is_fitted&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;BasePerturbationCV&#39;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\n    def check_fit_check_is_fitted(name, estimator_orig):\n        # Make sure that estimator doesn&#39;t pass check_is_fitted before calling fit\n        # and that passes check_is_fitted once it&#39;s fit.\n    \n        rng = np.random.RandomState(42)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if \&#34;warm_start\&#34; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if not _safe_tags(estimator).get(\&#34;stateless\&#34;, False):\n            # stateless estimators (such as FunctionTransformer) are always \&#34;fit\&#34;!\n            try:\n                check_is_fitted(estimator)\n&amp;gt;               raise AssertionError(\n                    f\&#34;{estimator.__class__.__name__} passes check_is_fitted before being\&#34;\n                    \&#34; fit!\&#34;\n                )\nE               AssertionError: BasePerturbationCV passes check_is_fitted before being fit!\n\nX          = array([[100.49671415,  99.8617357 ],\n       [100.64768854, 101.52302986],\n       [ 99.76584663,  99.76586304],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nn_samples  = 100\nname       = &#39;BasePerturbationCV&#39;\nrng        = RandomState(MT19937) at 0x7FF23C8C8140\ny          = array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,...1,\n       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3914: AssertionError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator23-check23-check_estimators_pickle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator23-check23-check_estimators_pickle]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator23-check23-check_estimators_pickle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_pickle at 0x7ff219fe8c10&amp;gt;, &#39;BasePerturbationCV&#39;)\nname = &#39;check_estimators_pickle&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_pickle at 0x7ff219fe8c10&amp;gt;, &#39;BasePerturbationCV&#39;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_estimators_pickle&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_pickle at 0x7ff219fe8b80&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2089: in check_estimators_pickle\n    estimator.fit(X, y)\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        check_methods = [&#39;predict&#39;, &#39;transform&#39;, &#39;decision_function&#39;, &#39;predict_proba&#39;]\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n        readonly_memmap = False\n        tags       = {&#39;X_types&#39;: [&#39;2darray&#39;], &#39;_skip_test&#39;: False, &#39;_xfail_checks&#39;: False, &#39;allow_nan&#39;: False, ...}\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7ff239011700&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7ff239011700&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...4211503],\n       [-0.03023028, -0.1048553 , -0.14200179]]), array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7ff239011700&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7ff216266f20&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7ff216266f20&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7ff216267760&amp;gt;\n        dispatch_timestamp = 1770122679.6559284\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7ff216267760&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7ff216266f20&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7ff2149be8f0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7ff216266f20&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7ff216266b00&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7ff216266f20&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7ff215f92d70&amp;gt;\n        args       = (LinearRegression(), array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n ...,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]]), array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n       [ 0.17640523,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\ny_train = array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n       [ 0.17640523,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 932.79it/s]\n\u0101\r \r\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator8-check8-check_estimator_sparse_array]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator8-check8-check_estimator_sparse_array]&#34;, &#34;duration&#34;: &#34;28 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator8-check8-check_estimator_sparse_array]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;28 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator37-check37-check_parameters_default_constructible]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator37-check37-check_parameters_default_constructible]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_valid[estimator37-check37-check_parameters_default_constructible]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator16-check16-check_estimators_fit_returns_self]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator16-check16-check_estimators_fit_returns_self]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator16-check16-check_estimators_fit_returns_self]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_fit_returns_self at 0x7ff219fe9d80&amp;gt;, &#39;BasePerturbationCV&#39;, readonly_memmap=True)\nname = &#39;check_estimators_fit_returns_self&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_fit_returns_self at 0x7ff219fe9d80&amp;gt;, &#39;BasePerturbationCV&#39;, readonly_memmap=True)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &#39;check_estimators_fit_returns_self&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbationCV&#39;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_fit_returns_self at 0x7ff219fe9cf0&amp;gt;\n        kwargs     = {&#39;readonly_memmap&#39;: True}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2871: in check_estimators_fit_returns_self\n    assert estimator.fit(X, y) is estimator\n        X          = memmap([[ 2.21021495,  1.27582618],\n        [ 1.28933778,  3.44969159],\n        [ 2.10102604,  0.71047981],\n        [ ...08313281],\n        [-2.77969937,  3.69537262],\n        [ 1.7373078 ,  4.42546234],\n        [-0.29661333,  4.12026211]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &#39;BasePerturbationCV&#39;\n        readonly_memmap = True\n        y          = memmap([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\nsrc/hidimstat/base_perturbation.py:388: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = memmap([[ 2.21021495,  1.27582618],\n        [ 1.28933778,  3.44969159],\n        [ 2.10102604,  0.71047981],\n        [ ...08313281],\n        [-2.77969937,  3.69537262],\n        [ 1.7373078 ,  4.42546234],\n        [-0.29661333,  4.12026211]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = memmap([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1085: in __call__\n    if self.dispatch_one_batch(iterator):\n        backend_name = &#39;SequentialBackend&#39;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7ff238b4e960&amp;gt;\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7ff238b4e960&amp;gt;\n        n_jobs     = 1\n        pre_dispatch = &#39;2 * n_jobs&#39;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:901: in dispatch_one_batch\n    self._dispatch(tasks)\n        batch_size = 1\n        big_batch_size = 1\n        final_batch_size = 1\n        i          = 0\n        islice     = [(&amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]]), array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])), {})]\n        iterator   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7ff238b4e960&amp;gt;\n        n_jobs     = 1\n        self       = Parallel(n_jobs=1)\n        tasks      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7ff2144b3610&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:819: in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7ff2144b3610&amp;gt;\n        cb         = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7ff2144b3880&amp;gt;\n        dispatch_timestamp = 1770122679.9623659\n        job_idx    = 0\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208: in apply_async\n    result = ImmediateResult(func)\n        callback   = &amp;lt;joblib.parallel.BatchCompletionCallBack object at 0x7ff2144b3880&amp;gt;\n        func       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7ff2144b3610&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.SequentialBackend object at 0x7ff2144b3a90&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597: in __init__\n    self.results = batch()\n        batch      = &amp;lt;joblib.parallel.BatchedCalls object at 0x7ff2144b3610&amp;gt;\n        self       = &amp;lt;joblib._parallel_backends.ImmediateResult object at 0x7ff2144b30d0&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in __call__\n    return [func(*args, **kwargs)\n        self       = &amp;lt;joblib.parallel.BatchedCalls object at 0x7ff2144b3610&amp;gt;\n.venv/lib/python3.10/site-packages/joblib/parallel.py:288: in &amp;lt;listcomp&amp;gt;\n    return [func(*args, **kwargs)\n        .0         = &amp;lt;list_iterator object at 0x7ff2144b3130&amp;gt;\n        args       = (LinearRegression(), array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.556...537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]]), array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2]))\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        kwargs     = {}\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.55670201],\n       [ 2.47...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\ny_train = array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        \&#34;\&#34;\&#34;\n        Fit the estimator on the training data for a single split.\n        \&#34;\&#34;\&#34;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.55670201],\n       [ 2.47...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\nsrc/hidimstat/base_perturbation.py:371: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\u0101\r \r\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A\n\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 965.87it/s]\u001b[A\u0101\r \r\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&lt;?, ?it/s]\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator1-check1-check_dtype_object]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator1-check1-check_dtype_object]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator1-check1-check_dtype_object]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbation(estimator=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_dtype_object at 0x7ff219fdb370&amp;gt;, &#39;BasePerturbation&#39;)\nname = &#39;check_dtype_object&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_dtype_object at 0x7ff219fdb370&amp;gt;, &#39;BasePerturbation&#39;)\nestimator  = BasePerturbation(estimator=LinearRegression())\nname       = &#39;check_dtype_object&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbation&#39;, BasePerturbation(estimator=LinearRegression()))\n        fn         = &amp;lt;function check_dtype_object at 0x7ff219fdb2e0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1355: in check_dtype_object\n    with raises(TypeError, match=msg):\n        X          = array([[{&#39;foo&#39;: &#39;bar&#39;}, 0.7151893663724195, 0.6027633760716439,\n        0.5448831829968969, 0.4236547993389047, 0.6458...4736,\n        0.3553688484719296, 0.3567068904025429, 0.01632850268370789,\n        0.18523232523618394]], dtype=object)\n        estimator  = BasePerturbation(estimator=LinearRegression(),\n                 features_groups={0: [0], 1: [1], 2: [2], 3: [3], 4: [4],\n                                  5: [5], 6: [6], 7: [7], 8: [8], 9: [9]})\n        estimator_orig = BasePerturbation(estimator=LinearRegression())\n        msg        = &#39;argument must be .* string.* number&#39;\n        name       = &#39;BasePerturbation&#39;\n        rng        = RandomState(MT19937) at 0x7FF21447F240\n        tags       = {&#39;X_types&#39;: [&#39;2darray&#39;], &#39;_skip_test&#39;: False, &#39;_xfail_checks&#39;: False, &#39;allow_nan&#39;: False, ...}\n        y          = array([2, 3, 3, 1, 1, 2, 0, 3, 1, 1, 2, 1, 2, 2, 3, 0, 2, 2, 0, 1, 1, 3,\n       2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7ff238bc6170&amp;gt;\nexc_type = None, exc_value = None, _ = None\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f\&#34;Did not raise: {self.expected_exc_types}\&#34;\n&amp;gt;               raise AssertionError(err_msg)\nE               AssertionError: Did not raise: [&amp;lt;class &#39;TypeError&#39;&amp;gt;]\n\n_          = None\nerr_msg    = \&#34;Did not raise: [&amp;lt;class &#39;TypeError&#39;&amp;gt;]\&#34;\nexc_type   = None\nexc_value  = None\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7ff238bc6170&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:908: AssertionError\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator2-check2-check_estimators_overwrite_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator2-check2-check_estimators_overwrite_params]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator2-check2-check_estimators_overwrite_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbation(estimator=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7ff219fea9e0&amp;gt;, &#39;BasePerturbation&#39;)\nname = &#39;check_estimators_overwrite_params&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7ff219fea9e0&amp;gt;, &#39;BasePerturbation&#39;)\nestimator  = BasePerturbation(estimator=LinearRegression())\nname       = &#39;check_estimators_overwrite_params&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbation&#39;, BasePerturbation(estimator=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_overwrite_params at 0x7ff219fea950&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;BasePerturbation&#39;\nestimator_orig = BasePerturbation(estimator=LinearRegression())\n\n    @ignore_warnings(category=FutureWarning)\n    def check_estimators_overwrite_params(name, estimator_orig):\n        X, y = make_blobs(random_state=0, n_samples=21)\n        X = _enforce_estimator_tags_X(estimator_orig, X, kernel=rbf_kernel)\n        estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        set_random_state(estimator)\n    \n        # Make a physical copy of the original estimator parameters before fitting.\n        params = estimator.get_params()\n        original_params = deepcopy(params)\n    \n        # Fit the model\n        estimator.fit(X, y)\n    \n        # Compare the state of the model parameters with the original parameters\n        new_params = estimator.get_params()\n        for param_name, original_value in original_params.items():\n            new_value = new_params[param_name]\n    \n            # We should never change or mutate the internal state of input\n            # parameters by default. To check this we use the joblib.hash function\n            # that introspects recursively any subobjects to compute a checksum.\n            # The only exception to this rule of immutable constructor parameters\n            # is possible RandomState instance but in this check we explicitly\n            # fixed the random_state params recursively to be integer seeds.\n&amp;gt;           assert joblib.hash(new_value) == joblib.hash(original_value), (\n                \&#34;Estimator %s should not change or mutate \&#34;\n                \&#34; the parameter %s from %s to %s during fit.\&#34;\n                % (name, param_name, original_value, new_value)\n            )\nE           AssertionError: Estimator BasePerturbation should not change or mutate  the parameter estimator from LinearRegression() to LinearRegression() during fit.\n\nX          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\nestimator  = BasePerturbation(estimator=LinearRegression(), features_groups={0: [0], 1: [1]},\n                 random_state=0)\nestimator_orig = BasePerturbation(estimator=LinearRegression())\nname       = &#39;BasePerturbation&#39;\nnew_params = {&#39;estimator&#39;: LinearRegression(), &#39;estimator__copy_X&#39;: True, &#39;estimator__fit_intercept&#39;: True, &#39;estimator__n_jobs&#39;: None, ...}\nnew_value  = LinearRegression()\noriginal_params = {&#39;estimator&#39;: LinearRegression(), &#39;estimator__copy_X&#39;: True, &#39;estimator__fit_intercept&#39;: True, &#39;estimator__n_jobs&#39;: None, ...}\noriginal_value = LinearRegression()\nparam_name = &#39;estimator&#39;\nparams     = {&#39;estimator&#39;: LinearRegression(), &#39;estimator__copy_X&#39;: True, &#39;estimator__fit_intercept&#39;: True, &#39;estimator__n_jobs&#39;: None, ...}\ny          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3270: AssertionError\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n--------------------------- Captured stderr teardown ---------------------------\n\n\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator9-check9-check_dont_overwrite_parameters]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator9-check9-check_dont_overwrite_parameters]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn_invalid[estimator9-check9-check_dont_overwrite_parameters]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbation(estimator=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_dont_overwrite_parameters at 0x7ff219fdb6d0&amp;gt;, &#39;BasePerturbation&#39;)\nname = &#39;check_dont_overwrite_parameters&#39;\n\n    @pytest.mark.xfail(reason=\&#34;invalid checks should fail\&#34;)\n    @pytest.mark.parametrize(\n        \&#34;estimator, check, name\&#34;,\n        check_estimator(\n            estimators=ESTIMATORS_TO_CHECK,\n            valid=False,\n            return_expected_failed_checks=expected_failed_checks,\n        ),\n    )\n    def test_check_estimator_sklearn_invalid(estimator, check, name):  # noqa: ARG001\n        \&#34;\&#34;\&#34;Check compliance with sklearn estimators.\&#34;\&#34;\&#34;\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_dont_overwrite_parameters at 0x7ff219fdb6d0&amp;gt;, &#39;BasePerturbation&#39;)\nestimator  = BasePerturbation(estimator=LinearRegression())\nname       = &#39;check_dont_overwrite_parameters&#39;\n\ntest/test_base_perturbation.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:160: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&#39;BasePerturbation&#39;, BasePerturbation(estimator=LinearRegression()))\n        fn         = &amp;lt;function check_dont_overwrite_parameters at 0x7ff219fdb640&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &#39;BasePerturbation&#39;\nestimator_orig = BasePerturbation(estimator=LinearRegression())\n\n    @ignore_warnings(category=FutureWarning)\n    def check_dont_overwrite_parameters(name, estimator_orig):\n        # check that fit method only changes or sets private attributes\n        if hasattr(estimator_orig.__init__, \&#34;deprecated_original\&#34;):\n            # to not check deprecated classes\n            return\n        estimator = clone(estimator_orig)\n        rnd = np.random.RandomState(0)\n        X = 3 * rnd.uniform(size=(20, 3))\n        X = _enforce_estimator_tags_X(estimator_orig, X)\n        y = X[:, 0].astype(int)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if hasattr(estimator, \&#34;n_components\&#34;):\n            estimator.n_components = 1\n        if hasattr(estimator, \&#34;n_clusters\&#34;):\n            estimator.n_clusters = 1\n    \n        set_random_state(estimator, 1)\n        dict_before_fit = estimator.__dict__.copy()\n        estimator.fit(X, y)\n    \n        dict_after_fit = estimator.__dict__\n    \n        public_keys_after_fit = [\n            key for key in dict_after_fit.keys() if _is_public_parameter(key)\n        ]\n    \n        attrs_added_by_fit = [\n            key for key in public_keys_after_fit if key not in dict_before_fit.keys()\n        ]\n    \n        # check that fit doesn&#39;t add any public attribute\n        assert not attrs_added_by_fit, (\n            \&#34;Estimator adds public attribute(s) during\&#34;\n            \&#34; the fit method.\&#34;\n            \&#34; Estimators are only allowed to add private attributes\&#34;\n            \&#34; either started with _ or ended\&#34;\n            \&#34; with _ but %s added\&#34; % \&#34;, \&#34;.join(attrs_added_by_fit)\n        )\n    \n        # check that fit doesn&#39;t change any public attribute\n        attrs_changed_by_fit = [\n            key\n            for key in public_keys_after_fit\n            if (dict_before_fit[key] is not dict_after_fit[key])\n        ]\n    \n&amp;gt;       assert not attrs_changed_by_fit, (\n            \&#34;Estimator changes public attribute(s) during\&#34;\n            \&#34; the fit method. Estimators are only allowed\&#34;\n            \&#34; to change attributes started\&#34;\n            \&#34; or ended with _, but\&#34;\n            \&#34; %s changed\&#34; % \&#34;, \&#34;.join(attrs_changed_by_fit)\n        )\nE       AssertionError: Estimator changes public attribute(s) during the fit method. Estimators are only allowed to change attributes started or ended with _, but features_groups changed\n\nX          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\nattrs_added_by_fit = []\nattrs_changed_by_fit = [&#39;features_groups&#39;]\ndict_after_fit = {&#39;_features_groups_ids&#39;: array([[0],\n       [1],\n       [2]]), &#39;_groups_ids&#39;: None, &#39;_n_groups&#39;: None, &#39;estimator&#39;: LinearRegression(), ...}\ndict_before_fit = {&#39;_features_groups_ids&#39;: None, &#39;_groups_ids&#39;: None, &#39;_n_groups&#39;: None, &#39;estimator&#39;: LinearRegression(), ...}\nestimator  = BasePerturbation(estimator=LinearRegression(),\n                 features_groups={0: [0], 1: [1], 2: [2]}, random_state=1)\nestimator_orig = BasePerturbation(estimator=LinearRegression())\nname       = &#39;BasePerturbation&#39;\npublic_keys_after_fit = [&#39;features_groups&#39;, &#39;estimator&#39;, &#39;loss&#39;, &#39;method&#39;, &#39;n_permutations&#39;, &#39;statistical_test&#39;, ...]\nrnd        = RandomState(MT19937) at 0x7FF21447DA40\ny          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1471: AssertionError\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}]}, &#34;renderCollapsed&#34;: [&#34;passed&#34;], &#34;initialSort&#34;: &#34;result&#34;, &#34;title&#34;: &#34;report-3.10-os-ubuntu-latest.html&#34;}"></div>
    <script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > td')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > td')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`).classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
  </footer>
</html>