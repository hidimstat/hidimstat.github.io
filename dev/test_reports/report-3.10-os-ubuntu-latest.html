<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title id="head-title">report-3.10-os-ubuntu-latest.html</title>
      <style type="text/css">body {
  font-family: Helvetica, Arial, sans-serif;
  font-size: 12px;
  /* do not increase min-width as some may use split screens */
  min-width: 800px;
  color: #999;
}

h1 {
  font-size: 24px;
  color: black;
}

h2 {
  font-size: 16px;
  color: black;
}

p {
  color: black;
}

a {
  color: #999;
}

table {
  border-collapse: collapse;
}

/******************************
 * SUMMARY INFORMATION
 ******************************/
#environment td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  vertical-align: top;
}
#environment tr:nth-child(odd) {
  background-color: #f6f6f6;
}
#environment ul {
  margin: 0;
  padding: 0 20px;
}

/******************************
 * TEST RESULT COLORS
 ******************************/
span.passed,
.passed .col-result {
  color: green;
}

span.skipped,
span.xfailed,
span.rerun,
.skipped .col-result,
.xfailed .col-result,
.rerun .col-result {
  color: orange;
}

span.error,
span.failed,
span.xpassed,
.error .col-result,
.failed .col-result,
.xpassed .col-result {
  color: red;
}

.col-links__extra {
  margin-right: 3px;
}

/******************************
 * RESULTS TABLE
 *
 * 1. Table Layout
 * 2. Extra
 * 3. Sorting items
 *
 ******************************/
/*------------------
 * 1. Table Layout
 *------------------*/
#results-table {
  border: 1px solid #e6e6e6;
  color: #999;
  font-size: 12px;
  width: 100%;
}
#results-table th,
#results-table td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  text-align: left;
}
#results-table th {
  font-weight: bold;
}

/*------------------
 * 2. Extra
 *------------------*/
.logwrapper {
  max-height: 230px;
  overflow-y: scroll;
  background-color: #e6e6e6;
}
.logwrapper.expanded {
  max-height: none;
}
.logwrapper.expanded .logexpander:after {
  content: "collapse [-]";
}
.logwrapper .logexpander {
  z-index: 1;
  position: sticky;
  top: 10px;
  width: max-content;
  border: 1px solid;
  border-radius: 3px;
  padding: 5px 7px;
  margin: 10px 0 10px calc(100% - 80px);
  cursor: pointer;
  background-color: #e6e6e6;
}
.logwrapper .logexpander:after {
  content: "expand [+]";
}
.logwrapper .logexpander:hover {
  color: #000;
  border-color: #000;
}
.logwrapper .log {
  min-height: 40px;
  position: relative;
  top: -50px;
  height: calc(100% + 50px);
  border: 1px solid #e6e6e6;
  color: black;
  display: block;
  font-family: "Courier New", Courier, monospace;
  padding: 5px;
  padding-right: 80px;
  white-space: pre-wrap;
}

div.media {
  border: 1px solid #e6e6e6;
  float: right;
  height: 240px;
  margin: 0 5px;
  overflow: hidden;
  width: 320px;
}

.media-container {
  display: grid;
  grid-template-columns: 25px auto 25px;
  align-items: center;
  flex: 1 1;
  overflow: hidden;
  height: 200px;
}

.media-container--fullscreen {
  grid-template-columns: 0px auto 0px;
}

.media-container__nav--right,
.media-container__nav--left {
  text-align: center;
  cursor: pointer;
}

.media-container__viewport {
  cursor: pointer;
  text-align: center;
  height: inherit;
}
.media-container__viewport img,
.media-container__viewport video {
  object-fit: cover;
  width: 100%;
  max-height: 100%;
}

.media__name,
.media__counter {
  display: flex;
  flex-direction: row;
  justify-content: space-around;
  flex: 0 0 25px;
  align-items: center;
}

.collapsible td:not(.col-links) {
  cursor: pointer;
}
.collapsible td:not(.col-links):hover::after {
  color: #bbb;
  font-style: italic;
  cursor: pointer;
}

.col-result {
  width: 130px;
}
.col-result:hover::after {
  content: " (hide details)";
}

.col-result.collapsed:hover::after {
  content: " (show details)";
}

#environment-header h2:hover::after {
  content: " (hide details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

#environment-header.collapsed h2:hover::after {
  content: " (show details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

/*------------------
 * 3. Sorting items
 *------------------*/
.sortable {
  cursor: pointer;
}
.sortable.desc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: -12.5px;
  border: 10px solid #4caf50;
  border-bottom: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}
.sortable.asc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: 12.5px;
  border: 10px solid #4caf50;
  border-top: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}

.hidden, .summary__reload__button.hidden {
  display: none;
}

.summary__data {
  flex: 0 0 550px;
}
.summary__reload {
  flex: 1 1;
  display: flex;
  justify-content: center;
}
.summary__reload__button {
  flex: 0 0 300px;
  display: flex;
  color: white;
  font-weight: bold;
  background-color: #4caf50;
  text-align: center;
  justify-content: center;
  align-items: center;
  border-radius: 3px;
  cursor: pointer;
}
.summary__reload__button:hover {
  background-color: #46a049;
}
.summary__spacer {
  flex: 0 0 550px;
}

.controls {
  display: flex;
  justify-content: space-between;
}

.filters,
.collapse {
  display: flex;
  align-items: center;
}
.filters button,
.collapse button {
  color: #999;
  border: none;
  background: none;
  cursor: pointer;
  text-decoration: underline;
}
.filters button:hover,
.collapse button:hover {
  color: #ccc;
}

.filter__label {
  margin-right: 10px;
}

      </style>
    
  </head>
  <body>
    <h1 id="title">report-3.10-os-ubuntu-latest.html</h1>
    <p>Report generated on 11-Feb-2026 at 08:32:57 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.2.0</p>
    <div id="environment-header">
      <h2>Environment</h2>
    </div>
    <table id="environment"></table>
    <!-- TEMPLATES -->
      <template id="template_environment_row">
      <tr>
        <td></td>
        <td></td>
      </tr>
    </template>
    <template id="template_results-table__body--empty">
      <tbody class="results-table-row">
        <tr id="not-found-message">
          <td colspan="4">No results found. Check the filters.</td>
        </tr>
      </tbody>
    </template>
    <template id="template_results-table__tbody">
      <tbody class="results-table-row">
        <tr class="collapsible">
        </tr>
        <tr class="extras-row">
          <td class="extra" colspan="4">
            <div class="extraHTML"></div>
            <div class="media">
              <div class="media-container">
                  <div class="media-container__nav--left">&lt;</div>
                  <div class="media-container__viewport">
                    <img src="" />
                    <video controls>
                      <source src="" type="video/mp4">
                    </video>
                  </div>
                  <div class="media-container__nav--right">&gt;</div>
                </div>
                <div class="media__name"></div>
                <div class="media__counter"></div>
            </div>
            <div class="logwrapper">
              <div class="logexpander"></div>
              <div class="log"></div>
            </div>
          </td>
        </tr>
      </tbody>
    </template>
    <!-- END TEMPLATES -->
    <div class="summary">
      <div class="summary__data">
        <h2>Summary</h2>
        <div class="additional-summary prefix">
        </div>
        <p class="run-count">463 tests took 00:01:22.</p>
        <p class="filter">(Un)check the boxes to filter the results.</p>
        <div class="summary__reload">
          <div class="summary__reload__button hidden" onclick="location.reload()">
            <div>There are still tests running. <br />Reload this page to get the latest results!</div>
          </div>
        </div>
        <div class="summary__spacer"></div>
        <div class="controls">
          <div class="filters">
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="failed" disabled>
            <span class="failed">0 Failed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="passed" >
            <span class="passed">392 Passed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="skipped" disabled>
            <span class="skipped">0 Skipped,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xfailed" >
            <span class="xfailed">71 Expected failures,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xpassed" disabled>
            <span class="xpassed">0 Unexpected passes,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="error" disabled>
            <span class="error">0 Errors,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="rerun" disabled>
            <span class="rerun">0 Reruns</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="retried" disabled>
            <span class="retried">0 Retried,</span>
          </div>
          <div class="collapse">
            <button id="show_all_details">Show all details</button>&nbsp;/&nbsp;<button id="hide_all_details">Hide all details</button>
          </div>
        </div>
      </div>
      <div class="additional-summary summary">
      </div>
      <div class="additional-summary postfix">
      </div>
    </div>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable" data-column-type="result">Result</th>
          <th class="sortable" data-column-type="testId">Test</th>
          <th class="sortable" data-column-type="duration">Duration</th>
          <th>Links</th>
        </tr>
      </thead>
    </table>
  <footer>
    <div id="data-container" data-jsonblob="{&#34;environment&#34;: {&#34;Python&#34;: &#34;3.10.19&#34;, &#34;Platform&#34;: &#34;Linux-6.11.0-1018-azure-x86_64-with-glibc2.39&#34;, &#34;Packages&#34;: {&#34;pytest&#34;: &#34;9.0.2&#34;, &#34;pluggy&#34;: &#34;1.6.0&#34;}, &#34;Plugins&#34;: {&#34;randomly&#34;: &#34;4.0.1&#34;, &#34;timeout&#34;: &#34;2.4.0&#34;, &#34;reportlog&#34;: &#34;1.0.0&#34;, &#34;durations&#34;: &#34;1.6.1&#34;, &#34;mpl&#34;: &#34;0.18.0&#34;, &#34;cov&#34;: &#34;7.0.0&#34;, &#34;env&#34;: &#34;1.2.0&#34;, &#34;xdist&#34;: &#34;3.8.0&#34;, &#34;html&#34;: &#34;4.2.0&#34;, &#34;metadata&#34;: &#34;3.1.1&#34;}, &#34;CI&#34;: &#34;true&#34;, &#34;JAVA_HOME&#34;: &#34;/usr/lib/jvm/temurin-17-jdk-amd64&#34;}, &#34;tests&#34;: {&#34;test/samplers/test_conditional_sampling.py::test_error_no_predic&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_error_no_predic&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_error_no_predic&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_binary_case&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_binary_case&#34;, &#34;duration&#34;: &#34;244 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_binary_case&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;244 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_continuous_case&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_continuous_case&#34;, &#34;duration&#34;: &#34;11 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_continuous_case&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;11 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_group_case&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_group_case&#34;, &#34;duration&#34;: &#34;230 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_group_case&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;230 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_sample_categorical&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_sample_categorical&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_sample_categorical&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_error_wrong_type_data&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_error_wrong_type_data&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_error_wrong_type_data&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_percentile&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_percentile&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_percentile&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_k_best&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_k_best&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_k_best&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_threshold&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_threshold&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_threshold&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_not_fit&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_not_fit&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestBVIExceptions::test_not_fit&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_k_lowest&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_k_lowest&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_k_lowest&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_pvalue_None&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_pvalue_None&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestBVIExceptions::test_selection_pvalue_None&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_lowest&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_lowest&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_k_lowest&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_threshold_max&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_threshold_max&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_threshold_max&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_threshold_min&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_threshold_min&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_threshold_min&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_threshols_value&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_threshols_value&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_threshols_value&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_best_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_best_none&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_k_best_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_best&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_best&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_k_best&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_none&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_lowest_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_k_lowest_none&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_k_lowest_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_percentile&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_all&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_all&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelection::test_selection_percentile_all&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::test_selection_fdr&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::test_selection_fdr&#34;, &#34;duration&#34;: &#34;18 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::test_selection_fdr&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;18 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::test_selection_bhq&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::test_selection_bhq&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::test_selection_bhq&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::test_plot_importance_ascending&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::test_plot_importance_ascending&#34;, &#34;duration&#34;: &#34;284 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::test_plot_importance_ascending&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;284 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::test_plot_importance_feature_names&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::test_plot_importance_feature_names&#34;, &#34;duration&#34;: &#34;187 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::test_plot_importance_feature_names&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;187 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::test_plot_importance_axis&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::test_plot_importance_axis&#34;, &#34;duration&#34;: &#34;270 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::test_plot_importance_axis&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;270 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::test_clustered_fwer_selection&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::test_clustered_fwer_selection&#34;, &#34;duration&#34;: &#34;53 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::test_clustered_fwer_selection&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;53 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nUsing number of clusters for multiple testing correction.\n&#34;}], &#34;test/test_base_variable_importance.py::test_fwer_selection&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::test_fwer_selection&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::test_fwer_selection&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_wrong_fdr&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_wrong_fdr&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_wrong_fdr&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_pvalue_None&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_pvalue_None&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_pvalue_None&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_fdr_control&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_fdr_control&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_selection_fdr_fdr_control&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_not_fit&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_not_fit&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_variable_importance.py::TestSelectionFDRExceptions::test_not_fit&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_gaussian_error&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_gaussian_error&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_gaussian_error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_rgn&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_rgn&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_rgn&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_reproducibility_sample_repeat&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_reproducibility_sample_repeat&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_reproducibility_sample_repeat&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_no_seed&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_no_seed&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_no_seed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_reproducibility_sample&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_reproducibility_sample&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_reproducibility_sample&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_gaussian_equi&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_gaussian_equi&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_gaussian_equi&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_no_seed_repeat&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_no_seed_repeat&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_no_seed_repeat&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_rgn_repeat&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_rgn_repeat&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_randomness_sample_rgn_repeat&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_gaussian_knockoffs.py::test_s_equi_not_definite_positive&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_gaussian_knockoffs.py::test_s_equi_not_definite_positive&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_gaussian_knockoffs.py::test_s_equi_not_definite_positive&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_repr]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_repr]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_repr]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_tags_renamed1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_tags_renamed1]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_tags_renamed1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_matrix1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_matrix1]&#34;, &#34;duration&#34;: &#34;22 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_matrix1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;22 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_idempotent1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_idempotent1]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_idempotent1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dtype_object1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dtype_object1]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dtype_object1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_get_params_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_get_params_invariance]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_get_params_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_ensemble_clustered_inference.py::test_encludl_independence&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_ensemble_clustered_inference.py::test_encludl_independence&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_ensemble_clustered_inference.py::test_encludl_independence&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting clustered inferences:   0%|          | 0/20 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:   5%|\u258c         | 1/20 [00:00&amp;lt;00:02,  6.57it/s]\rFitting clustered inferences:  10%|\u2588         | 2/20 [00:00&amp;lt;00:02,  6.71it/s]\rFitting clustered inferences:  15%|\u2588\u258c        | 3/20 [00:00&amp;lt;00:02,  6.37it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 4/20 [00:00&amp;lt;00:02,  6.33it/s]\rFitting clustered inferences:  25%|\u2588\u2588\u258c       | 5/20 [00:00&amp;lt;00:02,  5.78it/s]\rFitting clustered inferences:  30%|\u2588\u2588\u2588       | 6/20 [00:00&amp;lt;00:02,  5.83it/s]\rFitting clustered inferences:  35%|\u2588\u2588\u2588\u258c      | 7/20 [00:01&amp;lt;00:02,  5.65it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 8/20 [00:01&amp;lt;00:02,  5.96it/s]\rFitting clustered inferences:  45%|\u2588\u2588\u2588\u2588\u258c     | 9/20 [00:01&amp;lt;00:01,  6.25it/s]\rFitting clustered inferences:  50%|\u2588\u2588\u2588\u2588\u2588     | 10/20 [00:01&amp;lt;00:01,  6.57it/s]\rFitting clustered inferences:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 11/20 [00:01&amp;lt;00:01,  6.85it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 12/20 [00:01&amp;lt;00:01,  6.81it/s]\rFitting clustered inferences:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 13/20 [00:02&amp;lt;00:01,  6.87it/s]\rFitting clustered inferences:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 14/20 [00:02&amp;lt;00:00,  6.93it/s]\rFitting clustered inferences:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 15/20 [00:02&amp;lt;00:00,  7.03it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 16/20 [00:02&amp;lt;00:00,  6.80it/s]\rFitting clustered inferences:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 17/20 [00:02&amp;lt;00:00,  7.11it/s]\rFitting clustered inferences:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 18/20 [00:02&amp;lt;00:00,  6.88it/s]\rFitting clustered inferences:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 19/20 [00:02&amp;lt;00:00,  6.94it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:03&amp;lt;00:00,  6.97it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:03&amp;lt;00:00,  6.59it/s]\n\rComputing importances:   0%|          | 0/20 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&amp;lt;00:00, 1164.84it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_sparse_matrix]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_sparse_matrix]&#34;, &#34;duration&#34;: &#34;9 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_sparse_matrix]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;9 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nsparse_type = &amp;lt;class &amp;#x27;scipy.sparse._csr.csr_matrix&amp;#x27;&amp;gt;\n\n    def _check_estimator_sparse_container(name, estimator_orig, sparse_type):\n        rng = np.random.RandomState(0)\n        X = rng.uniform(size=(40, 3))\n        X[X &amp;lt; 0.6] = 0\n        X = _enforce_estimator_tags_X(estimator_orig, X)\n        y = (4 * rng.uniform(size=X.shape[0])).astype(np.int32)\n        # catch deprecation warnings\n        with ignore_warnings(category=FutureWarning):\n            estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n        tags = get_tags(estimator_orig)\n        for matrix_format, X in _generate_sparse_data(sparse_type(X)):\n            # catch deprecation warnings\n            with ignore_warnings(category=FutureWarning):\n                estimator = clone(estimator_orig)\n                if name in [&amp;quot;Scaler&amp;quot;, &amp;quot;StandardScaler&amp;quot;]:\n                    estimator.set_params(with_mean=False)\n            # fit and predict\n            if &amp;quot;64&amp;quot; in matrix_format:\n                err_msg = (\n                    f&amp;quot;Estimator {name} doesn&amp;#x27;t seem to support {matrix_format} &amp;quot;\n                    &amp;quot;matrix, and is not failing gracefully, e.g. by using &amp;quot;\n                    &amp;quot;check_array(X, accept_large_sparse=False).&amp;quot;\n                )\n            else:\n                err_msg = (\n                    f&amp;quot;Estimator {name} doesn&amp;#x27;t seem to fail gracefully on sparse &amp;quot;\n                    &amp;quot;data: error message should state explicitly that sparse &amp;quot;\n                    &amp;quot;input is not supported if this is not the case, e.g. by using &amp;quot;\n                    &amp;quot;check_array(X, accept_sparse=False).&amp;quot;\n                )\n            with raises(\n                (TypeError, ValueError),\n                match=[&amp;quot;sparse&amp;quot;, &amp;quot;Sparse&amp;quot;],\n                may_pass=True,\n                err_msg=err_msg,\n            ):\n                with ignore_warnings(category=FutureWarning):\n&amp;gt;                   estimator.fit(X, y)\n\nX          = &amp;lt;Compressed Sparse Row sparse matrix of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\nerr_msg    = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nmatrix_format = &amp;#x27;csr&amp;#x27;\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CFAC4DD40\nsparse_type = &amp;lt;class &amp;#x27;scipy.sparse._csr.csr_matrix&amp;#x27;&amp;gt;\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0], dtype=int32)\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1330: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = &amp;lt;Compressed Sparse Row sparse matrix of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0], dtype=int32)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4d03023d10&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4d03023bc0&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), &amp;lt;Compressed Sparse Row sparse matrix of dtype &amp;#x27;float64&amp;#x27;\n\twith 22 stored elements and shape (20, 3)&amp;gt;, array([3, 1, 1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0],\n      dtype=int32))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4d03023d10&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = &amp;lt;Compressed Sparse Row sparse matrix of dtype &amp;#x27;float64&amp;#x27;\n\twith 22 stored elements and shape (20, 3)&amp;gt;\ny_train = array([3, 1, 1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0],\n      dtype=int32)\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = &amp;lt;Compressed Sparse Row sparse matrix of dtype &amp;#x27;float64&amp;#x27;\n\twith 22 stored elements and shape (20, 3)&amp;gt;\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([3, 1, 1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0],\n      dtype=int32)\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimator_sparse_matrix at 0x7f4cfd879090&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimator_sparse_matrix at 0x7f4cfd879090&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1347: in check_estimator_sparse_matrix\n    _check_estimator_sparse_container(name, estimator_orig, sparse.csr_matrix)\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1323: in _check_estimator_sparse_container\n    with raises(\n        X          = &amp;lt;Compressed Sparse Row sparse matrix of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\n        err_msg    = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        matrix_format = &amp;#x27;csr&amp;#x27;\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CFAC4DD40\n        sparse_type = &amp;lt;class &amp;#x27;scipy.sparse._csr.csr_matrix&amp;#x27;&amp;gt;\n        tags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        y          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0], dtype=int32)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cf81af190&amp;gt;\nexc_type = &amp;lt;class &amp;#x27;NotImplementedError&amp;#x27;&amp;gt;, exc_value = NotImplementedError()\n_ = &amp;lt;traceback object at 0x7f4cf81f6140&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f&amp;quot;Did not raise: {self.expected_exc_types}&amp;quot;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n&amp;gt;               raise AssertionError(self.err_msg) from exc_value\nE               AssertionError: Estimator BasePerturbationCV doesn&amp;#x27;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).\n\n_          = &amp;lt;traceback object at 0x7f4cf81f6140&amp;gt;\nexc_type   = &amp;lt;class &amp;#x27;NotImplementedError&amp;#x27;&amp;gt;\nexc_value  = NotImplementedError()\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cf81af190&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:1145: AssertionError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 636.56it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_positive_only_tag_during_fit0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_positive_only_tag_during_fit0]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_positive_only_tag_during_fit0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_dtype_object]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_dtype_object]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_dtype_object]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_dtype_object at 0x7f4cfd879a20&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_dtype_object at 0x7f4cfd879a20&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_dtype_object at 0x7f4cfd879990&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1635: in check_dtype_object\n    estimator.fit(X, y)\n        X          = array([[0.5488135039273248, 0.7151893663724195, 0.6027633760716439,\n        0.5448831829968969, 0.4236547993389047, 0....4736,\n        0.3553688484719296, 0.3567068904025429, 0.01632850268370789,\n        0.18523232523618394]], dtype=object)\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CFAC4DE40\n        tags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        y          = array([2, 3, 3, 1, 1, 2, 0, 3, 1, 1, 2, 1, 2, 2, 3, 0, 2, 2, 0, 1, 1, 3,\n       2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[0.5488135039273248, 0.7151893663724195, 0.6027633760716439,\n        0.5448831829968969, 0.4236547993389047, 0....4736,\n        0.3553688484719296, 0.3567068904025429, 0.01632850268370789,\n        0.18523232523618394]], dtype=object)\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([2, 3, 3, 1, 1, 2, 0, 3, 1, 1, 2, 1, 2, 2, 3, 0, 2, 2, 0, 1, 1, 3,\n       2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf80052a0&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf8006110&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[0.3117958819941026, 0.6963434888154595, 0.3777518392924809,\n        0.1796036775596348, 0...789,\n        0.18523232523618394]], dtype=object), array([1, 3, 2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf80052a0&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.3117958819941026, 0.6963434888154595, 0.3777518392924809,\n        0.1796036775596348, 0.02467872839133123, 0...4736,\n        0.3553688484719296, 0.3567068904025429, 0.01632850268370789,\n        0.18523232523618394]], dtype=object)\ny_train = array([1, 3, 2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.3117958819941026, 0.6963434888154595, 0.3777518392924809,\n        0.1796036775596348, 0.02467872839133123, 0...4736,\n        0.3553688484719296, 0.3567068904025429, 0.01632850268370789,\n        0.18523232523618394]], dtype=object)\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 3, 2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 994.15it/s]\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_positive_only_tag_during_fit1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_positive_only_tag_during_fit1]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_positive_only_tag_during_fit1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_nan_inf]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_nan_inf]&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_nan_inf]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_nan_inf at 0x7f4cfd87b130&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_nan_inf at 0x7f4cfd87b130&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_nan_inf at 0x7f4cfd87b0a0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2350: in check_estimators_nan_inf\n    estimator.fit(X_train_finite, y)\n        X_train    = array([[       nan, 0.77423369, 0.45615033],\n       [0.56843395, 0.0187898 , 0.6176355 ],\n       [0.61209572, 0.616934...51, 0.98837384, 0.10204481],\n       [0.20887676, 0.16130952, 0.65310833],\n       [0.2532916 , 0.46631077, 0.24442559]])\n        X_train_finite = array([[0.5488135 , 0.71518937, 0.60276338],\n       [0.54488318, 0.4236548 , 0.64589411],\n       [0.43758721, 0.891773...56, 0.46147936, 0.78052918],\n       [0.11827443, 0.63992102, 0.14335329],\n       [0.94466892, 0.52184832, 0.41466194]])\n        X_train_inf = array([[       inf, 0.11037514, 0.65632959],\n       [0.13818295, 0.19658236, 0.36872517],\n       [0.82099323, 0.097101...99, 0.0641475 , 0.69247212],\n       [0.56660145, 0.26538949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]])\n        X_train_nan = array([[       nan, 0.77423369, 0.45615033],\n       [0.56843395, 0.0187898 , 0.6176355 ],\n       [0.61209572, 0.616934...51, 0.98837384, 0.10204481],\n       [0.20887676, 0.16130952, 0.65310833],\n       [0.2532916 , 0.46631077, 0.24442559]])\n        error_string_fit = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t check for NaN and inf in fit.&amp;quot;\n        error_string_predict = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t check for NaN and inf in predict.&amp;quot;\n        error_string_transform = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t check for NaN and inf in transform.&amp;quot;\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CFAC4F240\n        y          = array([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[0.5488135 , 0.71518937, 0.60276338],\n       [0.54488318, 0.4236548 , 0.64589411],\n       [0.43758721, 0.891773...56, 0.46147936, 0.78052918],\n       [0.11827443, 0.63992102, 0.14335329],\n       [0.94466892, 0.52184832, 0.41466194]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1f189e0&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf1f18ba0&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[0.0871293 , 0.0202184 , 0.83261985],\n       [0.77815675, 0.87001215, 0.97861834],\n       ...      [0.11827443, 0.63992102, 0.14335329],\n       [0.94466892, 0.52184832, 0.41466194]]), array([1., 1., 1., 1., 1.]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1f189e0&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.0871293 , 0.0202184 , 0.83261985],\n       [0.77815675, 0.87001215, 0.97861834],\n       [0.79915856, 0.46147936, 0.78052918],\n       [0.11827443, 0.63992102, 0.14335329],\n       [0.94466892, 0.52184832, 0.41466194]])\ny_train = array([1., 1., 1., 1., 1.])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.0871293 , 0.0202184 , 0.83261985],\n       [0.77815675, 0.87001215, 0.97861834],\n       [0.79915856, 0.46147936, 0.78052918],\n       [0.11827443, 0.63992102, 0.14335329],\n       [0.94466892, 0.52184832, 0.41466194]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1., 1., 1., 1., 1.])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&amp;lt;00:00, 625.64it/s]\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1256.91it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_sparse_array]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_sparse_array]&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_sparse_array]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nsparse_type = &amp;lt;class &amp;#x27;scipy.sparse._csr.csr_array&amp;#x27;&amp;gt;\n\n    def _check_estimator_sparse_container(name, estimator_orig, sparse_type):\n        rng = np.random.RandomState(0)\n        X = rng.uniform(size=(40, 3))\n        X[X &amp;lt; 0.6] = 0\n        X = _enforce_estimator_tags_X(estimator_orig, X)\n        y = (4 * rng.uniform(size=X.shape[0])).astype(np.int32)\n        # catch deprecation warnings\n        with ignore_warnings(category=FutureWarning):\n            estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n        tags = get_tags(estimator_orig)\n        for matrix_format, X in _generate_sparse_data(sparse_type(X)):\n            # catch deprecation warnings\n            with ignore_warnings(category=FutureWarning):\n                estimator = clone(estimator_orig)\n                if name in [&amp;quot;Scaler&amp;quot;, &amp;quot;StandardScaler&amp;quot;]:\n                    estimator.set_params(with_mean=False)\n            # fit and predict\n            if &amp;quot;64&amp;quot; in matrix_format:\n                err_msg = (\n                    f&amp;quot;Estimator {name} doesn&amp;#x27;t seem to support {matrix_format} &amp;quot;\n                    &amp;quot;matrix, and is not failing gracefully, e.g. by using &amp;quot;\n                    &amp;quot;check_array(X, accept_large_sparse=False).&amp;quot;\n                )\n            else:\n                err_msg = (\n                    f&amp;quot;Estimator {name} doesn&amp;#x27;t seem to fail gracefully on sparse &amp;quot;\n                    &amp;quot;data: error message should state explicitly that sparse &amp;quot;\n                    &amp;quot;input is not supported if this is not the case, e.g. by using &amp;quot;\n                    &amp;quot;check_array(X, accept_sparse=False).&amp;quot;\n                )\n            with raises(\n                (TypeError, ValueError),\n                match=[&amp;quot;sparse&amp;quot;, &amp;quot;Sparse&amp;quot;],\n                may_pass=True,\n                err_msg=err_msg,\n            ):\n                with ignore_warnings(category=FutureWarning):\n&amp;gt;                   estimator.fit(X, y)\n\nX          = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\nerr_msg    = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nmatrix_format = &amp;#x27;csr&amp;#x27;\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CFAC4F740\nsparse_type = &amp;lt;class &amp;#x27;scipy.sparse._csr.csr_array&amp;#x27;&amp;gt;\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0], dtype=int32)\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1330: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0], dtype=int32)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1f19930&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf1f193f0&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 22 stored elements and shape (20, 3)&amp;gt;, array([3, 1, 1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0],\n      dtype=int32))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1f19930&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 22 stored elements and shape (20, 3)&amp;gt;\ny_train = array([3, 1, 1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0],\n      dtype=int32)\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 22 stored elements and shape (20, 3)&amp;gt;\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([3, 1, 1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0],\n      dtype=int32)\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimator_sparse_array at 0x7f4cfd879120&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimator_sparse_array at 0x7f4cfd879120&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1351: in check_estimator_sparse_array\n    _check_estimator_sparse_container(name, estimator_orig, sparse.csr_array)\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1323: in _check_estimator_sparse_container\n    with raises(\n        X          = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\n        err_msg    = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        matrix_format = &amp;#x27;csr&amp;#x27;\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CFAC4F740\n        sparse_type = &amp;lt;class &amp;#x27;scipy.sparse._csr.csr_array&amp;#x27;&amp;gt;\n        tags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        y          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0], dtype=int32)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cfc180100&amp;gt;\nexc_type = &amp;lt;class &amp;#x27;NotImplementedError&amp;#x27;&amp;gt;, exc_value = NotImplementedError()\n_ = &amp;lt;traceback object at 0x7f4cfacf0a80&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f&amp;quot;Did not raise: {self.expected_exc_types}&amp;quot;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n&amp;gt;               raise AssertionError(self.err_msg) from exc_value\nE               AssertionError: Estimator BasePerturbationCV doesn&amp;#x27;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).\n\n_          = &amp;lt;traceback object at 0x7f4cfacf0a80&amp;gt;\nexc_type   = &amp;lt;class &amp;#x27;NotImplementedError&amp;#x27;&amp;gt;\nexc_value  = NotImplementedError()\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cfc180100&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:1145: AssertionError\n\n----------------------------- Captured stderr call -----------------------------\n\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A\u001b[A\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 649.27it/s]\n\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_ensemble_clustered_inference.py::test_cludl_spatial&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_ensemble_clustered_inference.py::test_cludl_spatial&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_ensemble_clustered_inference.py::test_cludl_spatial&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\nUsing number of clusters for multiple testing correction.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_empty_data_messages]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_empty_data_messages]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_empty_data_messages]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\n    @ignore_warnings(category=FutureWarning)\n    def check_estimators_empty_data_messages(name, estimator_orig):\n        e = clone(estimator_orig)\n        set_random_state(e, 1)\n    \n        X_zero_samples = np.empty(0).reshape(0, 3)\n        # The precise message can change depending on whether X or y is\n        # validated first. Let us test the type of exception only:\n        err_msg = (\n            f&amp;quot;The estimator {name} does not raise a ValueError when an &amp;quot;\n            &amp;quot;empty data is used to train. Perhaps use check_array in train.&amp;quot;\n        )\n        with raises(ValueError, err_msg=err_msg):\n            e.fit(X_zero_samples, [])\n    \n        X_zero_features = np.empty(0).reshape(12, 0)\n        # the following y should be accepted by both classifiers and regressors\n        # and ignored by unsupervised models\n        y = _enforce_estimator_tags_y(e, np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]))\n        msg = r&amp;quot;0 feature\\(s\\) \\(shape=\\(\\d*, 0\\)\\) while a minimum of \\d* is required.&amp;quot;\n        with raises(ValueError, match=msg):\n&amp;gt;           e.fit(X_zero_features, y)\n\nX_zero_features = array([], shape=(12, 0), dtype=float64)\nX_zero_samples = array([], shape=(0, 3), dtype=float64)\ne          = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nerr_msg    = &amp;#x27;The estimator BasePerturbationCV does not raise a ValueError when an empty data is used to train. Perhaps use check_array in train.&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nmsg        = &amp;#x27;0 feature\\\\(s\\\\) \\\\(shape=\\\\(\\\\d*, 0\\\\)\\\\) while a minimum of \\\\d* is required.&amp;#x27;\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\ny          = array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2319: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([], shape=(12, 0), dtype=float64)\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_estimators_empty_data_messages at 0x7f4cfd87b010&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_empty_data_messages at 0x7f4cfd87b010&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_estimators_empty_data_messages at 0x7f4cfd87af80&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2318: in check_estimators_empty_data_messages\n    with raises(ValueError, match=msg):\n        X_zero_features = array([], shape=(12, 0), dtype=float64)\n        X_zero_samples = array([], shape=(0, 3), dtype=float64)\n        e          = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        err_msg    = &amp;#x27;The estimator BasePerturbationCV does not raise a ValueError when an empty data is used to train. Perhaps use check_array in train.&amp;#x27;\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        msg        = &amp;#x27;0 feature\\\\(s\\\\) \\\\(shape=\\\\(\\\\d*, 0\\\\)\\\\) while a minimum of \\\\d* is required.&amp;#x27;\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        y          = array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cf813f220&amp;gt;\nexc_type = &amp;lt;class &amp;#x27;sklearn.exceptions.NotFittedError&amp;#x27;&amp;gt;\nexc_value = NotFittedError(&amp;quot;This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;)\n_ = &amp;lt;traceback object at 0x7f4cf1b29f00&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f&amp;quot;Did not raise: {self.expected_exc_types}&amp;quot;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n                raise AssertionError(self.err_msg) from exc_value\n            else:\n                return False  # will re-raise the original exception\n    \n        if self.matches is not None:\n            err_msg = self.err_msg or (\n                &amp;quot;The error message should contain one of the following &amp;quot;\n                &amp;quot;patterns:\\n{}\\nGot {}&amp;quot;.format(&amp;quot;\\n&amp;quot;.join(self.matches), str(exc_value))\n            )\n            if not any(re.search(match, str(exc_value)) for match in self.matches):\n&amp;gt;               raise AssertionError(err_msg) from exc_value\nE               AssertionError: The error message should contain one of the following patterns:\nE               0 feature\\(s\\) \\(shape=\\(\\d*, 0\\)\\) while a minimum of \\d* is required.\nE               Got This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\n_          = &amp;lt;traceback object at 0x7f4cf1b29f00&amp;gt;\nerr_msg    = &amp;quot;The error message should contain one of the following patterns:\\n0 feature\\\\(s\\\\) \\\\(shape=\\\\(\\\\d*, 0\\\\)\\\\) while a m...t This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\nexc_type   = &amp;lt;class &amp;#x27;sklearn.exceptions.NotFittedError&amp;#x27;&amp;gt;\nexc_value  = NotFittedError(&amp;quot;This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;)\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cf813f220&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:1155: AssertionError\n--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_ensemble_clustered_inference.py::test_cludl_independence&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_ensemble_clustered_inference.py::test_cludl_independence&#34;, &#34;duration&#34;: &#34;221 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_ensemble_clustered_inference.py::test_cludl_independence&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;221 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_n_features_in_after_fitting]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_n_features_in_after_fitting]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_n_features_in_after_fitting]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_n_features_in_after_fitting at 0x7f4cfd8867a0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_n_features_in_after_fitting at 0x7f4cfd8867a0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_n_features_in_after_fitting at 0x7f4cfd886710&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4448: in check_n_features_in_after_fitting\n    estimator.fit(X, y)\n        X          = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n       [ 1.86755799, -0.97727788,  0.95008842, -0.1513572...    [-0.88778575, -1.98079647, -0.34791215,  0.15634897],\n       [ 1.23029068,  1.20237985, -0.38732682, -0.30230275]])\n        err_msg    = &amp;#x27;`BasePerturbationCV.fit()` does not set the `n_features_in_` attribute. You might want to use `sklearn.utils.validation.validate_data` instead of `check_array` in `BasePerturbationCV.fit()` which takes care of setting the attribute.&amp;#x27;\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        is_supported_X_types = True\n        n_samples  = 10\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CFAC4F940\n        tags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        y          = array([0, 1, 1, 0, 1, 0, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n       [ 1.86755799, -0.97727788,  0.95008842, -0.1513572...    [-0.88778575, -1.98079647, -0.34791215,  0.15634897],\n       [ 1.23029068,  1.20237985, -0.38732682, -0.30230275]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([0, 1, 1, 0, 1, 0, 0, 1, 0, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_matrix0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_matrix0]&#34;, &#34;duration&#34;: &#34;19 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_matrix0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;19 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_tags_renamed0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_tags_renamed0]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_tags_renamed0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dtype_object0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dtype_object0]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dtype_object0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_idempotent0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_idempotent0]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_idempotent0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_readonly_memmap_input]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_readonly_memmap_input]&#34;, &#34;duration&#34;: &#34;9 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_readonly_memmap_input]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;9 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_readonly_memmap_input at 0x7f4cfd884670&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_readonly_memmap_input at 0x7f4cfd884670&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_readonly_memmap_input at 0x7f4cfd8845e0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3219: in check_readonly_memmap_input\n    assert estimator.fit(X, y) is estimator\n        X          = memmap([[ 2.21021495,  1.27582618],\n        [ 1.28933778,  3.44969159],\n        [ 2.10102604,  0.71047981],\n        [ ...08313281],\n        [-2.77969937,  3.69537262],\n        [ 1.7373078 ,  4.42546234],\n        [-0.29661333,  4.12026211]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        y          = memmap([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = memmap([[ 2.21021495,  1.27582618],\n        [ 1.28933778,  3.44969159],\n        [ 2.10102604,  0.71047981],\n        [ ...08313281],\n        [-2.77969937,  3.69537262],\n        [ 1.7373078 ,  4.42546234],\n        [-0.29661333,  4.12026211]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = memmap([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf18d85f0&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf18d8dd0&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.556...537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]]), array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf18d85f0&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.55670201],\n       [ 2.47...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\ny_train = array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.55670201],\n       [ 2.47...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1162.50it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit1d1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit1d1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit1d1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_f_contiguous_array_estimator1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_f_contiguous_array_estimator1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_f_contiguous_array_estimator1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_overwrite_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_overwrite_params]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_overwrite_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4cfd8852d0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4cfd8852d0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_overwrite_params at 0x7f4cfd885240&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3608: in check_estimators_overwrite_params\n    estimator.fit(X, y)\n        X          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        original_params = {&amp;#x27;cv&amp;#x27;: KFold(n_splits=2, random_state=None, shuffle=False), &amp;#x27;estimators&amp;#x27;: LinearRegression(), &amp;#x27;estimators__copy_X&amp;#x27;: True, &amp;#x27;estimators__fit_intercept&amp;#x27;: True, ...}\n        params     = {&amp;#x27;cv&amp;#x27;: KFold(n_splits=2, random_state=None, shuffle=False), &amp;#x27;estimators&amp;#x27;: LinearRegression(), &amp;#x27;estimators__copy_X&amp;#x27;: True, &amp;#x27;estimators__fit_intercept&amp;#x27;: True, ...}\n        y          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1f1bbc0&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf1f19e70&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.556...537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]]), array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1f1bbc0&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.55670201],\n       [ 2.47...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\ny_train = array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.55670201],\n       [ 2.47...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1209.78it/s]\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_complex_data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_complex_data]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_complex_data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\n    def check_complex_data(name, estimator_orig):\n        rng = np.random.RandomState(42)\n        # check that estimators raise an exception on providing complex data\n        X = rng.uniform(size=10) + 1j * rng.uniform(size=10)\n        X = X.reshape(-1, 1)\n    \n        # Something both valid for classification and regression\n        y = rng.randint(low=0, high=2, size=10) + 1j\n        estimator = clone(estimator_orig)\n        set_random_state(estimator, random_state=0)\n        with raises(ValueError, match=&amp;quot;Complex data not supported&amp;quot;):\n&amp;gt;           estimator.fit(X, y)\n\nX          = array([[0.37454012+0.02058449j],\n       [0.95071431+0.96990985j],\n       [0.73199394+0.83244264j],\n       [0.59865848+...08361+0.30424224j],\n       [0.86617615+0.52475643j],\n       [0.60111501+0.43194502j],\n       [0.70807258+0.29122914j]])\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CFAC4FC40\ny          = array([0.+1.j, 0.+1.j, 1.+1.j, 1.+1.j, 1.+1.j, 1.+1.j, 1.+1.j, 0.+1.j,\n       1.+1.j, 1.+1.j])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1678: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[0.37454012+0.02058449j],\n       [0.95071431+0.96990985j],\n       [0.73199394+0.83244264j],\n       [0.59865848+...08361+0.30424224j],\n       [0.86617615+0.52475643j],\n       [0.60111501+0.43194502j],\n       [0.70807258+0.29122914j]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([0.+1.j, 0.+1.j, 1.+1.j, 1.+1.j, 1.+1.j, 1.+1.j, 1.+1.j, 0.+1.j,\n       1.+1.j, 1.+1.j])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_complex_data at 0x7f4cfd879ab0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_complex_data at 0x7f4cfd879ab0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1677: in check_complex_data\n    with raises(ValueError, match=&amp;quot;Complex data not supported&amp;quot;):\n        X          = array([[0.37454012+0.02058449j],\n       [0.95071431+0.96990985j],\n       [0.73199394+0.83244264j],\n       [0.59865848+...08361+0.30424224j],\n       [0.86617615+0.52475643j],\n       [0.60111501+0.43194502j],\n       [0.70807258+0.29122914j]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CFAC4FC40\n        y          = array([0.+1.j, 0.+1.j, 1.+1.j, 1.+1.j, 1.+1.j, 1.+1.j, 1.+1.j, 0.+1.j,\n       1.+1.j, 1.+1.j])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cfc5b40d0&amp;gt;\nexc_type = &amp;lt;class &amp;#x27;sklearn.exceptions.NotFittedError&amp;#x27;&amp;gt;\nexc_value = NotFittedError(&amp;quot;This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;)\n_ = &amp;lt;traceback object at 0x7f4cf1737480&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f&amp;quot;Did not raise: {self.expected_exc_types}&amp;quot;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n                raise AssertionError(self.err_msg) from exc_value\n            else:\n                return False  # will re-raise the original exception\n    \n        if self.matches is not None:\n            err_msg = self.err_msg or (\n                &amp;quot;The error message should contain one of the following &amp;quot;\n                &amp;quot;patterns:\\n{}\\nGot {}&amp;quot;.format(&amp;quot;\\n&amp;quot;.join(self.matches), str(exc_value))\n            )\n            if not any(re.search(match, str(exc_value)) for match in self.matches):\n&amp;gt;               raise AssertionError(err_msg) from exc_value\nE               AssertionError: The error message should contain one of the following patterns:\nE               Complex data not supported\nE               Got This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\n_          = &amp;lt;traceback object at 0x7f4cf1737480&amp;gt;\nerr_msg    = &amp;quot;The error message should contain one of the following patterns:\\nComplex data not supported\\nGot This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\nexc_type   = &amp;lt;class &amp;#x27;sklearn.exceptions.NotFittedError&amp;#x27;&amp;gt;\nexc_value  = NotFittedError(&amp;quot;This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;)\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cfc5b40d0&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:1155: AssertionError\n--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_empty_data_messages]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_empty_data_messages]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_empty_data_messages]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit2d_1feature]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit2d_1feature]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit2d_1feature]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_fit2d_1feature at 0x7f4cfd87a3b0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit2d_1feature at 0x7f4cfd87a3b0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_fit2d_1feature at 0x7f4cfd87a320&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1956: in check_fit2d_1feature\n    estimator.fit(X, y)\n        X          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        msgs       = [&amp;#x27;1 feature\\\\(s\\\\)&amp;#x27;, &amp;#x27;n_features = 1&amp;#x27;, &amp;#x27;n_features=1&amp;#x27;]\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1B38540\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf80c9ee0&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf80c89e0&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]]), array([1, 1, 2, 2, 1]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf80c9ee0&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\ny_train = array([1, 1, 2, 2, 1])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 1, 2, 2, 1])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 921.52it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_dont_overwrite_parameters]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_dont_overwrite_parameters]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_dont_overwrite_parameters]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_dont_overwrite_parameters at 0x7f4cfd879d80&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_dont_overwrite_parameters at 0x7f4cfd879d80&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_dont_overwrite_parameters at 0x7f4cfd879cf0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1726: in check_dont_overwrite_parameters\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        dict_before_fit = {&amp;#x27;cv&amp;#x27;: KFold(n_splits=2, random_state=None, shuffle=False), &amp;#x27;estimators&amp;#x27;: LinearRegression(), &amp;#x27;n_jobs&amp;#x27;: 1, &amp;#x27;statistical_test&amp;#x27;: &amp;#x27;nb-ttest&amp;#x27;}\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1B38340\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf80c9d20&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf80c9c40&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       ...2663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]]), array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf80c9d20&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\ny_train = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 942.33it/s]\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_pipeline_consistency]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_pipeline_consistency]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_pipeline_consistency]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_pipeline_consistency at 0x7f4cfd87ab00&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_pipeline_consistency at 0x7f4cfd87ab00&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_pipeline_consistency at 0x7f4cfd87aa70&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2156: in check_pipeline_consistency\n    estimator.fit(X, y)\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        pipeline   = Pipeline(steps=[(&amp;#x27;baseperturbationcv&amp;#x27;,\n                 BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                                    estimators=LinearRegression()))])\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf18d8580&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf1fa75a0&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n ...,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]]), array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf18d8580&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n       [ 0.17640523,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\ny_train = array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n       [ 0.17640523,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1015.94it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_n_features_in]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_n_features_in]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_n_features_in]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_n_features_in at 0x7f4cfd8865f0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_n_features_in at 0x7f4cfd8865f0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4383: in check_n_features_in\n    estimator.fit(X, y)\n        X          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        n_samples  = 100\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CF1B38740\n        y          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf80b4eb0&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf80b4e40&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[101.8831507 ,  98.65224094],\n       [ 98.729515  , 100.96939671],\n       [ 98.82687659, 1..., 0, 0, 1, 0, 1, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n       1, 1, 1, 1, 0, 0]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf80b4eb0&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[101.8831507 ,  98.65224094],\n       [ 98.729515  , 100.96939671],\n       [ 98.82687659, 101.94362119],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\ny_train = array([1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n       1, 1, 1, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[101.8831507 ,  98.65224094],\n       [ 98.729515  , 100.96939671],\n       [ 98.82687659, 101.94362119],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n       1, 1, 1, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 982.50it/s]\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_fit_returns_self]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_fit_returns_self]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_fit_returns_self]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_estimators_fit_returns_self at 0x7f4cfd884550&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_fit_returns_self at 0x7f4cfd884550&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_estimators_fit_returns_self at 0x7f4cfd8844c0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3200: in check_estimators_fit_returns_self\n    assert estimator.fit(X, y) is estimator\n        X          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        y          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit1d0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit1d0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit1d0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_f_contiguous_array_estimator0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_f_contiguous_array_estimator0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_f_contiguous_array_estimator0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_sparse_tag]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_sparse_tag]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_sparse_tag]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\n    def check_estimator_sparse_tag(name, estimator_orig):\n        &amp;quot;&amp;quot;&amp;quot;Check that estimator tag related with accepting sparse data is properly set.&amp;quot;&amp;quot;&amp;quot;\n        estimator = clone(estimator_orig)\n    \n        rng = np.random.RandomState(0)\n        n_samples = 15 if name == &amp;quot;SpectralCoclustering&amp;quot; else 40\n        X = rng.uniform(size=(n_samples, 3))\n        X[X &amp;lt; 0.6] = 0\n        y = rng.randint(0, 3, size=n_samples)\n        X = _enforce_estimator_tags_X(estimator, X)\n        y = _enforce_estimator_tags_y(estimator, y)\n        X = sparse.csr_array(X)\n    \n        tags = get_tags(estimator)\n        if tags.input_tags.sparse:\n            try:\n                estimator.fit(X, y)  # should pass\n            except Exception as e:\n                err_msg = (\n                    f&amp;quot;Estimator {name} raised an exception. &amp;quot;\n                    f&amp;quot;The tag self.input_tags.sparse={tags.input_tags.sparse} &amp;quot;\n                    &amp;quot;might not be consistent with the estimator&amp;#x27;s ability to &amp;quot;\n                    &amp;quot;handle sparse data (i.e. controlled by the parameter `accept_sparse`&amp;quot;\n                    &amp;quot; in `validate_data` or `check_array` functions).&amp;quot;\n                )\n                raise AssertionError(err_msg) from e\n        else:\n            err_msg = (\n                f&amp;quot;Estimator {name} raised an exception. &amp;quot;\n                &amp;quot;The estimator failed when fitted on sparse data in accordance &amp;quot;\n                f&amp;quot;with its tag self.input_tags.sparse={tags.input_tags.sparse} &amp;quot;\n                &amp;quot;but didn&amp;#x27;t raise the appropriate error: error message should &amp;quot;\n                &amp;quot;state explicitly that sparse input is not supported if this is &amp;quot;\n                &amp;quot;not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\n            )\n            try:\n&amp;gt;               estimator.fit(X, y)  # should fail with appropriate error\n\nX          = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\nerr_msg    = &amp;#x27;Estimator BasePerturbationCV raised an exception. The estimator failed when fitted on sparse data in accordance with ...licitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;#x27;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nn_samples  = 40\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CF1B38F40\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([0, 1, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 2, 0, 2, 2, 1, 1,\n       1, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 2, 1, 1, 0, 0, 0, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1276: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([0, 1, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 2, 0, 2, 2, 1, 1,\n       1, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 2, 1, 1, 0, 0, 0, 2])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_estimator_sparse_tag at 0x7f4cfd878f70&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimator_sparse_tag at 0x7f4cfd878f70&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\n    def check_estimator_sparse_tag(name, estimator_orig):\n        &amp;quot;&amp;quot;&amp;quot;Check that estimator tag related with accepting sparse data is properly set.&amp;quot;&amp;quot;&amp;quot;\n        estimator = clone(estimator_orig)\n    \n        rng = np.random.RandomState(0)\n        n_samples = 15 if name == &amp;quot;SpectralCoclustering&amp;quot; else 40\n        X = rng.uniform(size=(n_samples, 3))\n        X[X &amp;lt; 0.6] = 0\n        y = rng.randint(0, 3, size=n_samples)\n        X = _enforce_estimator_tags_X(estimator, X)\n        y = _enforce_estimator_tags_y(estimator, y)\n        X = sparse.csr_array(X)\n    \n        tags = get_tags(estimator)\n        if tags.input_tags.sparse:\n            try:\n                estimator.fit(X, y)  # should pass\n            except Exception as e:\n                err_msg = (\n                    f&amp;quot;Estimator {name} raised an exception. &amp;quot;\n                    f&amp;quot;The tag self.input_tags.sparse={tags.input_tags.sparse} &amp;quot;\n                    &amp;quot;might not be consistent with the estimator&amp;#x27;s ability to &amp;quot;\n                    &amp;quot;handle sparse data (i.e. controlled by the parameter `accept_sparse`&amp;quot;\n                    &amp;quot; in `validate_data` or `check_array` functions).&amp;quot;\n                )\n                raise AssertionError(err_msg) from e\n        else:\n            err_msg = (\n                f&amp;quot;Estimator {name} raised an exception. &amp;quot;\n                &amp;quot;The estimator failed when fitted on sparse data in accordance &amp;quot;\n                f&amp;quot;with its tag self.input_tags.sparse={tags.input_tags.sparse} &amp;quot;\n                &amp;quot;but didn&amp;#x27;t raise the appropriate error: error message should &amp;quot;\n                &amp;quot;state explicitly that sparse input is not supported if this is &amp;quot;\n                &amp;quot;not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\n            )\n            try:\n                estimator.fit(X, y)  # should fail with appropriate error\n            except (ValueError, TypeError) as e:\n                if re.search(&amp;quot;[Ss]parse&amp;quot;, str(e)):\n                    # Got the right error type and mentioning sparse issue\n                    return\n&amp;gt;               raise AssertionError(err_msg) from e\nE               AssertionError: Estimator BasePerturbationCV raised an exception. The estimator failed when fitted on sparse data in accordance with its tag self.input_tags.sparse=False but didn&amp;#x27;t raise the appropriate error: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).\n\nX          = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\nerr_msg    = &amp;#x27;Estimator BasePerturbationCV raised an exception. The estimator failed when fitted on sparse data in accordance with ...licitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;#x27;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nn_samples  = 40\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CF1B38F40\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([0, 1, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 2, 0, 2, 2, 1, 1,\n       1, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 2, 1, 1, 0, 0, 0, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1281: AssertionError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_readonly_memmap_input0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_readonly_memmap_input0]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_readonly_memmap_input0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_do_not_raise_errors_in_init_or_set_params0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_do_not_raise_errors_in_init_or_set_params0]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_do_not_raise_errors_in_init_or_set_params0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit_check_is_fitted]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit_check_is_fitted]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit_check_is_fitted]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7f4cfd886560&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7f4cfd886560&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4353: in check_fit_check_is_fitted\n    estimator.fit(X, y)\n        X          = array([[100.49671415,  99.8617357 ],\n       [100.64768854, 101.52302986],\n       [ 99.76584663,  99.76586304],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        n_samples  = 100\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CF1B39140\n        y          = array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,...1,\n       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[100.49671415,  99.8617357 ],\n       [100.64768854, 101.52302986],\n       [ 99.76584663,  99.76586304],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,...1,\n       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_1sample0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_1sample0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_1sample0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_cloneable1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_cloneable1]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_cloneable1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit2d_1feature]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit2d_1feature]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit2d_1feature]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\n    @ignore_warnings\n    def check_fit2d_1feature(name, estimator_orig):\n        # check fitting a 2d array with only 1 feature either works or returns\n        # informative message\n        rnd = np.random.RandomState(0)\n        X = 3 * rnd.uniform(size=(10, 1))\n        X = _enforce_estimator_tags_X(estimator_orig, X)\n        y = X[:, 0].astype(int)\n        estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if hasattr(estimator, &amp;quot;n_components&amp;quot;):\n            estimator.n_components = 1\n        if hasattr(estimator, &amp;quot;n_clusters&amp;quot;):\n            estimator.n_clusters = 1\n        # ensure two labels in subsample for RandomizedLogisticRegression\n        if name == &amp;quot;RandomizedLogisticRegression&amp;quot;:\n            estimator.sample_fraction = 1\n        # ensure non skipped trials for RANSACRegressor\n        if name == &amp;quot;RANSACRegressor&amp;quot;:\n            estimator.residual_threshold = 0.5\n    \n        y = _enforce_estimator_tags_y(estimator, y)\n        set_random_state(estimator, 1)\n    \n        msgs = [r&amp;quot;1 feature\\(s\\)&amp;quot;, &amp;quot;n_features = 1&amp;quot;, &amp;quot;n_features=1&amp;quot;]\n    \n        with raises(ValueError, match=msgs, may_pass=True):\n&amp;gt;           estimator.fit(X, y)\n\nX          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nmsgs       = [&amp;#x27;1 feature\\\\(s\\\\)&amp;#x27;, &amp;#x27;n_features = 1&amp;#x27;, &amp;#x27;n_features=1&amp;#x27;]\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\nrnd        = RandomState(MT19937) at 0x7F4CF1B39040\ny          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1956: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_fit2d_1feature at 0x7f4cfd87a3b0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit2d_1feature at 0x7f4cfd87a3b0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_fit2d_1feature at 0x7f4cfd87a320&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1955: in check_fit2d_1feature\n    with raises(ValueError, match=msgs, may_pass=True):\n        X          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        msgs       = [&amp;#x27;1 feature\\\\(s\\\\)&amp;#x27;, &amp;#x27;n_features = 1&amp;#x27;, &amp;#x27;n_features=1&amp;#x27;]\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1B39040\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cfb052bf0&amp;gt;\nexc_type = &amp;lt;class &amp;#x27;sklearn.exceptions.NotFittedError&amp;#x27;&amp;gt;\nexc_value = NotFittedError(&amp;quot;This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;)\n_ = &amp;lt;traceback object at 0x7f4cfa581140&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f&amp;quot;Did not raise: {self.expected_exc_types}&amp;quot;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n                raise AssertionError(self.err_msg) from exc_value\n            else:\n                return False  # will re-raise the original exception\n    \n        if self.matches is not None:\n            err_msg = self.err_msg or (\n                &amp;quot;The error message should contain one of the following &amp;quot;\n                &amp;quot;patterns:\\n{}\\nGot {}&amp;quot;.format(&amp;quot;\\n&amp;quot;.join(self.matches), str(exc_value))\n            )\n            if not any(re.search(match, str(exc_value)) for match in self.matches):\n&amp;gt;               raise AssertionError(err_msg) from exc_value\nE               AssertionError: The error message should contain one of the following patterns:\nE               1 feature\\(s\\)\nE               n_features = 1\nE               n_features=1\nE               Got This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\n_          = &amp;lt;traceback object at 0x7f4cfa581140&amp;gt;\nerr_msg    = &amp;quot;The error message should contain one of the following patterns:\\n1 feature\\\\(s\\\\)\\nn_features = 1\\nn_features=1\\nGot This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\nexc_type   = &amp;lt;class &amp;#x27;sklearn.exceptions.NotFittedError&amp;#x27;&amp;gt;\nexc_value  = NotFittedError(&amp;quot;This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;)\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cfb052bf0&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:1155: AssertionError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_dtypes]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_dtypes]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_dtypes]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_dtypes at 0x7f4cfd87ae60&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_dtypes at 0x7f4cfd87ae60&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_dtypes at 0x7f4cfd87add0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2257: in check_estimators_dtypes\n    estimator.fit(X_train, y)\n        X_train    = array([[1.6464405 , 2.145568  , 1.80829   , 1.6346495 , 1.2709644 ],\n       [1.9376824 , 1.3127615 , 2.675319  , 2.890...6 , 2.1489816 , 0.8682183 ],\n       [0.5495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32)\n        X_train_32 = array([[1.6464405 , 2.145568  , 1.80829   , 1.6346495 , 1.2709644 ],\n       [1.9376824 , 1.3127615 , 2.675319  , 2.890...6 , 2.1489816 , 0.8682183 ],\n       [0.5495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32)\n        X_train_64 = array([[1.64644051, 2.14556789, 1.80829   , 1.63464952, 1.27096438],\n       [1.93768239, 1.31276155, 2.67531896, 2.890... 2.00223112, 0.39539361, 2.14898157, 0.8682183 ],\n       [0.54957408, 1.75953877, 0.06032264, 2.48682022, 0.01408643]])\n        X_train_int_32 = array([[1, 2, 1, 1, 1],\n       [1, 1, 2, 2, 1],\n       [2, 1, 1, 2, 0],\n       [0, 0, 2, 2, 2],\n       [2, 2, 1, 2, 0]...0, 0, 0],\n       [0, 1, 0, 2, 1],\n       [0, 1, 0, 1, 2],\n       [0, 2, 0, 2, 0],\n       [0, 1, 0, 2, 0]], dtype=int32)\n        X_train_int_64 = array([[1, 2, 1, 1, 1],\n       [1, 1, 2, 2, 1],\n       [2, 1, 1, 2, 0],\n       [0, 0, 2, 2, 2],\n       [2, 2, 1, 2, 0]...      [0, 0, 0, 0, 0],\n       [0, 1, 0, 2, 1],\n       [0, 1, 0, 1, 2],\n       [0, 2, 0, 2, 0],\n       [0, 1, 0, 2, 0]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        methods    = [&amp;#x27;predict&amp;#x27;, &amp;#x27;transform&amp;#x27;, &amp;#x27;decision_function&amp;#x27;, &amp;#x27;predict_proba&amp;#x27;]\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1B39440\n        y          = array([1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.6464405 , 2.145568  , 1.80829   , 1.6346495 , 1.2709644 ],\n       [1.9376824 , 1.3127615 , 2.675319  , 2.890...6 , 2.1489816 , 0.8682183 ],\n       [0.5495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32)\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1fb98c0&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf1fb92a0&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[1.7105902 , 1.3158046 , 2.9651215 , 0.30613443, 0.6266303 ],\n       [0.48392853, 1.959324...495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32), array([1, 2, 1, 2, 1, 2, 1, 2, 1, 2]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1fb98c0&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[1.7105902 , 1.3158046 , 2.9651215 , 0.30613443, 0.6266303 ],\n       [0.48392853, 1.9593248 , 0.7598748 , 1.398...6 , 2.1489816 , 0.8682183 ],\n       [0.5495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32)\ny_train = array([1, 2, 1, 2, 1, 2, 1, 2, 1, 2])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[1.7105902 , 1.3158046 , 2.9651215 , 0.30613443, 0.6266303 ],\n       [0.48392853, 1.9593248 , 0.7598748 , 1.398...6 , 2.1489816 , 0.8682183 ],\n       [0.5495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32)\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 2, 1, 2, 1, 2, 1, 2, 1, 2])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1007.16it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_fit_returns_self]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_fit_returns_self]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_fit_returns_self]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_fit_returns_self at 0x7f4cfd884550&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_fit_returns_self at 0x7f4cfd884550&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_fit_returns_self at 0x7f4cfd8844c0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3200: in check_estimators_fit_returns_self\n    assert estimator.fit(X, y) is estimator\n        X          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        y          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1fb8f20&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf1fb8c80&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.556...537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]]), array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1fb8f20&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.55670201],\n       [ 2.47...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\ny_train = array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 1.9263585 ,  4.15243012],\n       [-2.03655619,  2.47980796],\n       [ 4.32502215, -0.55670201],\n       [ 2.47...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1046.74it/s]\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_check_is_fitted1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_check_is_fitted1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_check_is_fitted1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_cloneable0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_cloneable0]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_cloneable0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_methods_sample_order_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_methods_sample_order_invariance]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_methods_sample_order_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_methods_sample_order_invariance at 0x7f4cfd87a170&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_methods_sample_order_invariance at 0x7f4cfd87a170&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_methods_sample_order_invariance at 0x7f4cfd87a0e0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1862: in check_methods_sample_order_invariance\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1B39040\n        tags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf80b5150&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf80b7530&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       ...2663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]]), array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf80b5150&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\ny_train = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1110.78it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_1sample1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_1sample1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_1sample1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_valid_tag_types]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_valid_tag_types]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_valid_tag_types]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_overwrite_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_overwrite_params]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_overwrite_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4cfd8852d0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4cfd8852d0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_estimators_overwrite_params at 0x7f4cfd885240&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3608: in check_estimators_overwrite_params\n    estimator.fit(X, y)\n        X          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        original_params = {&amp;#x27;cv&amp;#x27;: KFold(n_splits=2, random_state=None, shuffle=False), &amp;#x27;estimators&amp;#x27;: [LinearRegression(), LinearRegression()], &amp;#x27;n_jobs&amp;#x27;: 1, &amp;#x27;statistical_test&amp;#x27;: &amp;#x27;nb-ttest&amp;#x27;}\n        params     = {&amp;#x27;cv&amp;#x27;: KFold(n_splits=2, random_state=None, shuffle=False), &amp;#x27;estimators&amp;#x27;: [LinearRegression(), LinearRegression()], &amp;#x27;n_jobs&amp;#x27;: 1, &amp;#x27;statistical_test&amp;#x27;: &amp;#x27;nb-ttest&amp;#x27;}\n        y          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_check_is_fitted0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_check_is_fitted0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_check_is_fitted0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_pickle(readonly_memmap=True)]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_pickle(readonly_memmap=True)]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_pickle(readonly_memmap=True)]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_estimators_pickle at 0x7f4cfd87b370&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;, readonly_memmap=True)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_pickle at 0x7f4cfd87b370&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;, readonly_memmap=True)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_estimators_pickle at 0x7f4cfd87b2e0&amp;gt;\n        kwargs     = {&amp;#x27;readonly_memmap&amp;#x27;: True}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2415: in check_estimators_pickle\n    estimator.fit(X, y)\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        check_methods = [&amp;#x27;predict&amp;#x27;, &amp;#x27;transform&amp;#x27;, &amp;#x27;decision_function&amp;#x27;, &amp;#x27;predict_proba&amp;#x27;]\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        readonly_memmap = True\n        tags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_mixin_order]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_mixin_order]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_mixin_order]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_base_cv_errors&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_base_cv_errors&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_base_cv_errors&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 912.00it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_pickle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_pickle]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_pickle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_estimators_pickle at 0x7f4cfd87b370&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_pickle at 0x7f4cfd87b370&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_estimators_pickle at 0x7f4cfd87b2e0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2415: in check_estimators_pickle\n    estimator.fit(X, y)\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        check_methods = [&amp;#x27;predict&amp;#x27;, &amp;#x27;transform&amp;#x27;, &amp;#x27;decision_function&amp;#x27;, &amp;#x27;predict_proba&amp;#x27;]\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        readonly_memmap = False\n        tags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_readonly_memmap_input1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_readonly_memmap_input1]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_readonly_memmap_input1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_do_not_raise_errors_in_init_or_set_params1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_do_not_raise_errors_in_init_or_set_params1]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_do_not_raise_errors_in_init_or_set_params1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_pickle(readonly_memmap=True)1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_pickle(readonly_memmap=True)1]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_pickle(readonly_memmap=True)1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_repr]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_repr]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_repr]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_n_features_in]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_n_features_in]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_n_features_in]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_n_features_in at 0x7f4cfd8865f0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_n_features_in at 0x7f4cfd8865f0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4383: in check_n_features_in\n    estimator.fit(X, y)\n        X          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        n_samples  = 100\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CF1B39540\n        y          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_cloneable2]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_cloneable2]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_cloneable2]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_sparse_array]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_sparse_array]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_sparse_array]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nsparse_type = &amp;lt;class &amp;#x27;scipy.sparse._csr.csr_array&amp;#x27;&amp;gt;\n\n    def _check_estimator_sparse_container(name, estimator_orig, sparse_type):\n        rng = np.random.RandomState(0)\n        X = rng.uniform(size=(40, 3))\n        X[X &amp;lt; 0.6] = 0\n        X = _enforce_estimator_tags_X(estimator_orig, X)\n        y = (4 * rng.uniform(size=X.shape[0])).astype(np.int32)\n        # catch deprecation warnings\n        with ignore_warnings(category=FutureWarning):\n            estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n        tags = get_tags(estimator_orig)\n        for matrix_format, X in _generate_sparse_data(sparse_type(X)):\n            # catch deprecation warnings\n            with ignore_warnings(category=FutureWarning):\n                estimator = clone(estimator_orig)\n                if name in [&amp;quot;Scaler&amp;quot;, &amp;quot;StandardScaler&amp;quot;]:\n                    estimator.set_params(with_mean=False)\n            # fit and predict\n            if &amp;quot;64&amp;quot; in matrix_format:\n                err_msg = (\n                    f&amp;quot;Estimator {name} doesn&amp;#x27;t seem to support {matrix_format} &amp;quot;\n                    &amp;quot;matrix, and is not failing gracefully, e.g. by using &amp;quot;\n                    &amp;quot;check_array(X, accept_large_sparse=False).&amp;quot;\n                )\n            else:\n                err_msg = (\n                    f&amp;quot;Estimator {name} doesn&amp;#x27;t seem to fail gracefully on sparse &amp;quot;\n                    &amp;quot;data: error message should state explicitly that sparse &amp;quot;\n                    &amp;quot;input is not supported if this is not the case, e.g. by using &amp;quot;\n                    &amp;quot;check_array(X, accept_sparse=False).&amp;quot;\n                )\n            with raises(\n                (TypeError, ValueError),\n                match=[&amp;quot;sparse&amp;quot;, &amp;quot;Sparse&amp;quot;],\n                may_pass=True,\n                err_msg=err_msg,\n            ):\n                with ignore_warnings(category=FutureWarning):\n&amp;gt;                   estimator.fit(X, y)\n\nX          = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\nerr_msg    = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nmatrix_format = &amp;#x27;csr&amp;#x27;\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CF1B39340\nsparse_type = &amp;lt;class &amp;#x27;scipy.sparse._csr.csr_array&amp;#x27;&amp;gt;\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0], dtype=int32)\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1330: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0], dtype=int32)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_estimator_sparse_array at 0x7f4cfd879120&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimator_sparse_array at 0x7f4cfd879120&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1351: in check_estimator_sparse_array\n    _check_estimator_sparse_container(name, estimator_orig, sparse.csr_array)\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1323: in _check_estimator_sparse_container\n    with raises(\n        X          = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\n        err_msg    = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        matrix_format = &amp;#x27;csr&amp;#x27;\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CF1B39340\n        sparse_type = &amp;lt;class &amp;#x27;scipy.sparse._csr.csr_array&amp;#x27;&amp;gt;\n        tags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        y          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0], dtype=int32)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4d02fc8520&amp;gt;\nexc_type = &amp;lt;class &amp;#x27;sklearn.exceptions.NotFittedError&amp;#x27;&amp;gt;\nexc_value = NotFittedError(&amp;quot;This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;)\n_ = &amp;lt;traceback object at 0x7f4cf1985080&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f&amp;quot;Did not raise: {self.expected_exc_types}&amp;quot;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n                raise AssertionError(self.err_msg) from exc_value\n            else:\n                return False  # will re-raise the original exception\n    \n        if self.matches is not None:\n            err_msg = self.err_msg or (\n                &amp;quot;The error message should contain one of the following &amp;quot;\n                &amp;quot;patterns:\\n{}\\nGot {}&amp;quot;.format(&amp;quot;\\n&amp;quot;.join(self.matches), str(exc_value))\n            )\n            if not any(re.search(match, str(exc_value)) for match in self.matches):\n&amp;gt;               raise AssertionError(err_msg) from exc_value\nE               AssertionError: Estimator BasePerturbationCV doesn&amp;#x27;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).\n\n_          = &amp;lt;traceback object at 0x7f4cf1985080&amp;gt;\nerr_msg    = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\nexc_type   = &amp;lt;class &amp;#x27;sklearn.exceptions.NotFittedError&amp;#x27;&amp;gt;\nexc_value  = NotFittedError(&amp;quot;This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;)\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4d02fc8520&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:1155: AssertionError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_no_attributes_set_in_init]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_no_attributes_set_in_init]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_no_attributes_set_in_init]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_cloneable1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_cloneable1]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_cloneable1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_valid_tag_types]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_valid_tag_types]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_valid_tag_types]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_n_features_in_after_fitting]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_n_features_in_after_fitting]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_n_features_in_after_fitting]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_n_features_in_after_fitting at 0x7f4cfd8867a0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_n_features_in_after_fitting at 0x7f4cfd8867a0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_n_features_in_after_fitting at 0x7f4cfd886710&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4448: in check_n_features_in_after_fitting\n    estimator.fit(X, y)\n        X          = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n       [ 1.86755799, -0.97727788,  0.95008842, -0.1513572...    [-0.88778575, -1.98079647, -0.34791215,  0.15634897],\n       [ 1.23029068,  1.20237985, -0.38732682, -0.30230275]])\n        err_msg    = &amp;#x27;`BasePerturbationCV.fit()` does not set the `n_features_in_` attribute. You might want to use `sklearn.utils.validation.validate_data` instead of `check_array` in `BasePerturbationCV.fit()` which takes care of setting the attribute.&amp;#x27;\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        is_supported_X_types = True\n        n_samples  = 10\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CF1B39640\n        tags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        y          = array([0, 1, 1, 0, 1, 0, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n       [ 1.86755799, -0.97727788,  0.95008842, -0.1513572...    [-0.88778575, -1.98079647, -0.34791215,  0.15634897],\n       [ 1.23029068,  1.20237985, -0.38732682, -0.30230275]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([0, 1, 1, 0, 1, 0, 0, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1fba6c0&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf1fbb530&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[-2.55298982,  0.6536186 ,  0.8644362 , -0.74216502],\n       [ 2.26975462, -1.45436567,  0...9647, -0.34791215,  0.15634897],\n       [ 1.23029068,  1.20237985, -0.38732682, -0.30230275]]), array([0, 0, 1, 0, 0]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1fba6c0&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[-2.55298982,  0.6536186 ,  0.8644362 , -0.74216502],\n       [ 2.26975462, -1.45436567,  0.04575852, -0.1871838...    [-0.88778575, -1.98079647, -0.34791215,  0.15634897],\n       [ 1.23029068,  1.20237985, -0.38732682, -0.30230275]])\ny_train = array([0, 0, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[-2.55298982,  0.6536186 ,  0.8644362 , -0.74216502],\n       [ 2.26975462, -1.45436567,  0.04575852, -0.1871838...    [-0.88778575, -1.98079647, -0.34791215,  0.15634897],\n       [ 1.23029068,  1.20237985, -0.38732682, -0.30230275]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 0, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 908.25it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_n_features_in1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_n_features_in1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_n_features_in1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_unfitted1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_unfitted1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_unfitted1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_f_contiguous_array_estimator]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_f_contiguous_array_estimator]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_f_contiguous_array_estimator]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_f_contiguous_array_estimator at 0x7f4cfd8791b0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_f_contiguous_array_estimator at 0x7f4cfd8791b0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1367: in check_f_contiguous_array_estimator\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CF1B39A40\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1fb9850&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf1fb9620&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       ...2663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]]), array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1fb9850&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\ny_train = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1208.73it/s]\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_unfitted]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_unfitted]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_unfitted]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_n_features_in0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_n_features_in0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_n_features_in0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_cloneable0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_cloneable0]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_cloneable0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_mixin_order]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_mixin_order]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_mixin_order]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_ensemble_clustered_inference.py::test_encludl_spatial&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_ensemble_clustered_inference.py::test_encludl_spatial&#34;, &#34;duration&#34;: &#34;00:00:06&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_ensemble_clustered_inference.py::test_encludl_spatial&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:06&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\nUsing number of features for multiple testing correction.\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.62it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.42it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.58it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.53it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.61it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.57it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1237.18it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.55it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.68it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.68it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.15it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.25it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.34it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1254.05it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.65it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.71it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.63it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.69it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.68it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.67it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1211.95it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.47it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.61it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.55it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.61it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.52it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.54it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1212.37it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.63it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.40it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.47it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.56it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.52it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.51it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1212.65it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.65it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.73it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.57it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.56it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.60it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.60it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1211.53it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.67it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.53it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.60it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.58it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.63it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.61it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1233.26it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.51it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.68it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.57it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.60it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.66it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.63it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 766.47it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.79it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.53it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.64it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.72it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.59it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.62it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1249.79it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.76it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.33it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.37it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.35it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.49it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.45it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1228.70it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_f_contiguous_array_estimator]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_f_contiguous_array_estimator]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_f_contiguous_array_estimator]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_f_contiguous_array_estimator at 0x7f4cfd8791b0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_f_contiguous_array_estimator at 0x7f4cfd8791b0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1367: in check_f_contiguous_array_estimator\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CF1B3A140\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_unfitted0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_unfitted0]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_unfitted0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_pickle(readonly_memmap=True)0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_pickle(readonly_memmap=True)0]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_pickle(readonly_memmap=True)0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_methods_subset_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_methods_subset_invariance]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_methods_subset_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_methods_subset_invariance at 0x7f4cfd87a050&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_methods_subset_invariance at 0x7f4cfd87a050&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_methods_subset_invariance at 0x7f4cfd879fc0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1822: in check_methods_subset_invariance\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1B3A540\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_cloneable3]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_cloneable3]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_cloneable3]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit1d]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit_score_takes_y]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit_score_takes_y]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit_score_takes_y]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_fit_score_takes_y at 0x7f4cfd87ad40&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_score_takes_y at 0x7f4cfd87ad40&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_fit_score_takes_y at 0x7f4cfd87acb0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2228: in check_fit_score_takes_y\n    func(X, y)\n        X          = array([[0.5488135 , 0.71518937, 0.60276338],\n       [0.54488318, 0.4236548 , 0.64589411],\n       [0.43758721, 0.891773...99, 0.0641475 , 0.69247212],\n       [0.56660145, 0.26538949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        func       = &amp;lt;bound method BasePerturbationCV.fit of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        func_name  = &amp;#x27;fit&amp;#x27;\n        funcs      = [&amp;#x27;fit&amp;#x27;, &amp;#x27;score&amp;#x27;, &amp;#x27;partial_fit&amp;#x27;, &amp;#x27;fit_predict&amp;#x27;, &amp;#x27;fit_transform&amp;#x27;]\n        n_samples  = 30\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1B39F40\n        y          = array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n       1, 2, 0, 1, 2, 0, 1, 2])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[0.5488135 , 0.71518937, 0.60276338],\n       [0.54488318, 0.4236548 , 0.64589411],\n       [0.43758721, 0.891773...99, 0.0641475 , 0.69247212],\n       [0.56660145, 0.26538949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n       1, 2, 0, 1, 2, 0, 1, 2])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1960120&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf19618c0&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[0.67063787, 0.21038256, 0.1289263 ],\n       [0.31542835, 0.36371077, 0.57019677],\n       ...8949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]]), array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1960120&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.67063787, 0.21038256, 0.1289263 ],\n       [0.31542835, 0.36371077, 0.57019677],\n       [0.43860151, 0.988373...99, 0.0641475 , 0.69247212],\n       [0.56660145, 0.26538949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]])\ny_train = array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.67063787, 0.21038256, 0.1289263 ],\n       [0.31542835, 0.36371077, 0.57019677],\n       [0.43860151, 0.988373...99, 0.0641475 , 0.69247212],\n       [0.56660145, 0.26538949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 968.44it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_get_params_invariance0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_get_params_invariance0]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_get_params_invariance0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_no_attributes_set_in_init1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_no_attributes_set_in_init1]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_no_attributes_set_in_init1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_methods_subset_invariance1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_methods_subset_invariance1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_methods_subset_invariance1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dict_unchanged0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dict_unchanged0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dict_unchanged0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_nan_inf]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_nan_inf]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_nan_inf]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\n    @ignore_warnings(category=FutureWarning)\n    def check_estimators_nan_inf(name, estimator_orig):\n        # Checks that Estimator X&amp;#x27;s do not contain NaN or inf.\n        rnd = np.random.RandomState(0)\n        X_train_finite = _enforce_estimator_tags_X(\n            estimator_orig, rnd.uniform(size=(10, 3))\n        )\n        X_train_nan = rnd.uniform(size=(10, 3))\n        X_train_nan[0, 0] = np.nan\n        X_train_inf = rnd.uniform(size=(10, 3))\n        X_train_inf[0, 0] = np.inf\n        y = np.ones(10)\n        y[:5] = 0\n        y = _enforce_estimator_tags_y(estimator_orig, y)\n        error_string_fit = f&amp;quot;Estimator {name} doesn&amp;#x27;t check for NaN and inf in fit.&amp;quot;\n        error_string_predict = f&amp;quot;Estimator {name} doesn&amp;#x27;t check for NaN and inf in predict.&amp;quot;\n        error_string_transform = (\n            f&amp;quot;Estimator {name} doesn&amp;#x27;t check for NaN and inf in transform.&amp;quot;\n        )\n        for X_train in [X_train_nan, X_train_inf]:\n            # catch deprecation warnings\n            with ignore_warnings(category=FutureWarning):\n                estimator = clone(estimator_orig)\n                set_random_state(estimator, 1)\n                # try to fit\n                with raises(ValueError, match=[&amp;quot;inf&amp;quot;, &amp;quot;NaN&amp;quot;], err_msg=error_string_fit):\n&amp;gt;                   estimator.fit(X_train, y)\n\nX_train    = array([[       nan, 0.77423369, 0.45615033],\n       [0.56843395, 0.0187898 , 0.6176355 ],\n       [0.61209572, 0.616934...51, 0.98837384, 0.10204481],\n       [0.20887676, 0.16130952, 0.65310833],\n       [0.2532916 , 0.46631077, 0.24442559]])\nX_train_finite = array([[0.5488135 , 0.71518937, 0.60276338],\n       [0.54488318, 0.4236548 , 0.64589411],\n       [0.43758721, 0.891773...56, 0.46147936, 0.78052918],\n       [0.11827443, 0.63992102, 0.14335329],\n       [0.94466892, 0.52184832, 0.41466194]])\nX_train_inf = array([[       inf, 0.11037514, 0.65632959],\n       [0.13818295, 0.19658236, 0.36872517],\n       [0.82099323, 0.097101...99, 0.0641475 , 0.69247212],\n       [0.56660145, 0.26538949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]])\nX_train_nan = array([[       nan, 0.77423369, 0.45615033],\n       [0.56843395, 0.0187898 , 0.6176355 ],\n       [0.61209572, 0.616934...51, 0.98837384, 0.10204481],\n       [0.20887676, 0.16130952, 0.65310833],\n       [0.2532916 , 0.46631077, 0.24442559]])\nerror_string_fit = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t check for NaN and inf in fit.&amp;quot;\nerror_string_predict = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t check for NaN and inf in predict.&amp;quot;\nerror_string_transform = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t check for NaN and inf in transform.&amp;quot;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\nrnd        = RandomState(MT19937) at 0x7F4CF1B39A40\ny          = array([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2348: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[       nan, 0.77423369, 0.45615033],\n       [0.56843395, 0.0187898 , 0.6176355 ],\n       [0.61209572, 0.616934...51, 0.98837384, 0.10204481],\n       [0.20887676, 0.16130952, 0.65310833],\n       [0.2532916 , 0.46631077, 0.24442559]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_estimators_nan_inf at 0x7f4cfd87b130&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_nan_inf at 0x7f4cfd87b130&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_estimators_nan_inf at 0x7f4cfd87b0a0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2347: in check_estimators_nan_inf\n    with raises(ValueError, match=[&amp;quot;inf&amp;quot;, &amp;quot;NaN&amp;quot;], err_msg=error_string_fit):\n        X_train    = array([[       nan, 0.77423369, 0.45615033],\n       [0.56843395, 0.0187898 , 0.6176355 ],\n       [0.61209572, 0.616934...51, 0.98837384, 0.10204481],\n       [0.20887676, 0.16130952, 0.65310833],\n       [0.2532916 , 0.46631077, 0.24442559]])\n        X_train_finite = array([[0.5488135 , 0.71518937, 0.60276338],\n       [0.54488318, 0.4236548 , 0.64589411],\n       [0.43758721, 0.891773...56, 0.46147936, 0.78052918],\n       [0.11827443, 0.63992102, 0.14335329],\n       [0.94466892, 0.52184832, 0.41466194]])\n        X_train_inf = array([[       inf, 0.11037514, 0.65632959],\n       [0.13818295, 0.19658236, 0.36872517],\n       [0.82099323, 0.097101...99, 0.0641475 , 0.69247212],\n       [0.56660145, 0.26538949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]])\n        X_train_nan = array([[       nan, 0.77423369, 0.45615033],\n       [0.56843395, 0.0187898 , 0.6176355 ],\n       [0.61209572, 0.616934...51, 0.98837384, 0.10204481],\n       [0.20887676, 0.16130952, 0.65310833],\n       [0.2532916 , 0.46631077, 0.24442559]])\n        error_string_fit = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t check for NaN and inf in fit.&amp;quot;\n        error_string_predict = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t check for NaN and inf in predict.&amp;quot;\n        error_string_transform = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t check for NaN and inf in transform.&amp;quot;\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1B39A40\n        y          = array([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cfa669b40&amp;gt;\nexc_type = &amp;lt;class &amp;#x27;sklearn.exceptions.NotFittedError&amp;#x27;&amp;gt;\nexc_value = NotFittedError(&amp;quot;This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;)\n_ = &amp;lt;traceback object at 0x7f4cf1b70f00&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f&amp;quot;Did not raise: {self.expected_exc_types}&amp;quot;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n                raise AssertionError(self.err_msg) from exc_value\n            else:\n                return False  # will re-raise the original exception\n    \n        if self.matches is not None:\n            err_msg = self.err_msg or (\n                &amp;quot;The error message should contain one of the following &amp;quot;\n                &amp;quot;patterns:\\n{}\\nGot {}&amp;quot;.format(&amp;quot;\\n&amp;quot;.join(self.matches), str(exc_value))\n            )\n            if not any(re.search(match, str(exc_value)) for match in self.matches):\n&amp;gt;               raise AssertionError(err_msg) from exc_value\nE               AssertionError: Estimator BasePerturbationCV doesn&amp;#x27;t check for NaN and inf in fit.\n\n_          = &amp;lt;traceback object at 0x7f4cf1b70f00&amp;gt;\nerr_msg    = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t check for NaN and inf in fit.&amp;quot;\nexc_type   = &amp;lt;class &amp;#x27;sklearn.exceptions.NotFittedError&amp;#x27;&amp;gt;\nexc_value  = NotFittedError(&amp;quot;This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;)\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cfa669b40&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:1155: AssertionError\n--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dont_overwrite_parameters1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dont_overwrite_parameters1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dont_overwrite_parameters1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_fit_returns_self1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_fit_returns_self1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_fit_returns_self1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_valid_tag_types0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_valid_tag_types0]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_valid_tag_types0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_pipeline_consistency1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_pipeline_consistency1]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_pipeline_consistency1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_predict1d0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_predict1d0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_predict1d0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_score_takes_y0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_score_takes_y0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_score_takes_y0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_dtype_object]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_dtype_object]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_dtype_object]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_dtype_object at 0x7f4cfd879a20&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_dtype_object at 0x7f4cfd879a20&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_dtype_object at 0x7f4cfd879990&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1635: in check_dtype_object\n    estimator.fit(X, y)\n        X          = array([[0.5488135039273248, 0.7151893663724195, 0.6027633760716439,\n        0.5448831829968969, 0.4236547993389047, 0....4736,\n        0.3553688484719296, 0.3567068904025429, 0.01632850268370789,\n        0.18523232523618394]], dtype=object)\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CF1B3A240\n        tags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        y          = array([2, 3, 3, 1, 1, 2, 0, 3, 1, 1, 2, 1, 2, 2, 3, 0, 2, 2, 0, 1, 1, 3,\n       2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[0.5488135039273248, 0.7151893663724195, 0.6027633760716439,\n        0.5448831829968969, 0.4236547993389047, 0....4736,\n        0.3553688484719296, 0.3567068904025429, 0.01632850268370789,\n        0.18523232523618394]], dtype=object)\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([2, 3, 3, 1, 1, 2, 0, 3, 1, 1, 2, 1, 2, 2, 3, 0, 2, 2, 0, 1, 1, 3,\n       2, 1, 3, 1, 0, 3, 1, 1, 3, 3, 1, 0, 1, 2, 0, 2, 3, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_overwrite_params0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_overwrite_params0]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_overwrite_params0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_empty_data_messages0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_empty_data_messages0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_empty_data_messages0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_dtypes1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_dtypes1]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_dtypes1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_set_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_set_params]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_set_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_predict1d1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_predict1d1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_predict1d1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_score_takes_y1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_score_takes_y1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit_score_takes_y1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_fit_returns_self0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_fit_returns_self0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_fit_returns_self0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_pipeline_consistency0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_pipeline_consistency0]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_pipeline_consistency0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_valid_tag_types1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_valid_tag_types1]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_valid_tag_types1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_dict_unchanged]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_dict_unchanged]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_dict_unchanged]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_dict_unchanged at 0x7f4cfd879bd0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_dict_unchanged at 0x7f4cfd879bd0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_dict_unchanged at 0x7f4cfd879b40&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1692: in check_dict_unchanged\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1B39A40\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf80b6260&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf80b7450&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       ...2663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]]), array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf80b6260&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\ny_train = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1220.16it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_dont_overwrite_parameters]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_dont_overwrite_parameters]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_dont_overwrite_parameters]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_dont_overwrite_parameters at 0x7f4cfd879d80&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_dont_overwrite_parameters at 0x7f4cfd879d80&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_dont_overwrite_parameters at 0x7f4cfd879cf0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1726: in check_dont_overwrite_parameters\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        dict_before_fit = {&amp;#x27;cv&amp;#x27;: KFold(n_splits=2, random_state=None, shuffle=False), &amp;#x27;estimators&amp;#x27;: [LinearRegression(), LinearRegression()], &amp;#x27;n_jobs&amp;#x27;: 1, &amp;#x27;statistical_test&amp;#x27;: &amp;#x27;nb-ttest&amp;#x27;}\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1B39F40\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_pickle(readonly_memmap=True)]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_pickle(readonly_memmap=True)]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_pickle(readonly_memmap=True)]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_pickle at 0x7f4cfd87b370&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;, readonly_memmap=True)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_pickle at 0x7f4cfd87b370&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;, readonly_memmap=True)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_pickle at 0x7f4cfd87b2e0&amp;gt;\n        kwargs     = {&amp;#x27;readonly_memmap&amp;#x27;: True}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2415: in check_estimators_pickle\n    estimator.fit(X, y)\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        check_methods = [&amp;#x27;predict&amp;#x27;, &amp;#x27;transform&amp;#x27;, &amp;#x27;decision_function&amp;#x27;, &amp;#x27;predict_proba&amp;#x27;]\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        readonly_memmap = True\n        tags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1fb9b60&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf1fba1f0&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n ...,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]]), array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1fb9b60&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n       [ 0.17640523,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\ny_train = array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n       [ 0.17640523,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1057.03it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_empty_data_messages1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_empty_data_messages1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_empty_data_messages1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_do_not_raise_errors_in_init_or_set_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_do_not_raise_errors_in_init_or_set_params]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_do_not_raise_errors_in_init_or_set_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_importance&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_importance&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_importance&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_overwrite_params1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_overwrite_params1]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_overwrite_params1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_dtypes0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_dtypes0]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_dtypes0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_no_implemented_methods&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_no_implemented_methods&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_no_implemented_methods&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_get_params_invariance1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_get_params_invariance1]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_get_params_invariance1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_no_attributes_set_in_init0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_no_attributes_set_in_init0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_no_attributes_set_in_init0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_parameters_default_constructible]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_parameters_default_constructible]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_parameters_default_constructible]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_do_not_raise_errors_in_init_or_set_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_do_not_raise_errors_in_init_or_set_params]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_do_not_raise_errors_in_init_or_set_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_methods_subset_invariance0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_methods_subset_invariance0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_methods_subset_invariance0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dict_unchanged1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dict_unchanged1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dict_unchanged1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dont_overwrite_parameters0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dont_overwrite_parameters0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_dont_overwrite_parameters0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_n_features_in_after_fitting1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_n_features_in_after_fitting1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_n_features_in_after_fitting1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_pickle1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_pickle1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_pickle1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_methods_sample_order_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_methods_sample_order_invariance]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_methods_sample_order_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_methods_sample_order_invariance at 0x7f4cfd87a170&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_methods_sample_order_invariance at 0x7f4cfd87a170&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_methods_sample_order_invariance at 0x7f4cfd87a0e0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1862: in check_methods_sample_order_invariance\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1B3A240\n        tags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit1d]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_array1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_array1]&#34;, &#34;duration&#34;: &#34;19 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_array1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;19 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_set_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_set_params]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_set_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_sparse_tag]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_sparse_tag]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_sparse_tag]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\n    def check_estimator_sparse_tag(name, estimator_orig):\n        &amp;quot;&amp;quot;&amp;quot;Check that estimator tag related with accepting sparse data is properly set.&amp;quot;&amp;quot;&amp;quot;\n        estimator = clone(estimator_orig)\n    \n        rng = np.random.RandomState(0)\n        n_samples = 15 if name == &amp;quot;SpectralCoclustering&amp;quot; else 40\n        X = rng.uniform(size=(n_samples, 3))\n        X[X &amp;lt; 0.6] = 0\n        y = rng.randint(0, 3, size=n_samples)\n        X = _enforce_estimator_tags_X(estimator, X)\n        y = _enforce_estimator_tags_y(estimator, y)\n        X = sparse.csr_array(X)\n    \n        tags = get_tags(estimator)\n        if tags.input_tags.sparse:\n            try:\n                estimator.fit(X, y)  # should pass\n            except Exception as e:\n                err_msg = (\n                    f&amp;quot;Estimator {name} raised an exception. &amp;quot;\n                    f&amp;quot;The tag self.input_tags.sparse={tags.input_tags.sparse} &amp;quot;\n                    &amp;quot;might not be consistent with the estimator&amp;#x27;s ability to &amp;quot;\n                    &amp;quot;handle sparse data (i.e. controlled by the parameter `accept_sparse`&amp;quot;\n                    &amp;quot; in `validate_data` or `check_array` functions).&amp;quot;\n                )\n                raise AssertionError(err_msg) from e\n        else:\n            err_msg = (\n                f&amp;quot;Estimator {name} raised an exception. &amp;quot;\n                &amp;quot;The estimator failed when fitted on sparse data in accordance &amp;quot;\n                f&amp;quot;with its tag self.input_tags.sparse={tags.input_tags.sparse} &amp;quot;\n                &amp;quot;but didn&amp;#x27;t raise the appropriate error: error message should &amp;quot;\n                &amp;quot;state explicitly that sparse input is not supported if this is &amp;quot;\n                &amp;quot;not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\n            )\n            try:\n&amp;gt;               estimator.fit(X, y)  # should fail with appropriate error\n\nX          = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\nerr_msg    = &amp;#x27;Estimator BasePerturbationCV raised an exception. The estimator failed when fitted on sparse data in accordance with ...licitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;#x27;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nn_samples  = 40\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CF1B39A40\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([0, 1, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 2, 0, 2, 2, 1, 1,\n       1, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 2, 1, 1, 0, 0, 0, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1276: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([0, 1, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 2, 0, 2, 2, 1, 1,\n       1, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 2, 1, 1, 0, 0, 0, 2])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf19614d0&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf1963450&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 22 stored elements and shape (20, 3)&amp;gt;, array([1, 1, 1, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 2, 1, 1, 0, 0, 0, 2]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf19614d0&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 22 stored elements and shape (20, 3)&amp;gt;\ny_train = array([1, 1, 1, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 2, 1, 1, 0, 0, 0, 2])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 22 stored elements and shape (20, 3)&amp;gt;\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 1, 1, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 2, 1, 1, 0, 0, 0, 2])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimator_sparse_tag at 0x7f4cfd878f70&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimator_sparse_tag at 0x7f4cfd878f70&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\n    def check_estimator_sparse_tag(name, estimator_orig):\n        &amp;quot;&amp;quot;&amp;quot;Check that estimator tag related with accepting sparse data is properly set.&amp;quot;&amp;quot;&amp;quot;\n        estimator = clone(estimator_orig)\n    \n        rng = np.random.RandomState(0)\n        n_samples = 15 if name == &amp;quot;SpectralCoclustering&amp;quot; else 40\n        X = rng.uniform(size=(n_samples, 3))\n        X[X &amp;lt; 0.6] = 0\n        y = rng.randint(0, 3, size=n_samples)\n        X = _enforce_estimator_tags_X(estimator, X)\n        y = _enforce_estimator_tags_y(estimator, y)\n        X = sparse.csr_array(X)\n    \n        tags = get_tags(estimator)\n        if tags.input_tags.sparse:\n            try:\n                estimator.fit(X, y)  # should pass\n            except Exception as e:\n                err_msg = (\n                    f&amp;quot;Estimator {name} raised an exception. &amp;quot;\n                    f&amp;quot;The tag self.input_tags.sparse={tags.input_tags.sparse} &amp;quot;\n                    &amp;quot;might not be consistent with the estimator&amp;#x27;s ability to &amp;quot;\n                    &amp;quot;handle sparse data (i.e. controlled by the parameter `accept_sparse`&amp;quot;\n                    &amp;quot; in `validate_data` or `check_array` functions).&amp;quot;\n                )\n                raise AssertionError(err_msg) from e\n        else:\n            err_msg = (\n                f&amp;quot;Estimator {name} raised an exception. &amp;quot;\n                &amp;quot;The estimator failed when fitted on sparse data in accordance &amp;quot;\n                f&amp;quot;with its tag self.input_tags.sparse={tags.input_tags.sparse} &amp;quot;\n                &amp;quot;but didn&amp;#x27;t raise the appropriate error: error message should &amp;quot;\n                &amp;quot;state explicitly that sparse input is not supported if this is &amp;quot;\n                &amp;quot;not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\n            )\n            try:\n                estimator.fit(X, y)  # should fail with appropriate error\n            except (ValueError, TypeError) as e:\n                if re.search(&amp;quot;[Ss]parse&amp;quot;, str(e)):\n                    # Got the right error type and mentioning sparse issue\n                    return\n                raise AssertionError(err_msg) from e\n            except Exception as e:\n&amp;gt;               raise AssertionError(err_msg) from e\nE               AssertionError: Estimator BasePerturbationCV raised an exception. The estimator failed when fitted on sparse data in accordance with its tag self.input_tags.sparse=False but didn&amp;#x27;t raise the appropriate error: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).\n\nX          = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\nerr_msg    = &amp;#x27;Estimator BasePerturbationCV raised an exception. The estimator failed when fitted on sparse data in accordance with ...licitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;#x27;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nn_samples  = 40\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CF1B39A40\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([0, 1, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 2, 0, 2, 2, 1, 1,\n       1, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 2, 1, 1, 0, 0, 0, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1283: AssertionError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 685.85it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit2d_1sample]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit2d_1sample]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit2d_1sample]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit_idempotent]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit_idempotent]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit_idempotent]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_fit_idempotent at 0x7f4cfd8864d0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_idempotent at 0x7f4cfd8864d0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4293: in check_fit_idempotent\n    estimator.fit(X_train, y_train)\n        X          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\n        X_test     = array([[ 98.77456448, 100.84436298],\n       [101.86755896, 100.90604466],\n       [100.8644362 ,  99.25783498],\n       ...20353],\n       [100.61407937, 100.92220667],\n       [ 98.92924738, 101.05445173],\n       [100.01050002, 101.78587049]])\n        X_train    = array([[ 99.30543214,  99.85036546],\n       [ 98.82687659, 101.94362119],\n       [ 99.260437  , 101.5430146 ],\n       ...07516],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [ 98.68409259,  99.5384154 ]])\n        check_methods = [&amp;#x27;predict&amp;#x27;, &amp;#x27;transform&amp;#x27;, &amp;#x27;decision_function&amp;#x27;, &amp;#x27;predict_proba&amp;#x27;]\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        n_samples  = 100\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CF1B3AE40\n        test       = array([82, 55, 11, 63, 90, 92, 47, 99, 18, 65, 64, 88, 61, 75, 54, 31, 16,\n       59, 44, 48])\n        train      = array([62, 52, 94, 89, 22, 57,  9, 84, 87, 50, 45, 66, 13, 42, 15, 20,  2,\n       35, 17, 27, 29,  4, 41, 76, 85, 49, ... 7, 81, 86, 53, 73, 51, 26, 68, 28, 33, 60, 40, 95,  6, 69, 36,\n       93, 24, 39,  0,  1, 58, 12,  3, 43, 97, 98, 74])\n        y          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\n        y_test     = array([0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1])\n        y_train    = array([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,...    1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[ 99.30543214,  99.85036546],\n       [ 98.82687659, 101.94362119],\n       [ 99.260437  , 101.5430146 ],\n       ...07516],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [ 98.68409259,  99.5384154 ]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,...    1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1961b60&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf1960350&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[ 99.96071718,  98.8319065 ],\n       [101.49407907,  99.79484174],\n       [ 99.50196755, 1...0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1961b60&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 99.96071718,  98.8319065 ],\n       [101.49407907,  99.79484174],\n       [ 99.50196755, 101.92953205],\n       ...07516],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [ 98.68409259,  99.5384154 ]])\ny_train = array([1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 99.96071718,  98.8319065 ],\n       [101.49407907,  99.79484174],\n       [ 99.50196755, 101.92953205],\n       ...07516],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [ 98.68409259,  99.5384154 ]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1097.70it/s]\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_repr0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_repr0]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_repr0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_nan_inf1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_nan_inf1]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_nan_inf1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_complex_data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_complex_data]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_complex_data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_methods_sample_order_invariance1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_methods_sample_order_invariance1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_methods_sample_order_invariance1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_pipeline_consistency]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_pipeline_consistency]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_pipeline_consistency]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_pipeline_consistency at 0x7f4cfd87ab00&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_pipeline_consistency at 0x7f4cfd87ab00&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_pipeline_consistency at 0x7f4cfd87aa70&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2156: in check_pipeline_consistency\n    estimator.fit(X, y)\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        pipeline   = Pipeline(steps=[(&amp;#x27;baseperturbationcv&amp;#x27;,\n                 BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shu...                estimators=[LinearRegression(),\n                                                LinearRegression()]))])\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_repr1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_repr1]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_repr1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_methods_sample_order_invariance0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_methods_sample_order_invariance0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_methods_sample_order_invariance0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_nan_inf0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_nan_inf0]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_nan_inf0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_n_features_in_after_fitting0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_n_features_in_after_fitting0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_n_features_in_after_fitting0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_pickle0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_pickle0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimators_pickle0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_array0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_array0]&#34;, &#34;duration&#34;: &#34;18 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_array0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;18 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_parameters_default_constructible]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_parameters_default_constructible]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_parameters_default_constructible]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_tags_renamed]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_tags_renamed]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_tags_renamed]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_positive_only_tag_during_fit]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_positive_only_tag_during_fit]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_positive_only_tag_during_fit]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\n    @ignore_warnings(category=FutureWarning)\n    def check_positive_only_tag_during_fit(name, estimator_orig):\n        &amp;quot;&amp;quot;&amp;quot;Test that the estimator correctly sets the tags.input_tags.positive_only\n    \n        If the tag is False, the estimator should accept negative input regardless of the\n        tags.input_tags.pairwise flag.\n        &amp;quot;&amp;quot;&amp;quot;\n        estimator = clone(estimator_orig)\n        tags = get_tags(estimator)\n    \n        X, y = load_iris(return_X_y=True)\n        y = _enforce_estimator_tags_y(estimator, y)\n        set_random_state(estimator, 0)\n        X = _enforce_estimator_tags_X(estimator, X)\n        # Make sure that the dtype of X stays unchanged: for instance estimator\n        # that expect categorical inputs typically expected integer-based encoded\n        # categories.\n        X -= X.mean().astype(X.dtype)\n    \n        if tags.input_tags.positive_only:\n            with raises(ValueError, match=&amp;quot;Negative values in data&amp;quot;):\n                estimator.fit(X, y)\n        else:\n            # This should pass\n            try:\n&amp;gt;               estimator.fit(X, y)\n\nX          = array([[ 1.6355,  0.0355, -2.0645, -3.2645],\n       [ 1.4355, -0.4645, -2.0645, -3.2645],\n       [ 1.2355, -0.2645, -2... -0.4645,  1.7355, -1.4645],\n       [ 2.7355, -0.0645,  1.9355, -1.1645],\n       [ 2.4355, -0.4645,  1.6355, -1.6645]])\nerr_msg    = &amp;quot;Estimator &amp;#x27;BasePerturbationCV&amp;#x27; raised NotImplementedError unexpectedly. This happens when passing negative input valu...ues are not supported for this estimator instance, then the tags.input_tags.positive_only tag needs to be set to True.&amp;quot;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4011: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[ 1.6355,  0.0355, -2.0645, -3.2645],\n       [ 1.4355, -0.4645, -2.0645, -3.2645],\n       [ 1.2355, -0.2645, -2... -0.4645,  1.7355, -1.4645],\n       [ 2.7355, -0.0645,  1.9355, -1.1645],\n       [ 2.4355, -0.4645,  1.6355, -1.6645]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1fb99a0&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf1fbb0d0&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[ 3.1355, -0.4645,  0.9355, -2.0645],\n       [ 3.3355, -0.6645,  1.3355, -2.0645],\n       ..., 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1fb99a0&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 3.1355, -0.4645,  0.9355, -2.0645],\n       [ 3.3355, -0.6645,  1.3355, -2.0645],\n       [ 3.2355, -0.4645,  1... -0.4645,  1.7355, -1.4645],\n       [ 2.7355, -0.0645,  1.9355, -1.1645],\n       [ 2.4355, -0.4645,  1.6355, -1.6645]])\ny_train = array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,...2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 3.1355, -0.4645,  0.9355, -2.0645],\n       [ 3.3355, -0.6645,  1.3355, -2.0645],\n       [ 3.2355, -0.4645,  1... -0.4645,  1.7355, -1.4645],\n       [ 2.7355, -0.0645,  1.9355, -1.1645],\n       [ 2.4355, -0.4645,  1.6355, -1.6645]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,...2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_positive_only_tag_during_fit at 0x7f4cfd885c60&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_positive_only_tag_during_fit at 0x7f4cfd885c60&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_positive_only_tag_during_fit at 0x7f4cfd885bd0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\n    @ignore_warnings(category=FutureWarning)\n    def check_positive_only_tag_during_fit(name, estimator_orig):\n        &amp;quot;&amp;quot;&amp;quot;Test that the estimator correctly sets the tags.input_tags.positive_only\n    \n        If the tag is False, the estimator should accept negative input regardless of the\n        tags.input_tags.pairwise flag.\n        &amp;quot;&amp;quot;&amp;quot;\n        estimator = clone(estimator_orig)\n        tags = get_tags(estimator)\n    \n        X, y = load_iris(return_X_y=True)\n        y = _enforce_estimator_tags_y(estimator, y)\n        set_random_state(estimator, 0)\n        X = _enforce_estimator_tags_X(estimator, X)\n        # Make sure that the dtype of X stays unchanged: for instance estimator\n        # that expect categorical inputs typically expected integer-based encoded\n        # categories.\n        X -= X.mean().astype(X.dtype)\n    \n        if tags.input_tags.positive_only:\n            with raises(ValueError, match=&amp;quot;Negative values in data&amp;quot;):\n                estimator.fit(X, y)\n        else:\n            # This should pass\n            try:\n                estimator.fit(X, y)\n            except Exception as e:\n                err_msg = (\n                    f&amp;quot;Estimator {name!r} raised {e.__class__.__name__} unexpectedly.&amp;quot;\n                    &amp;quot; This happens when passing negative input values as X.&amp;quot;\n                    &amp;quot; If negative values are not supported for this estimator instance,&amp;quot;\n                    &amp;quot; then the tags.input_tags.positive_only tag needs to be set to True.&amp;quot;\n                )\n&amp;gt;               raise AssertionError(err_msg) from e\nE               AssertionError: Estimator &amp;#x27;BasePerturbationCV&amp;#x27; raised NotImplementedError unexpectedly. This happens when passing negative input values as X. If negative values are not supported for this estimator instance, then the tags.input_tags.positive_only tag needs to be set to True.\n\nX          = array([[ 1.6355,  0.0355, -2.0645, -3.2645],\n       [ 1.4355, -0.4645, -2.0645, -3.2645],\n       [ 1.2355, -0.2645, -2... -0.4645,  1.7355, -1.4645],\n       [ 2.7355, -0.0645,  1.9355, -1.1645],\n       [ 2.4355, -0.4645,  1.6355, -1.6645]])\nerr_msg    = &amp;quot;Estimator &amp;#x27;BasePerturbationCV&amp;#x27; raised NotImplementedError unexpectedly. This happens when passing negative input valu...ues are not supported for this estimator instance, then the tags.input_tags.positive_only tag needs to be set to True.&amp;quot;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4019: AssertionError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1181.16it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit2d_predict1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit2d_predict1d]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit2d_predict1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_fit2d_predict1d at 0x7f4cfd879ea0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit2d_predict1d at 0x7f4cfd879ea0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_fit2d_predict1d at 0x7f4cfd879e10&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1779: in check_fit2d_predict1d\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1B3AE40\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_complex_data0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_complex_data0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_complex_data0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_set_params1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_set_params1]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_set_params1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_tag0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_tag0]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_tag0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbation(estimator=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimator_sparse_tag at 0x7f4cfd878f70&amp;gt;, &amp;#x27;BasePerturbation&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimator_sparse_tag at 0x7f4cfd878f70&amp;gt;, &amp;#x27;BasePerturbation&amp;#x27;)\nestimator  = BasePerturbation(estimator=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;BasePerturbation&amp;#x27;\nestimator_orig = BasePerturbation(estimator=LinearRegression())\n\n    def check_estimator_sparse_tag(name, estimator_orig):\n        &amp;quot;&amp;quot;&amp;quot;Check that estimator tag related with accepting sparse data is properly set.&amp;quot;&amp;quot;&amp;quot;\n        estimator = clone(estimator_orig)\n    \n        rng = np.random.RandomState(0)\n        n_samples = 15 if name == &amp;quot;SpectralCoclustering&amp;quot; else 40\n        X = rng.uniform(size=(n_samples, 3))\n        X[X &amp;lt; 0.6] = 0\n        y = rng.randint(0, 3, size=n_samples)\n        X = _enforce_estimator_tags_X(estimator, X)\n        y = _enforce_estimator_tags_y(estimator, y)\n        X = sparse.csr_array(X)\n    \n        tags = get_tags(estimator)\n        if tags.input_tags.sparse:\n            try:\n                estimator.fit(X, y)  # should pass\n            except Exception as e:\n                err_msg = (\n                    f&amp;quot;Estimator {name} raised an exception. &amp;quot;\n                    f&amp;quot;The tag self.input_tags.sparse={tags.input_tags.sparse} &amp;quot;\n                    &amp;quot;might not be consistent with the estimator&amp;#x27;s ability to &amp;quot;\n                    &amp;quot;handle sparse data (i.e. controlled by the parameter `accept_sparse`&amp;quot;\n                    &amp;quot; in `validate_data` or `check_array` functions).&amp;quot;\n                )\n                raise AssertionError(err_msg) from e\n        else:\n            err_msg = (\n                f&amp;quot;Estimator {name} raised an exception. &amp;quot;\n                &amp;quot;The estimator failed when fitted on sparse data in accordance &amp;quot;\n                f&amp;quot;with its tag self.input_tags.sparse={tags.input_tags.sparse} &amp;quot;\n                &amp;quot;but didn&amp;#x27;t raise the appropriate error: error message should &amp;quot;\n                &amp;quot;state explicitly that sparse input is not supported if this is &amp;quot;\n                &amp;quot;not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\n            )\n            try:\n                estimator.fit(X, y)  # should fail with appropriate error\n            except (ValueError, TypeError) as e:\n                if re.search(&amp;quot;[Ss]parse&amp;quot;, str(e)):\n                    # Got the right error type and mentioning sparse issue\n                    return\n                raise AssertionError(err_msg) from e\n            except Exception as e:\n                raise AssertionError(err_msg) from e\n&amp;gt;           raise AssertionError(\n                f&amp;quot;Estimator {name} didn&amp;#x27;t fail when fitted on sparse data &amp;quot;\n                &amp;quot;but should have according to its tag &amp;quot;\n                f&amp;quot;self.input_tags.sparse={tags.input_tags.sparse}. &amp;quot;\n                f&amp;quot;The tag is inconsistent and must be fixed.&amp;quot;\n            )\nE           AssertionError: Estimator BasePerturbation didn&amp;#x27;t fail when fitted on sparse data but should have according to its tag self.input_tags.sparse=False. The tag is inconsistent and must be fixed.\n\nX          = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\nerr_msg    = &amp;#x27;Estimator BasePerturbation raised an exception. The estimator failed when fitted on sparse data in accordance with it...licitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;#x27;\nestimator  = BasePerturbation(estimator=LinearRegression())\nestimator_orig = BasePerturbation(estimator=LinearRegression())\nn_samples  = 40\nname       = &amp;#x27;BasePerturbation&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CF1B3B940\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([0, 1, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 2, 0, 2, 2, 1, 1,\n       1, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 2, 1, 1, 0, 0, 0, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1284: AssertionError\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_unfitted]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_unfitted]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_unfitted]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_no_attributes_set_in_init]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_no_attributes_set_in_init]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_no_attributes_set_in_init]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit_idempotent]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit_idempotent]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit_idempotent]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_fit_idempotent at 0x7f4cfd8864d0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_idempotent at 0x7f4cfd8864d0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4293: in check_fit_idempotent\n    estimator.fit(X_train, y_train)\n        X          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\n        X_test     = array([[ 98.77456448, 100.84436298],\n       [101.86755896, 100.90604466],\n       [100.8644362 ,  99.25783498],\n       ...20353],\n       [100.61407937, 100.92220667],\n       [ 98.92924738, 101.05445173],\n       [100.01050002, 101.78587049]])\n        X_train    = array([[ 99.30543214,  99.85036546],\n       [ 98.82687659, 101.94362119],\n       [ 99.260437  , 101.5430146 ],\n       ...07516],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [ 98.68409259,  99.5384154 ]])\n        check_methods = [&amp;#x27;predict&amp;#x27;, &amp;#x27;transform&amp;#x27;, &amp;#x27;decision_function&amp;#x27;, &amp;#x27;predict_proba&amp;#x27;]\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        n_samples  = 100\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CF1B3B840\n        test       = array([82, 55, 11, 63, 90, 92, 47, 99, 18, 65, 64, 88, 61, 75, 54, 31, 16,\n       59, 44, 48])\n        train      = array([62, 52, 94, 89, 22, 57,  9, 84, 87, 50, 45, 66, 13, 42, 15, 20,  2,\n       35, 17, 27, 29,  4, 41, 76, 85, 49, ... 7, 81, 86, 53, 73, 51, 26, 68, 28, 33, 60, 40, 95,  6, 69, 36,\n       93, 24, 39,  0,  1, 58, 12,  3, 43, 97, 98, 74])\n        y          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\n        y_test     = array([0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1])\n        y_train    = array([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,...    1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[ 99.30543214,  99.85036546],\n       [ 98.82687659, 101.94362119],\n       [ 99.260437  , 101.5430146 ],\n       ...07516],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [ 98.68409259,  99.5384154 ]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,...    1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_tags_renamed]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_tags_renamed]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimator_tags_renamed]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_mixin_order0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_mixin_order0]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_mixin_order0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_dtypes]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_dtypes]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimators_dtypes]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_estimators_dtypes at 0x7f4cfd87ae60&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_dtypes at 0x7f4cfd87ae60&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_estimators_dtypes at 0x7f4cfd87add0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2257: in check_estimators_dtypes\n    estimator.fit(X_train, y)\n        X_train    = array([[1.6464405 , 2.145568  , 1.80829   , 1.6346495 , 1.2709644 ],\n       [1.9376824 , 1.3127615 , 2.675319  , 2.890...6 , 2.1489816 , 0.8682183 ],\n       [0.5495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32)\n        X_train_32 = array([[1.6464405 , 2.145568  , 1.80829   , 1.6346495 , 1.2709644 ],\n       [1.9376824 , 1.3127615 , 2.675319  , 2.890...6 , 2.1489816 , 0.8682183 ],\n       [0.5495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32)\n        X_train_64 = array([[1.64644051, 2.14556789, 1.80829   , 1.63464952, 1.27096438],\n       [1.93768239, 1.31276155, 2.67531896, 2.890... 2.00223112, 0.39539361, 2.14898157, 0.8682183 ],\n       [0.54957408, 1.75953877, 0.06032264, 2.48682022, 0.01408643]])\n        X_train_int_32 = array([[1, 2, 1, 1, 1],\n       [1, 1, 2, 2, 1],\n       [2, 1, 1, 2, 0],\n       [0, 0, 2, 2, 2],\n       [2, 2, 1, 2, 0]...0, 0, 0],\n       [0, 1, 0, 2, 1],\n       [0, 1, 0, 1, 2],\n       [0, 2, 0, 2, 0],\n       [0, 1, 0, 2, 0]], dtype=int32)\n        X_train_int_64 = array([[1, 2, 1, 1, 1],\n       [1, 1, 2, 2, 1],\n       [2, 1, 1, 2, 0],\n       [0, 0, 2, 2, 2],\n       [2, 2, 1, 2, 0]...      [0, 0, 0, 0, 0],\n       [0, 1, 0, 2, 1],\n       [0, 1, 0, 1, 2],\n       [0, 2, 0, 2, 0],\n       [0, 1, 0, 2, 0]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        methods    = [&amp;#x27;predict&amp;#x27;, &amp;#x27;transform&amp;#x27;, &amp;#x27;decision_function&amp;#x27;, &amp;#x27;predict_proba&amp;#x27;]\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1B3BC40\n        y          = array([1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[1.6464405 , 2.145568  , 1.80829   , 1.6346495 , 1.2709644 ],\n       [1.9376824 , 1.3127615 , 2.675319  , 2.890...6 , 2.1489816 , 0.8682183 ],\n       [0.5495741 , 1.7595388 , 0.06032264, 2.4868202 , 0.01408643]],\n      dtype=float32)\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_mixin_order1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_mixin_order1]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_mixin_order1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_methods_subset_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_methods_subset_invariance]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_methods_subset_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_methods_subset_invariance at 0x7f4cfd87a050&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_methods_subset_invariance at 0x7f4cfd87a050&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_methods_subset_invariance at 0x7f4cfd879fc0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1822: in check_methods_subset_invariance\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1B3BD40\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf18d7530&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf18d7300&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       ...2663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]]), array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf18d7530&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\ny_train = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 992.62it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_pickle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_pickle]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_estimators_pickle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimators_pickle at 0x7f4cfd87b370&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_pickle at 0x7f4cfd87b370&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_estimators_pickle at 0x7f4cfd87b2e0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2415: in check_estimators_pickle\n    estimator.fit(X, y)\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        check_methods = [&amp;#x27;predict&amp;#x27;, &amp;#x27;transform&amp;#x27;, &amp;#x27;decision_function&amp;#x27;, &amp;#x27;predict_proba&amp;#x27;]\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        readonly_memmap = False\n        tags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[ 1.00519454,  1.07290906,  1.01289829],\n       [ 0.12302907,  0.12023798, -0.03873268],\n       [ 0.04105985,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 1, 1, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf18d6490&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf18d6650&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n ...,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]]), array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf18d6490&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n       [ 0.17640523,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\ny_train = array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 0.96884475,  1.00561653,  0.88348502],\n       [ 0.07610377,  0.0121675 ,  0.04438632],\n       [ 0.17640523,  ...9292474,  1.10544517],\n       [ 0.93151899,  0.91292029,  0.94211503],\n       [-0.03023028, -0.1048553 , -0.14200179]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1035.76it/s]\n\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\u001b[A--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_positive_only_tag_during_fit]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_positive_only_tag_during_fit]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_positive_only_tag_during_fit]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\n    @ignore_warnings(category=FutureWarning)\n    def check_positive_only_tag_during_fit(name, estimator_orig):\n        &amp;quot;&amp;quot;&amp;quot;Test that the estimator correctly sets the tags.input_tags.positive_only\n    \n        If the tag is False, the estimator should accept negative input regardless of the\n        tags.input_tags.pairwise flag.\n        &amp;quot;&amp;quot;&amp;quot;\n        estimator = clone(estimator_orig)\n        tags = get_tags(estimator)\n    \n        X, y = load_iris(return_X_y=True)\n        y = _enforce_estimator_tags_y(estimator, y)\n        set_random_state(estimator, 0)\n        X = _enforce_estimator_tags_X(estimator, X)\n        # Make sure that the dtype of X stays unchanged: for instance estimator\n        # that expect categorical inputs typically expected integer-based encoded\n        # categories.\n        X -= X.mean().astype(X.dtype)\n    \n        if tags.input_tags.positive_only:\n            with raises(ValueError, match=&amp;quot;Negative values in data&amp;quot;):\n                estimator.fit(X, y)\n        else:\n            # This should pass\n            try:\n&amp;gt;               estimator.fit(X, y)\n\nX          = array([[ 1.6355,  0.0355, -2.0645, -3.2645],\n       [ 1.4355, -0.4645, -2.0645, -3.2645],\n       [ 1.2355, -0.2645, -2... -0.4645,  1.7355, -1.4645],\n       [ 2.7355, -0.0645,  1.9355, -1.1645],\n       [ 2.4355, -0.4645,  1.6355, -1.6645]])\nerr_msg    = &amp;quot;Estimator &amp;#x27;BasePerturbationCV&amp;#x27; raised NotFittedError unexpectedly. This happens when passing negative input values as...ues are not supported for this estimator instance, then the tags.input_tags.positive_only tag needs to be set to True.&amp;quot;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4011: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[ 1.6355,  0.0355, -2.0645, -3.2645],\n       [ 1.4355, -0.4645, -2.0645, -3.2645],\n       [ 1.2355, -0.2645, -2... -0.4645,  1.7355, -1.4645],\n       [ 2.7355, -0.0645,  1.9355, -1.1645],\n       [ 2.4355, -0.4645,  1.6355, -1.6645]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_positive_only_tag_during_fit at 0x7f4cfd885c60&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_positive_only_tag_during_fit at 0x7f4cfd885c60&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_positive_only_tag_during_fit at 0x7f4cfd885bd0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\n    @ignore_warnings(category=FutureWarning)\n    def check_positive_only_tag_during_fit(name, estimator_orig):\n        &amp;quot;&amp;quot;&amp;quot;Test that the estimator correctly sets the tags.input_tags.positive_only\n    \n        If the tag is False, the estimator should accept negative input regardless of the\n        tags.input_tags.pairwise flag.\n        &amp;quot;&amp;quot;&amp;quot;\n        estimator = clone(estimator_orig)\n        tags = get_tags(estimator)\n    \n        X, y = load_iris(return_X_y=True)\n        y = _enforce_estimator_tags_y(estimator, y)\n        set_random_state(estimator, 0)\n        X = _enforce_estimator_tags_X(estimator, X)\n        # Make sure that the dtype of X stays unchanged: for instance estimator\n        # that expect categorical inputs typically expected integer-based encoded\n        # categories.\n        X -= X.mean().astype(X.dtype)\n    \n        if tags.input_tags.positive_only:\n            with raises(ValueError, match=&amp;quot;Negative values in data&amp;quot;):\n                estimator.fit(X, y)\n        else:\n            # This should pass\n            try:\n                estimator.fit(X, y)\n            except Exception as e:\n                err_msg = (\n                    f&amp;quot;Estimator {name!r} raised {e.__class__.__name__} unexpectedly.&amp;quot;\n                    &amp;quot; This happens when passing negative input values as X.&amp;quot;\n                    &amp;quot; If negative values are not supported for this estimator instance,&amp;quot;\n                    &amp;quot; then the tags.input_tags.positive_only tag needs to be set to True.&amp;quot;\n                )\n&amp;gt;               raise AssertionError(err_msg) from e\nE               AssertionError: Estimator &amp;#x27;BasePerturbationCV&amp;#x27; raised NotFittedError unexpectedly. This happens when passing negative input values as X. If negative values are not supported for this estimator instance, then the tags.input_tags.positive_only tag needs to be set to True.\n\nX          = array([[ 1.6355,  0.0355, -2.0645, -3.2645],\n       [ 1.4355, -0.4645, -2.0645, -3.2645],\n       [ 1.2355, -0.2645, -2... -0.4645,  1.7355, -1.4645],\n       [ 2.7355, -0.0645,  1.9355, -1.1645],\n       [ 2.4355, -0.4645,  1.6355, -1.6645]])\nerr_msg    = &amp;quot;Estimator &amp;#x27;BasePerturbationCV&amp;#x27; raised NotFittedError unexpectedly. This happens when passing negative input values as...ues are not supported for this estimator instance, then the tags.input_tags.positive_only tag needs to be set to True.&amp;quot;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4019: AssertionError\n--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_complex_data1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_complex_data1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_complex_data1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_set_params0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_set_params0]&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_set_params0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_tag1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_tag1]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_estimator_sparse_tag1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbation(estimator=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_estimator_sparse_tag at 0x7f4cfd878f70&amp;gt;, &amp;#x27;BasePerturbation&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimator_sparse_tag at 0x7f4cfd878f70&amp;gt;, &amp;#x27;BasePerturbation&amp;#x27;)\nestimator  = BasePerturbation(estimator=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;BasePerturbation&amp;#x27;\nestimator_orig = BasePerturbation(estimator=LinearRegression())\n\n    def check_estimator_sparse_tag(name, estimator_orig):\n        &amp;quot;&amp;quot;&amp;quot;Check that estimator tag related with accepting sparse data is properly set.&amp;quot;&amp;quot;&amp;quot;\n        estimator = clone(estimator_orig)\n    \n        rng = np.random.RandomState(0)\n        n_samples = 15 if name == &amp;quot;SpectralCoclustering&amp;quot; else 40\n        X = rng.uniform(size=(n_samples, 3))\n        X[X &amp;lt; 0.6] = 0\n        y = rng.randint(0, 3, size=n_samples)\n        X = _enforce_estimator_tags_X(estimator, X)\n        y = _enforce_estimator_tags_y(estimator, y)\n        X = sparse.csr_array(X)\n    \n        tags = get_tags(estimator)\n        if tags.input_tags.sparse:\n            try:\n                estimator.fit(X, y)  # should pass\n            except Exception as e:\n                err_msg = (\n                    f&amp;quot;Estimator {name} raised an exception. &amp;quot;\n                    f&amp;quot;The tag self.input_tags.sparse={tags.input_tags.sparse} &amp;quot;\n                    &amp;quot;might not be consistent with the estimator&amp;#x27;s ability to &amp;quot;\n                    &amp;quot;handle sparse data (i.e. controlled by the parameter `accept_sparse`&amp;quot;\n                    &amp;quot; in `validate_data` or `check_array` functions).&amp;quot;\n                )\n                raise AssertionError(err_msg) from e\n        else:\n            err_msg = (\n                f&amp;quot;Estimator {name} raised an exception. &amp;quot;\n                &amp;quot;The estimator failed when fitted on sparse data in accordance &amp;quot;\n                f&amp;quot;with its tag self.input_tags.sparse={tags.input_tags.sparse} &amp;quot;\n                &amp;quot;but didn&amp;#x27;t raise the appropriate error: error message should &amp;quot;\n                &amp;quot;state explicitly that sparse input is not supported if this is &amp;quot;\n                &amp;quot;not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\n            )\n            try:\n                estimator.fit(X, y)  # should fail with appropriate error\n            except (ValueError, TypeError) as e:\n                if re.search(&amp;quot;[Ss]parse&amp;quot;, str(e)):\n                    # Got the right error type and mentioning sparse issue\n                    return\n                raise AssertionError(err_msg) from e\n            except Exception as e:\n                raise AssertionError(err_msg) from e\n&amp;gt;           raise AssertionError(\n                f&amp;quot;Estimator {name} didn&amp;#x27;t fail when fitted on sparse data &amp;quot;\n                &amp;quot;but should have according to its tag &amp;quot;\n                f&amp;quot;self.input_tags.sparse={tags.input_tags.sparse}. &amp;quot;\n                f&amp;quot;The tag is inconsistent and must be fixed.&amp;quot;\n            )\nE           AssertionError: Estimator BasePerturbation didn&amp;#x27;t fail when fitted on sparse data but should have according to its tag self.input_tags.sparse=False. The tag is inconsistent and must be fixed.\n\nX          = &amp;lt;Compressed Sparse Row sparse array of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\nerr_msg    = &amp;#x27;Estimator BasePerturbation raised an exception. The estimator failed when fitted on sparse data in accordance with it...licitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;#x27;\nestimator  = BasePerturbation(estimator=LinearRegression())\nestimator_orig = BasePerturbation(estimator=LinearRegression())\nn_samples  = 40\nname       = &amp;#x27;BasePerturbation&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CF1B3BD40\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([0, 1, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 2, 0, 2, 2, 1, 1,\n       1, 2, 0, 0, 1, 0, 2, 2, 0, 2, 2, 2, 1, 1, 0, 0, 0, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1284: AssertionError\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_1feature1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_1feature1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_1feature1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_ensemble_clustered_inference.py::test_encludl_temporal&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_ensemble_clustered_inference.py::test_encludl_temporal&#34;, &#34;duration&#34;: &#34;00:00:06&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_ensemble_clustered_inference.py::test_encludl_temporal&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:06&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.50it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.91it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.82it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.74it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.80it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.78it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1314.66it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.42it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.56it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.63it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.53it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.72it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.64it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1330.17it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  9.02it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.46it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.73it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.74it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.63it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.66it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1345.02it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.21it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.55it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.50it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.24it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.37it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.37it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1342.26it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.51it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.35it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.66it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.68it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.77it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.68it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1340.72it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  7.98it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.28it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.09it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.41it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.50it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.37it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1327.48it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  9.10it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.81it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.86it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.53it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.42it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.56it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1357.64it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.93it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.98it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.87it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.95it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.61it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.75it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1319.96it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.87it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.95it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.72it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.90it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.83it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.83it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1319.13it/s]\n\rFitting clustered inferences:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting clustered inferences:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:00,  8.91it/s]\rFitting clustered inferences:  40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&amp;lt;00:00,  8.66it/s]\rFitting clustered inferences:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&amp;lt;00:00,  8.50it/s]\rFitting clustered inferences:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00,  8.59it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.76it/s]\rFitting clustered inferences: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00,  8.69it/s]\n\rComputing importances:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importances: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1307.94it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit_check_is_fitted]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit_check_is_fitted]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit_check_is_fitted]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7f4cfd886560&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7f4cfd886560&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4353: in check_fit_check_is_fitted\n    estimator.fit(X, y)\n        X          = array([[100.49671415,  99.8617357 ],\n       [100.64768854, 101.52302986],\n       [ 99.76584663,  99.76586304],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        n_samples  = 100\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CF1E00240\n        y          = array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,...1,\n       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[100.49671415,  99.8617357 ],\n       [100.64768854, 101.52302986],\n       [ 99.76584663,  99.76586304],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,...1,\n       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf80b54d0&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf80b4c10&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[ 98.58462926,  99.57935468],\n       [ 99.65728548,  99.19772273],\n       [ 99.83871429, 1..., 1, 1, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n       0, 1, 0, 1, 0, 1]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf80b54d0&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[ 98.58462926,  99.57935468],\n       [ 99.65728548,  99.19772273],\n       [ 99.83871429, 100.40405086],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\ny_train = array([1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n       0, 1, 0, 1, 0, 1])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[ 98.58462926,  99.57935468],\n       [ 99.65728548,  99.19772273],\n       [ 99.83871429, 100.40405086],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n       0, 1, 0, 1, 0, 1])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1182.66it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_parameters_default_constructible1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_parameters_default_constructible1]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_parameters_default_constructible1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_readonly_memmap_input]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_readonly_memmap_input]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_readonly_memmap_input]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_readonly_memmap_input at 0x7f4cfd884670&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_readonly_memmap_input at 0x7f4cfd884670&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_readonly_memmap_input at 0x7f4cfd8845e0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3219: in check_readonly_memmap_input\n    assert estimator.fit(X, y) is estimator\n        X          = memmap([[ 2.21021495,  1.27582618],\n        [ 1.28933778,  3.44969159],\n        [ 2.10102604,  0.71047981],\n        [ ...08313281],\n        [-2.77969937,  3.69537262],\n        [ 1.7373078 ,  4.42546234],\n        [-0.29661333,  4.12026211]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        y          = memmap([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = memmap([[ 2.21021495,  1.27582618],\n        [ 1.28933778,  3.44969159],\n        [ 2.10102604,  0.71047981],\n        [ ...08313281],\n        [-2.77969937,  3.69537262],\n        [ 1.7373078 ,  4.42546234],\n        [-0.29661333,  4.12026211]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = memmap([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_cloneable0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_cloneable0]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_cloneable0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit2d_1sample]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit2d_1sample]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit2d_1sample]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\n    @ignore_warnings\n    def check_fit2d_1sample(name, estimator_orig):\n        # Check that fitting a 2d array with only one sample either works or\n        # returns an informative message. The error message should either mention\n        # the number of samples or the number of classes.\n        rnd = np.random.RandomState(0)\n        X = 3 * rnd.uniform(size=(1, 10))\n        X = _enforce_estimator_tags_X(estimator_orig, X)\n    \n        y = X[:, 0].astype(int)\n        estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if hasattr(estimator, &amp;quot;n_components&amp;quot;):\n            estimator.n_components = 1\n        if hasattr(estimator, &amp;quot;n_clusters&amp;quot;):\n            estimator.n_clusters = 1\n    \n        set_random_state(estimator, 1)\n    \n        # min_cluster_size cannot be less than the data size for OPTICS.\n        if name == &amp;quot;OPTICS&amp;quot;:\n            estimator.set_params(min_samples=1.0)\n    \n        # perplexity cannot be more than the number of samples for TSNE.\n        if name == &amp;quot;TSNE&amp;quot;:\n            estimator.set_params(perplexity=0.5)\n    \n        msgs = [\n            &amp;quot;1 sample&amp;quot;,\n            &amp;quot;n_samples = 1&amp;quot;,\n            &amp;quot;n_samples=1&amp;quot;,\n            &amp;quot;one sample&amp;quot;,\n            &amp;quot;1 class&amp;quot;,\n            &amp;quot;one class&amp;quot;,\n        ]\n    \n        with raises(ValueError, match=msgs, may_pass=True):\n&amp;gt;           estimator.fit(X, y)\n\nX          = array([[1.64644051, 2.1455681 , 1.80829013, 1.63464955, 1.2709644 ,\n        1.93768234, 1.31276163, 2.675319  , 2.89098828, 1.15032456]])\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nmsgs       = [&amp;#x27;1 sample&amp;#x27;, &amp;#x27;n_samples = 1&amp;#x27;, &amp;#x27;n_samples=1&amp;#x27;, &amp;#x27;one sample&amp;#x27;, &amp;#x27;1 class&amp;#x27;, &amp;#x27;one class&amp;#x27;]\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\nrnd        = RandomState(MT19937) at 0x7F4CF1E00C40\ny          = array([1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1925: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013, 1.63464955, 1.2709644 ,\n        1.93768234, 1.31276163, 2.675319  , 2.89098828, 1.15032456]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_fit2d_1sample at 0x7f4cfd87a290&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit2d_1sample at 0x7f4cfd87a290&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_fit2d_1sample at 0x7f4cfd87a200&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1924: in check_fit2d_1sample\n    with raises(ValueError, match=msgs, may_pass=True):\n        X          = array([[1.64644051, 2.1455681 , 1.80829013, 1.63464955, 1.2709644 ,\n        1.93768234, 1.31276163, 2.675319  , 2.89098828, 1.15032456]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        msgs       = [&amp;#x27;1 sample&amp;#x27;, &amp;#x27;n_samples = 1&amp;#x27;, &amp;#x27;n_samples=1&amp;#x27;, &amp;#x27;one sample&amp;#x27;, &amp;#x27;1 class&amp;#x27;, &amp;#x27;one class&amp;#x27;]\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1E00C40\n        y          = array([1])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cfb03b850&amp;gt;\nexc_type = &amp;lt;class &amp;#x27;sklearn.exceptions.NotFittedError&amp;#x27;&amp;gt;\nexc_value = NotFittedError(&amp;quot;This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;)\n_ = &amp;lt;traceback object at 0x7f4cf1731840&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f&amp;quot;Did not raise: {self.expected_exc_types}&amp;quot;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n                raise AssertionError(self.err_msg) from exc_value\n            else:\n                return False  # will re-raise the original exception\n    \n        if self.matches is not None:\n            err_msg = self.err_msg or (\n                &amp;quot;The error message should contain one of the following &amp;quot;\n                &amp;quot;patterns:\\n{}\\nGot {}&amp;quot;.format(&amp;quot;\\n&amp;quot;.join(self.matches), str(exc_value))\n            )\n            if not any(re.search(match, str(exc_value)) for match in self.matches):\n&amp;gt;               raise AssertionError(err_msg) from exc_value\nE               AssertionError: The error message should contain one of the following patterns:\nE               1 sample\nE               n_samples = 1\nE               n_samples=1\nE               one sample\nE               1 class\nE               one class\nE               Got This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\n_          = &amp;lt;traceback object at 0x7f4cf1731840&amp;gt;\nerr_msg    = &amp;quot;The error message should contain one of the following patterns:\\n1 sample\\nn_samples = 1\\nn_samples=1\\none sample\\n1 ...t This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\nexc_type   = &amp;lt;class &amp;#x27;sklearn.exceptions.NotFittedError&amp;#x27;&amp;gt;\nexc_value  = NotFittedError(&amp;quot;This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;)\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cfb03b850&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:1155: AssertionError\n--------------------------- Captured stderr teardown ---------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_1feature0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_1feature0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_fit2d_1feature0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nRunning initial fit of the estimator LinearRegression.\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_dict_unchanged]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_dict_unchanged]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_dict_unchanged]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_dict_unchanged at 0x7f4cfd879bd0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_dict_unchanged at 0x7f4cfd879bd0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_dict_unchanged at 0x7f4cfd879b40&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1692: in check_dict_unchanged\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1E00D40\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_parameters_default_constructible0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_parameters_default_constructible0]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbation(estimator=LinearRegression())-check_parameters_default_constructible0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_cloneable1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_cloneable1]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_cloneable1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_get_params_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_get_params_invariance]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_get_params_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit_score_takes_y]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit_score_takes_y]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_fit_score_takes_y]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_fit_score_takes_y at 0x7f4cfd87ad40&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_score_takes_y at 0x7f4cfd87ad40&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()]))\n        fn         = &amp;lt;function check_fit_score_takes_y at 0x7f4cfd87acb0&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:2228: in check_fit_score_takes_y\n    func(X, y)\n        X          = array([[0.5488135 , 0.71518937, 0.60276338],\n       [0.54488318, 0.4236548 , 0.64589411],\n       [0.43758721, 0.891773...99, 0.0641475 , 0.69247212],\n       [0.56660145, 0.26538949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        func       = &amp;lt;bound method BasePerturbationCV.fit of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])&amp;gt;\n        func_name  = &amp;#x27;fit&amp;#x27;\n        funcs      = [&amp;#x27;fit&amp;#x27;, &amp;#x27;score&amp;#x27;, &amp;#x27;partial_fit&amp;#x27;, &amp;#x27;fit_predict&amp;#x27;, &amp;#x27;fit_transform&amp;#x27;]\n        n_samples  = 30\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1E00740\n        y          = array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n       1, 2, 0, 1, 2, 0, 1, 2])\nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = array([[0.5488135 , 0.71518937, 0.60276338],\n       [0.54488318, 0.4236548 , 0.64589411],\n       [0.43758721, 0.891773...99, 0.0641475 , 0.69247212],\n       [0.56660145, 0.26538949, 0.52324805],\n       [0.09394051, 0.5759465 , 0.9292962 ]])\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n       1, 2, 0, 1, 2, 0, 1, 2])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_sparse_matrix]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_sparse_matrix]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=[LinearRegression(),LinearRegression()])-check_estimator_sparse_matrix]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;BasePerturbationCV&amp;#x27;\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nsparse_type = &amp;lt;class &amp;#x27;scipy.sparse._csr.csr_matrix&amp;#x27;&amp;gt;\n\n    def _check_estimator_sparse_container(name, estimator_orig, sparse_type):\n        rng = np.random.RandomState(0)\n        X = rng.uniform(size=(40, 3))\n        X[X &amp;lt; 0.6] = 0\n        X = _enforce_estimator_tags_X(estimator_orig, X)\n        y = (4 * rng.uniform(size=X.shape[0])).astype(np.int32)\n        # catch deprecation warnings\n        with ignore_warnings(category=FutureWarning):\n            estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n        tags = get_tags(estimator_orig)\n        for matrix_format, X in _generate_sparse_data(sparse_type(X)):\n            # catch deprecation warnings\n            with ignore_warnings(category=FutureWarning):\n                estimator = clone(estimator_orig)\n                if name in [&amp;quot;Scaler&amp;quot;, &amp;quot;StandardScaler&amp;quot;]:\n                    estimator.set_params(with_mean=False)\n            # fit and predict\n            if &amp;quot;64&amp;quot; in matrix_format:\n                err_msg = (\n                    f&amp;quot;Estimator {name} doesn&amp;#x27;t seem to support {matrix_format} &amp;quot;\n                    &amp;quot;matrix, and is not failing gracefully, e.g. by using &amp;quot;\n                    &amp;quot;check_array(X, accept_large_sparse=False).&amp;quot;\n                )\n            else:\n                err_msg = (\n                    f&amp;quot;Estimator {name} doesn&amp;#x27;t seem to fail gracefully on sparse &amp;quot;\n                    &amp;quot;data: error message should state explicitly that sparse &amp;quot;\n                    &amp;quot;input is not supported if this is not the case, e.g. by using &amp;quot;\n                    &amp;quot;check_array(X, accept_sparse=False).&amp;quot;\n                )\n            with raises(\n                (TypeError, ValueError),\n                match=[&amp;quot;sparse&amp;quot;, &amp;quot;Sparse&amp;quot;],\n                may_pass=True,\n                err_msg=err_msg,\n            ):\n                with ignore_warnings(category=FutureWarning):\n&amp;gt;                   estimator.fit(X, y)\n\nX          = &amp;lt;Compressed Sparse Row sparse matrix of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\nerr_msg    = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nestimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\nmatrix_format = &amp;#x27;csr&amp;#x27;\nname       = &amp;#x27;BasePerturbationCV&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CF1E01040\nsparse_type = &amp;lt;class &amp;#x27;scipy.sparse._csr.csr_matrix&amp;#x27;&amp;gt;\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0], dtype=int32)\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1330: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/base_perturbation.py:405: in fit\n    check_is_fitted(est)\n        X          = &amp;lt;Compressed Sparse Row sparse matrix of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\n        est        = LinearRegression()\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        y          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0], dtype=int32)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = LinearRegression(), attributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = LinearRegression()\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\ncheck = functools.partial(&amp;lt;function check_estimator_sparse_matrix at 0x7f4cfd879090&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimator_sparse_matrix at 0x7f4cfd879090&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1347: in check_estimator_sparse_matrix\n    _check_estimator_sparse_container(name, estimator_orig, sparse.csr_matrix)\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1323: in _check_estimator_sparse_container\n    with raises(\n        X          = &amp;lt;Compressed Sparse Row sparse matrix of dtype &amp;#x27;float64&amp;#x27;\n\twith 48 stored elements and shape (40, 3)&amp;gt;\n        err_msg    = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=[LinearRegression(), LinearRegression()])\n        matrix_format = &amp;#x27;csr&amp;#x27;\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rng        = RandomState(MT19937) at 0x7F4CF1E01040\n        sparse_type = &amp;lt;class &amp;#x27;scipy.sparse._csr.csr_matrix&amp;#x27;&amp;gt;\n        tags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        y          = array([2, 2, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 3, 1,\n       1, 3, 3, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 3, 3, 2, 1, 0], dtype=int32)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cfa66ac20&amp;gt;\nexc_type = &amp;lt;class &amp;#x27;sklearn.exceptions.NotFittedError&amp;#x27;&amp;gt;\nexc_value = NotFittedError(&amp;quot;This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;)\n_ = &amp;lt;traceback object at 0x7f4cf1986400&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f&amp;quot;Did not raise: {self.expected_exc_types}&amp;quot;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n                raise AssertionError(self.err_msg) from exc_value\n            else:\n                return False  # will re-raise the original exception\n    \n        if self.matches is not None:\n            err_msg = self.err_msg or (\n                &amp;quot;The error message should contain one of the following &amp;quot;\n                &amp;quot;patterns:\\n{}\\nGot {}&amp;quot;.format(&amp;quot;\\n&amp;quot;.join(self.matches), str(exc_value))\n            )\n            if not any(re.search(match, str(exc_value)) for match in self.matches):\n&amp;gt;               raise AssertionError(err_msg) from exc_value\nE               AssertionError: Estimator BasePerturbationCV doesn&amp;#x27;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).\n\n_          = &amp;lt;traceback object at 0x7f4cf1986400&amp;gt;\nerr_msg    = &amp;quot;Estimator BasePerturbationCV doesn&amp;#x27;t seem to fail gracefully on sparse data: error message should state explicitly that sparse input is not supported if this is not the case, e.g. by using check_array(X, accept_sparse=False).&amp;quot;\nexc_type   = &amp;lt;class &amp;#x27;sklearn.exceptions.NotFittedError&amp;#x27;&amp;gt;\nexc_value  = NotFittedError(&amp;quot;This LinearRegression instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;)\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cfa66ac20&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:1155: AssertionError\n&#34;}], &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit2d_predict1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit2d_predict1d]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_base_perturbation.py::test_check_estimator_sklearn[BasePerturbationCV(cv=KFold(n_splits=2,random_state=None,shuffle=False),estimators=LinearRegression())-check_fit2d_predict1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ncheck = functools.partial(&amp;lt;function check_fit2d_predict1d at 0x7f4cfd879ea0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit2d_predict1d at 0x7f4cfd879ea0&amp;gt;, &amp;#x27;BasePerturbationCV&amp;#x27;)\nestimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n\ntest/test_base_perturbation.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;BasePerturbationCV&amp;#x27;, BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression()))\n        fn         = &amp;lt;function check_fit2d_predict1d at 0x7f4cfd879e10&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1779: in check_fit2d_predict1d\n    estimator.fit(X, y)\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        estimator  = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        estimator_orig = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        name       = &amp;#x27;BasePerturbationCV&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1E00E40\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\nsrc/hidimstat/base_perturbation.py:419: in fit\n    self.importance_estimators_ = Parallel(n_jobs=self.n_jobs)(\n        X          = array([[1.64644051, 2.1455681 , 1.80829013],\n       [1.63464955, 1.2709644 , 1.93768234],\n       [1.31276163, 2.675319...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\n        self       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\n        y          = array([1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1962500&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf19621f0&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = (LinearRegression(), array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       ...2663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]]), array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0]))\n        batch_size = 1\n        func       = &amp;lt;bound method BasePerturbationCV._fit_single_split of BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())&amp;gt;\n        iterable   = &amp;lt;generator object BasePerturbationCV.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf1962500&amp;gt;\n        kwargs     = {}\n        self       = Parallel(n_jobs=1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\nestimator = LinearRegression()\nX_train = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\ny_train = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\n    def _fit_single_split(self, estimator, X_train, y_train):\n        &amp;quot;&amp;quot;&amp;quot;\n        Fit the estimator on the training data for a single split.\n        &amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       raise NotImplementedError\nE       NotImplementedError\n\nX_train    = array([[0.79366684, 2.32270107, 1.368451  ],\n       [1.70530185, 0.0563694 , 1.85290649],\n       [1.83628717, 1.850801...54, 2.96512151, 0.30613443],\n       [0.62663027, 0.48392855, 1.95932498],\n       [0.75987481, 1.39893232, 0.73327678]])\nestimator  = LinearRegression()\nself       = BasePerturbationCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n                   estimators=LinearRegression())\ny_train    = array([0, 1, 1, 2, 2, 2, 0, 1, 0, 0])\n\nsrc/hidimstat/base_perturbation.py:374: NotImplementedError\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&amp;lt;00:00, 1038.07it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:00&amp;lt;?, ?it/s]&#34;}], &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_unfitted_importance[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_unfitted_importance[default data]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::TestModelXKnockoffExceptions::test_unfitted_importance[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_error_lasso_statistic_with_sampling[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_error_lasso_statistic_with_sampling[default data]&#34;, &#34;duration&#34;: &#34;11 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::TestModelXKnockoffExceptions::test_error_lasso_statistic_with_sampling[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;11 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_error_lasso_statistic_with_sampling_with_bad_config[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_error_lasso_statistic_with_sampling_with_bad_config[default data]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::TestModelXKnockoffExceptions::test_error_lasso_statistic_with_sampling_with_bad_config[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_warning[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_warning[default data]&#34;, &#34;duration&#34;: &#34;50 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::TestModelXKnockoffExceptions::test_warning[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;50 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_invalid_n_samplings[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::TestModelXKnockoffExceptions::test_invalid_n_samplings[default data]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::TestModelXKnockoffExceptions::test_invalid_n_samplings[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::test_model_x_knockoff&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_model_x_knockoff&#34;, &#34;duration&#34;: &#34;130 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_model_x_knockoff&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;130 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::test_knockoff_function_not_centered&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_knockoff_function_not_centered&#34;, &#34;duration&#34;: &#34;94 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_knockoff_function_not_centered&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;94 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::test_model_x_knockoff_estimator&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_model_x_knockoff_estimator&#34;, &#34;duration&#34;: &#34;57 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_model_x_knockoff_estimator&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;57 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::test_knockoff_bootstrap_e_values&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_knockoff_bootstrap_e_values&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_knockoff_bootstrap_e_values&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.920e-01, tolerance: 1.630e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.433e-01, tolerance: 1.442e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.926e-01, tolerance: 1.662e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.273e-01, tolerance: 1.611e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.878e-01, tolerance: 1.949e-01\n  model = cd_fast.enet_coordinate_descent(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.807e-01, tolerance: 1.891e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.693e-01, tolerance: 2.229e-01\n  model = cd_fast.enet_coordinate_descent(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.019e-01, tolerance: 1.760e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.596e-01, tolerance: 1.522e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.458e-01, tolerance: 1.524e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n&#34;}], &#34;test/test_ensemble_clustered_inference.py::test_cludl_temporal&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_ensemble_clustered_inference.py::test_cludl_temporal&#34;, &#34;duration&#34;: &#34;00:00:05&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_ensemble_clustered_inference.py::test_cludl_temporal&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:05&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_categorical[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_categorical[default data]&#34;, &#34;duration&#34;: &#34;63 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIClass::test_categorical[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;63 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::test_estimate_distribution&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_estimate_distribution&#34;, &#34;duration&#34;: &#34;244 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_estimate_distribution&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;244 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::test_invariant_with_bootstrap&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_invariant_with_bootstrap&#34;, &#34;duration&#34;: &#34;90 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_invariant_with_bootstrap&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;90 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_knockoff.py::test_knockoff_bootstrap_quantile&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_knockoff_bootstrap_quantile&#34;, &#34;duration&#34;: &#34;535 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_knockoff_bootstrap_quantile&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;535 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.532e-01, tolerance: 1.750e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.516e-01, tolerance: 1.927e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.869e-01, tolerance: 1.746e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.119e-01, tolerance: 1.935e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.640e-01, tolerance: 1.940e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.248e-01, tolerance: 2.318e-01\n  model = cd_fast.enet_coordinate_descent(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.435e-01, tolerance: 2.186e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.227e-01, tolerance: 2.625e-01\n  model = cd_fast.enet_coordinate_descent(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.224e-01, tolerance: 2.029e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e-01, tolerance: 2.075e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.196e-01, tolerance: 2.557e-01\n  model = cd_fast.enet_coordinate_descent(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.928e-01, tolerance: 1.736e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.283e-01, tolerance: 1.778e-01\n  model = cd_fast.enet_coordinate_descent_gram(\n&#34;}], &#34;test/test_knockoff.py::test_preconfigure_LassoCV&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_knockoff.py::test_preconfigure_LassoCV&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_knockoff.py::test_preconfigure_LassoCV&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_result_attributes&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_result_attributes&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_result_attributes&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[less]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[less]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[less]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[greater]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[greater]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[greater]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative_exception&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative_exception&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative_exception&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[two-sided]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[two-sided]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_nadeau_bengio_ttest.py::TestTtest_1samp::test_alternative[two-sided]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_fit[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_fit[default data]&#34;, &#34;duration&#34;: &#34;992 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIClass::test_fit[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;992 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_init[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_init[default data]&#34;, &#34;duration&#34;: &#34;11 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIClass::test_init[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;11 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_fit_group[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIClass::test_fit_group[default data]&#34;, &#34;duration&#34;: &#34;20 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIClass::test_fit_group[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;20 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::test_ttest_1samp_corrected_NB[100-6-2-0.2-0-1.0-10.0-0.0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_nadeau_bengio_ttest.py::test_ttest_1samp_corrected_NB[100-6-2-0.2-0-1.0-10.0-0.0]&#34;, &#34;duration&#34;: &#34;467 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_nadeau_bengio_ttest.py::test_ttest_1samp_corrected_NB[100-6-2-0.2-0-1.0-10.0-0.0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;467 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit2d_predict1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit2d_predict1d]&#34;, &#34;duration&#34;: &#34;190 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit2d_predict1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;190 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_f_contiguous_array_estimator]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_f_contiguous_array_estimator]&#34;, &#34;duration&#34;: &#34;189 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_f_contiguous_array_estimator]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;189 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_mismatched_features[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_mismatched_features[default data]&#34;, &#34;duration&#34;: &#34;875 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_mismatched_features[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;875 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unfitted_importance[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unfitted_importance[default data]&#34;, &#34;duration&#34;: &#34;12 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unfitted_importance[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;12 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_n_features_in_after_fitting]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_n_features_in_after_fitting]&#34;, &#34;duration&#34;: &#34;239 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_n_features_in_after_fitting]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;239 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ncheck = functools.partial(&amp;lt;function check_n_features_in_after_fitting at 0x7f4cfd8867a0&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_n_features_in_after_fitting at 0x7f4cfd8867a0&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\ntest/test_distilled_conditional_randomization_test.py:73: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;D0CRT&amp;#x27;, D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None))\n        fn         = &amp;lt;function check_n_features_in_after_fitting at 0x7f4cfd886710&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;D0CRT&amp;#x27;\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\n    @ignore_warnings(category=FutureWarning)\n    def check_n_features_in_after_fitting(name, estimator_orig):\n        # Make sure that n_features_in are checked after fitting\n        tags = get_tags(estimator_orig)\n    \n        is_supported_X_types = tags.input_tags.two_d_array or tags.input_tags.categorical\n    \n        if not is_supported_X_types or tags.no_validation:\n            return\n    \n        rng = np.random.RandomState(0)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if &amp;quot;warm_start&amp;quot; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 10\n        X = rng.normal(size=(n_samples, 4))\n        X = _enforce_estimator_tags_X(estimator, X)\n    \n        if is_regressor(estimator):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        err_msg = (\n            &amp;quot;`{name}.fit()` does not set the `n_features_in_` attribute. &amp;quot;\n            &amp;quot;You might want to use `sklearn.utils.validation.validate_data` instead &amp;quot;\n            &amp;quot;of `check_array` in `{name}.fit()` which takes care of setting the &amp;quot;\n            &amp;quot;attribute.&amp;quot;.format(name=name)\n        )\n    \n        estimator.fit(X, y)\n&amp;gt;       assert hasattr(estimator, &amp;quot;n_features_in_&amp;quot;), err_msg\nE       AssertionError: `D0CRT.fit()` does not set the `n_features_in_` attribute. You might want to use `sklearn.utils.validation.validate_data` instead of `check_array` in `D0CRT.fit()` which takes care of setting the attribute.\n\nX          = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n       [ 1.86755799, -0.97727788,  0.95008842, -0.1513572...    [-0.88778575, -1.98079647, -0.34791215,  0.15634897],\n       [ 1.23029068,  1.20237985, -0.38732682, -0.30230275]])\nerr_msg    = &amp;#x27;`D0CRT.fit()` does not set the `n_features_in_` attribute. You might want to use `sklearn.utils.validation.validate_data` instead of `check_array` in `D0CRT.fit()` which takes care of setting the attribute.&amp;#x27;\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7F4CF1E01840),\n      random_state=0, screening_threshold=None)\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nis_supported_X_types = True\nn_samples  = 10\nname       = &amp;#x27;D0CRT&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4D14930140\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([0, 1, 1, 0, 1, 0, 0, 1, 0, 0])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4449: AssertionError\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_sparse_tag]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_sparse_tag]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_sparse_tag]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_internal_error[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_internal_error[default data]&#34;, &#34;duration&#34;: &#34;56 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_internal_error[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;56 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unknown_predict_method[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unknown_predict_method[default data]&#34;, &#34;duration&#34;: &#34;12 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unknown_predict_method[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;12 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_linear&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_linear&#34;, &#34;duration&#34;: &#34;219 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_d0crt_linear&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;219 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit_idempotent]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit_idempotent]&#34;, &#34;duration&#34;: &#34;373 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit_idempotent]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;373 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/2 [00:05&amp;lt;?, ?it/s]\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_RF_classification&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_RF_classification&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_RF_classification&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_nan_inf]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_nan_inf]&#34;, &#34;duration&#34;: &#34;379 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_nan_inf]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;379 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit_check_is_fitted]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit_check_is_fitted]&#34;, &#34;duration&#34;: &#34;141 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit_check_is_fitted]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;141 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;D0CRT&amp;#x27;\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\n    def check_fit_check_is_fitted(name, estimator_orig):\n        # Make sure that estimator doesn&amp;#x27;t pass check_is_fitted before calling fit\n        # and that passes check_is_fitted once it&amp;#x27;s fit.\n    \n        rng = np.random.RandomState(42)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if &amp;quot;warm_start&amp;quot; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if get_tags(estimator).requires_fit:\n            # stateless estimators (such as FunctionTransformer) are always &amp;quot;fit&amp;quot;!\n            try:\n                check_is_fitted(estimator)\n                raise AssertionError(\n                    f&amp;quot;{estimator.__class__.__name__} passes check_is_fitted before being&amp;quot;\n                    &amp;quot; fit!&amp;quot;\n                )\n            except NotFittedError:\n                pass\n        estimator.fit(X, y)\n        try:\n&amp;gt;           check_is_fitted(estimator)\n\nX          = array([[100.49671415,  99.8617357 ],\n       [100.64768854, 101.52302986],\n       [ 99.76584663,  99.76586304],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7F4CF1E01E40),\n      la...ate(PCG64) at 0x7F4D14930140,\n                              tol=1e-06),\n      random_state=0, screening_threshold=None)\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nn_samples  = 100\nname       = &amp;#x27;D0CRT&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CFAC4D140\ny          = array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,...1,\n       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4355: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7F4CF1E01E40),\n      la...ate(PCG64) at 0x7F4D14930140,\n                              tol=1e-06),\n      random_state=0, screening_threshold=None)\nattributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This D0CRT instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7F4CF1E01E40),\n      la...ate(PCG64) at 0x7F4D14930140,\n                              tol=1e-06),\n      random_state=0, screening_threshold=None)\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ncheck = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7f4cfd886560&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7f4cfd886560&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\ntest/test_distilled_conditional_randomization_test.py:73: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;D0CRT&amp;#x27;\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\n    def check_fit_check_is_fitted(name, estimator_orig):\n        # Make sure that estimator doesn&amp;#x27;t pass check_is_fitted before calling fit\n        # and that passes check_is_fitted once it&amp;#x27;s fit.\n    \n        rng = np.random.RandomState(42)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if &amp;quot;warm_start&amp;quot; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if get_tags(estimator).requires_fit:\n            # stateless estimators (such as FunctionTransformer) are always &amp;quot;fit&amp;quot;!\n            try:\n                check_is_fitted(estimator)\n                raise AssertionError(\n                    f&amp;quot;{estimator.__class__.__name__} passes check_is_fitted before being&amp;quot;\n                    &amp;quot; fit!&amp;quot;\n                )\n            except NotFittedError:\n                pass\n        estimator.fit(X, y)\n        try:\n            check_is_fitted(estimator)\n        except NotFittedError as e:\n&amp;gt;           raise NotFittedError(\n                &amp;quot;Estimator fails to pass `check_is_fitted` even though it has been fit.&amp;quot;\n            ) from e\nE           sklearn.exceptions.NotFittedError: Estimator fails to pass `check_is_fitted` even though it has been fit.\n\nX          = array([[100.49671415,  99.8617357 ],\n       [100.64768854, 101.52302986],\n       [ 99.76584663,  99.76586304],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7F4CF1E01E40),\n      la...ate(PCG64) at 0x7F4D14930140,\n                              tol=1e-06),\n      random_state=0, screening_threshold=None)\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nn_samples  = 100\nname       = &amp;#x27;D0CRT&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CFAC4D140\ny          = array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,...1,\n       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4357: NotFittedError\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit&#34;, &#34;duration&#34;: &#34;99 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;99 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_dict_unchanged]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_dict_unchanged]&#34;, &#34;duration&#34;: &#34;189 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_dict_unchanged]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;189 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_assert_dimension_pvalue[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_assert_dimension_pvalue[default data]&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_assert_dimension_pvalue[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_var_type[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_var_type[default data]&#34;, &#34;duration&#34;: &#34;89 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_var_type[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;89 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_groups_format[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_groups_format[default data]&#34;, &#34;duration&#34;: &#34;12 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_groups_format[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;12 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unfitted_base_perturbation[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unfitted_base_perturbation[default data]&#34;, &#34;duration&#34;: &#34;12 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_unfitted_base_perturbation[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;12 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_type[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_type[default data]&#34;, &#34;duration&#34;: &#34;12 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_type[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;12 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_n_permutations[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_n_permutations[default data]&#34;, &#34;duration&#34;: &#34;11 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_invalid_n_permutations[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;11 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_repeatability&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_repeatability&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_d0crt_repeatability&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_fit_returns_self]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_fit_returns_self]&#34;, &#34;duration&#34;: &#34;141 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_fit_returns_self]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;141 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_parameters_default_constructible]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_parameters_default_constructible]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_parameters_default_constructible]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ncheck = functools.partial(&amp;lt;function check_parameters_default_constructible at 0x7f4cfd885a20&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_parameters_default_constructible at 0x7f4cfd885a20&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\ntest/test_distilled_conditional_randomization_test.py:73: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;D0CRT&amp;#x27;\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\n    def check_parameters_default_constructible(name, estimator_orig):\n        # test default-constructibility\n        # get rid of deprecation warnings\n    \n        Estimator = estimator_orig.__class__\n        estimator = clone(estimator_orig)\n    \n        with ignore_warnings(category=FutureWarning):\n            # test that set_params returns self\n            # TODO(devtools): this should be a separate check.\n            assert estimator.set_params() is estimator\n    \n            # test if init does nothing but set parameters\n            # this is important for grid_search etc.\n            # We get the default parameters from init and then\n            # compare these against the actual values of the attributes.\n    \n            # this comes from getattr. Gets rid of deprecation decorator.\n            init = getattr(estimator.__init__, &amp;quot;deprecated_original&amp;quot;, estimator.__init__)\n    \n            try:\n    \n                def param_default_value(p):\n                    &amp;quot;&amp;quot;&amp;quot;Identify hyper parameters of an estimator.&amp;quot;&amp;quot;&amp;quot;\n                    return (\n                        p.name != &amp;quot;self&amp;quot;\n                        and p.kind != p.VAR_KEYWORD\n                        and p.kind != p.VAR_POSITIONAL\n                        # and it should have a default value for this test\n                        and p.default != p.empty\n                    )\n    \n                def param_required(p):\n                    &amp;quot;&amp;quot;&amp;quot;Identify hyper parameters of an estimator.&amp;quot;&amp;quot;&amp;quot;\n                    return (\n                        p.name != &amp;quot;self&amp;quot;\n                        and p.kind != p.VAR_KEYWORD\n                        # technically VAR_POSITIONAL is also required, but we don&amp;#x27;t have a\n                        # nice way to check for it. We assume there&amp;#x27;s no VAR_POSITIONAL in\n                        # the constructor parameters.\n                        #\n                        # TODO(devtools): separately check that the constructor doesn&amp;#x27;t\n                        # have *args.\n                        and p.kind != p.VAR_POSITIONAL\n                        # these are parameters that don&amp;#x27;t have a default value and are\n                        # required to construct the estimator.\n                        and p.default == p.empty\n                    )\n    \n                required_params_names = [\n                    p.name for p in signature(init).parameters.values() if param_required(p)\n                ]\n    \n                default_value_params = [\n                    p for p in signature(init).parameters.values() if param_default_value(p)\n                ]\n    \n            except (TypeError, ValueError):\n                # init is not a python function.\n                # true for mixins\n                return\n    \n            # here we construct an instance of the estimator using only the required\n            # parameters.\n            old_params = estimator.get_params()\n            init_params = {\n                param: old_params[param]\n                for param in old_params\n                if param in required_params_names\n            }\n            estimator = Estimator(**init_params)\n            params = estimator.get_params()\n    \n            for init_param in default_value_params:\n                allowed_types = {\n                    str,\n                    int,\n                    float,\n                    bool,\n                    tuple,\n                    type(None),\n                    type,\n                }\n                # Any numpy numeric such as np.int32.\n                allowed_types.update(np.sctypeDict.values())\n    \n                allowed_value = (\n                    type(init_param.default) in allowed_types\n                    or\n                    # Although callables are mutable, we accept them as argument\n                    # default value and trust that neither the implementation of\n                    # the callable nor of the estimator changes the state of the\n                    # callable.\n                    callable(init_param.default)\n                )\n    \n&amp;gt;               assert allowed_value, (\n                    f&amp;quot;Parameter &amp;#x27;{init_param.name}&amp;#x27; of estimator &amp;quot;\n                    f&amp;quot;&amp;#x27;{Estimator.__name__}&amp;#x27; is of type &amp;quot;\n                    f&amp;quot;{type(init_param.default).__name__} which is not allowed. &amp;quot;\n                    f&amp;quot;&amp;#x27;{init_param.name}&amp;#x27; must be a callable or must be of type &amp;quot;\n                    f&amp;quot;{set(type.__name__ for type in allowed_types)}.&amp;quot;\n                )\nE               AssertionError: Parameter &amp;#x27;lasso_screening&amp;#x27; of estimator &amp;#x27;D0CRT&amp;#x27; is of type LassoCV which is not allowed. &amp;#x27;lasso_screening&amp;#x27; must be a callable or must be of type {&amp;#x27;int64&amp;#x27;, &amp;#x27;float16&amp;#x27;, &amp;#x27;bool&amp;#x27;, &amp;#x27;ulonglong&amp;#x27;, &amp;#x27;int&amp;#x27;, &amp;#x27;float&amp;#x27;, &amp;#x27;clongdouble&amp;#x27;, &amp;#x27;uint64&amp;#x27;, &amp;#x27;tuple&amp;#x27;, &amp;#x27;timedelta64&amp;#x27;, &amp;#x27;bytes_&amp;#x27;, &amp;#x27;uint8&amp;#x27;, &amp;#x27;NoneType&amp;#x27;, &amp;#x27;int8&amp;#x27;, &amp;#x27;int16&amp;#x27;, &amp;#x27;type&amp;#x27;, &amp;#x27;int32&amp;#x27;, &amp;#x27;object_&amp;#x27;, &amp;#x27;uint32&amp;#x27;, &amp;#x27;float64&amp;#x27;, &amp;#x27;str&amp;#x27;, &amp;#x27;str_&amp;#x27;, &amp;#x27;void&amp;#x27;, &amp;#x27;longlong&amp;#x27;, &amp;#x27;datetime64&amp;#x27;, &amp;#x27;complex64&amp;#x27;, &amp;#x27;longdouble&amp;#x27;, &amp;#x27;uint16&amp;#x27;, &amp;#x27;complex128&amp;#x27;, &amp;#x27;float32&amp;#x27;}.\n\nEstimator  = &amp;lt;class &amp;#x27;hidimstat.distilled_conditional_randomization_test.D0CRT&amp;#x27;&amp;gt;\nallowed_types = {&amp;lt;class &amp;#x27;numpy.datetime64&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.complex128&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.float16&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.uint8&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.int8&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;bool&amp;#x27;&amp;gt;, ...}\nallowed_value = False\ndefault_value_params = [&amp;lt;Parameter &amp;quot;method: str = &amp;#x27;predict&amp;#x27;&amp;quot;&amp;gt;, &amp;lt;Parameter &amp;quot;estimated_coef=None&amp;quot;&amp;gt;, &amp;lt;Parameter &amp;quot;estimated_intercept=None&amp;quot;&amp;gt;, &amp;lt;Pa...state=RandomState(PCG64) at 0x7F4CF1E00940, tol=1e-06)&amp;quot;&amp;gt;, &amp;lt;Parameter &amp;quot;model_distillation_x=LassoCV(n_alphas=10)&amp;quot;&amp;gt;, ...]\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1))\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nfailure_text = &amp;#x27;Parameter sigma_X was mutated on init. All parameters must be stored unchanged.&amp;#x27;\ninit       = &amp;lt;bound method D0CRT.__init__ of D0CRT(estimator=LassoCV(n_jobs=1),\n      lasso_screening=LassoCV(fit_intercept=False, ..._state=RandomState(PCG64) at 0x7F4CF1E01440,\n                              tol=1e-06),\n      screening_threshold=None)&amp;gt;\ninit_param = &amp;lt;Parameter &amp;quot;lasso_screening=LassoCV(fit_intercept=False, n_alphas=10,\n        random_state=RandomState(PCG64) at 0x7F4CF1E00940, tol=1e-06)&amp;quot;&amp;gt;\ninit_params = {&amp;#x27;estimator&amp;#x27;: LassoCV(n_jobs=1)}\nname       = &amp;#x27;D0CRT&amp;#x27;\nold_params = {&amp;#x27;centered&amp;#x27;: True, &amp;#x27;estimated_coef&amp;#x27;: None, &amp;#x27;estimated_intercept&amp;#x27;: None, &amp;#x27;estimator&amp;#x27;: LassoCV(n_jobs=1), ...}\nparam_default_value = &amp;lt;function check_parameters_default_constructible.&amp;lt;locals&amp;gt;.param_default_value at 0x7f4cf179b760&amp;gt;\nparam_required = &amp;lt;function check_parameters_default_constructible.&amp;lt;locals&amp;gt;.param_required at 0x7f4cf179b880&amp;gt;\nparam_value = None\nparams     = {&amp;#x27;centered&amp;#x27;: True, &amp;#x27;estimated_coef&amp;#x27;: None, &amp;#x27;estimated_intercept&amp;#x27;: None, &amp;#x27;estimator&amp;#x27;: LassoCV(n_jobs=1), ...}\nrequired_params_names = [&amp;#x27;estimator&amp;#x27;]\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3890: AssertionError\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_do_not_raise_errors_in_init_or_set_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_do_not_raise_errors_in_init_or_set_params]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_do_not_raise_errors_in_init_or_set_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ncheck = functools.partial(&amp;lt;function check_do_not_raise_errors_in_init_or_set_params at 0x7f4cfd887250&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_do_not_raise_errors_in_init_or_set_params at 0x7f4cfd887250&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\ntest/test_distilled_conditional_randomization_test.py:73: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:5307: in check_do_not_raise_errors_in_init_or_set_params\n    est = Estimator(**new_params)\n        Estimator  = &amp;lt;class &amp;#x27;hidimstat.distilled_conditional_randomization_test.D0CRT&amp;#x27;&amp;gt;\n        estimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n        name       = &amp;#x27;D0CRT&amp;#x27;\n        new_params = {&amp;#x27;centered&amp;#x27;: -1, &amp;#x27;estimated_coef&amp;#x27;: -1, &amp;#x27;estimated_intercept&amp;#x27;: -1, &amp;#x27;estimator&amp;#x27;: -1, ...}\n        params     = mappingproxy(OrderedDict([(&amp;#x27;estimator&amp;#x27;, &amp;lt;Parameter &amp;quot;estimator&amp;quot;&amp;gt;), (&amp;#x27;method&amp;#x27;, &amp;lt;Parameter &amp;quot;method: str = &amp;#x27;predict&amp;#x27;&amp;quot;&amp;gt;), (...reuse_screening_model&amp;#x27;, &amp;lt;Parameter &amp;quot;reuse_screening_model=True&amp;quot;&amp;gt;), (&amp;#x27;random_state&amp;#x27;, &amp;lt;Parameter &amp;quot;random_state=None&amp;quot;&amp;gt;)]))\n        smoke_test_values = [-1, 3.0, &amp;#x27;helloworld&amp;#x27;, array([1., 4.]), [1], {}, ...]\n        value      = -1\nsrc/hidimstat/distilled_conditional_randomization_test.py:151: in __init__\n    _check_vim_predict_method(method)\n        centered   = -1\n        estimated_coef = -1\n        estimated_intercept = -1\n        estimator  = -1\n        fit_y      = -1\n        joblib_verbose = -1\n        lasso_screening = -1\n        method     = -1\n        model_distillation_x = -1\n        n_jobs     = -1\n        random_state = -1\n        refit      = -1\n        reuse_screening_model = -1\n        scaled_statistics = -1\n        screening_threshold = -1\n        self       = &amp;lt;[AttributeError(&amp;quot;&amp;#x27;D0CRT&amp;#x27; object has no attribute &amp;#x27;centered&amp;#x27;&amp;quot;) raised in repr()] D0CRT object at 0x7f4cf80efdf0&amp;gt;\n        sigma_X    = -1\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmethod = -1\n\n    def _check_vim_predict_method(method):\n        &amp;quot;&amp;quot;&amp;quot;\n        Validates that the method is a valid scikit-learn prediction method for variable importance measures.\n    \n        Parameters\n        ----------\n        method : str\n            The scikit-learn prediction method to validate.\n    \n        Returns\n        -------\n        str\n            The validated method if valid.\n    \n        Raises\n        ------\n        ValueError\n            If the method is not one of the standard scikit-learn prediction methods:\n            &amp;#x27;predict&amp;#x27;, &amp;#x27;predict_proba&amp;#x27; or &amp;#x27;decision_function&amp;#x27;.\n        &amp;quot;&amp;quot;&amp;quot;\n        if method in [&amp;quot;predict&amp;quot;, &amp;quot;predict_proba&amp;quot;, &amp;quot;decision_function&amp;quot;]:\n            return method\n        else:\n&amp;gt;           raise ValueError(\n                f&amp;quot;The method {method} is not a valid method &amp;quot;\n                &amp;quot;for variable importance measure prediction&amp;quot;\n            )\nE           ValueError: The method -1 is not a valid method for variable importance measure prediction\n\nmethod     = -1\n\nsrc/hidimstat/_utils/utils.py:34: ValueError\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_unfitted]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_unfitted]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_unfitted]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_not_good_type_X[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_not_good_type_X[default data]&#34;, &#34;duration&#34;: &#34;879 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_not_good_type_X[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;879 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_groups_warning[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_groups_warning[default data]&#34;, &#34;duration&#34;: &#34;58 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_groups_warning[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;58 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_incompatible_imputer[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_incompatible_imputer[default data]&#34;, &#34;duration&#34;: &#34;13 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_incompatible_imputer[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;13 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_mismatched_features_string[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::TestCFIExceptions::test_mismatched_features_string[default data]&#34;, &#34;duration&#34;: &#34;29 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::TestCFIExceptions::test_mismatched_features_string[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;29 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_n_features_in]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_n_features_in]&#34;, &#34;duration&#34;: &#34;142 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_n_features_in]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;142 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ncheck = functools.partial(&amp;lt;function check_n_features_in at 0x7f4cfd8865f0&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_n_features_in at 0x7f4cfd8865f0&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\ntest/test_distilled_conditional_randomization_test.py:73: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;D0CRT&amp;#x27;\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\n    def check_n_features_in(name, estimator_orig):\n        # Make sure that n_features_in_ attribute doesn&amp;#x27;t exist until fit is\n        # called, and that its value is correct.\n    \n        rng = np.random.RandomState(0)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if &amp;quot;warm_start&amp;quot; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        assert not hasattr(estimator, &amp;quot;n_features_in_&amp;quot;)\n        estimator.fit(X, y)\n&amp;gt;       assert hasattr(estimator, &amp;quot;n_features_in_&amp;quot;)\nE       AssertionError\n\nX          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7F4CF1E01540),\n      la...ate(PCG64) at 0x7F4CF1E01040,\n                              tol=1e-06),\n      random_state=0, screening_threshold=None)\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nn_samples  = 100\nname       = &amp;#x27;D0CRT&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CF1E01A40\ny          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4384: AssertionError\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_methods_sample_order_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_methods_sample_order_invariance]&#34;, &#34;duration&#34;: &#34;190 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_methods_sample_order_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;190 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_dtype_object]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_dtype_object]&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_dtype_object]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_distillation_y_different&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_distillation_y_different&#34;, &#34;duration&#34;: &#34;24 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_distillation_y_different&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;24 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_no_cv&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_no_cv&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_no_cv&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_no_selection&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_no_selection&#34;, &#34;duration&#34;: &#34;502 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_no_selection&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;502 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_overwrite_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_overwrite_params]&#34;, &#34;duration&#34;: &#34;144 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_overwrite_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;144 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ncheck = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4cfd8852d0&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4cfd8852d0&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\ntest/test_distilled_conditional_randomization_test.py:73: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;D0CRT&amp;#x27;, D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None))\n        fn         = &amp;lt;function check_estimators_overwrite_params at 0x7f4cfd885240&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;D0CRT&amp;#x27;\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\n    @ignore_warnings(category=FutureWarning)\n    def check_estimators_overwrite_params(name, estimator_orig):\n        X, y = make_blobs(random_state=0, n_samples=21)\n        X = _enforce_estimator_tags_X(estimator_orig, X, kernel=rbf_kernel)\n        estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        set_random_state(estimator)\n    \n        # Make a physical copy of the original estimator parameters before fitting.\n        params = estimator.get_params()\n        original_params = deepcopy(params)\n    \n        # Fit the model\n        estimator.fit(X, y)\n    \n        # Compare the state of the model parameters with the original parameters\n        new_params = estimator.get_params()\n        for param_name, original_value in original_params.items():\n            new_value = new_params[param_name]\n    \n            # We should never change or mutate the internal state of input\n            # parameters by default. To check this we use the joblib.hash function\n            # that introspects recursively any subobjects to compute a checksum.\n            # The only exception to this rule of immutable constructor parameters\n            # is possible RandomState instance but in this check we explicitly\n            # fixed the random_state params recursively to be integer seeds.\n&amp;gt;           assert joblib.hash(new_value) == joblib.hash(original_value), (\n                &amp;quot;Estimator %s should not change or mutate &amp;quot;\n                &amp;quot; the parameter %s from %s to %s during fit.&amp;quot;\n                % (name, param_name, original_value, new_value)\n            )\nE           AssertionError: Estimator D0CRT should not change or mutate  the parameter estimator__random_state from None to RandomState(PCG64) during fit.\n\nX          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7F4CF1E02C40),\n      la...ate(PCG64) at 0x7F4CF1E02940,\n                              tol=1e-06),\n      random_state=0, screening_threshold=None)\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nname       = &amp;#x27;D0CRT&amp;#x27;\nnew_params = {&amp;#x27;centered&amp;#x27;: True, &amp;#x27;estimated_coef&amp;#x27;: None, &amp;#x27;estimated_intercept&amp;#x27;: None, &amp;#x27;estimator&amp;#x27;: LassoCV(n_jobs=1, random_state=RandomState(PCG64) at 0x7F4CF1E02C40), ...}\nnew_value  = RandomState(PCG64) at 0x7F4CF1E02C40\noriginal_params = {&amp;#x27;centered&amp;#x27;: True, &amp;#x27;estimated_coef&amp;#x27;: None, &amp;#x27;estimated_intercept&amp;#x27;: None, &amp;#x27;estimator&amp;#x27;: LassoCV(n_jobs=1), ...}\noriginal_value = None\nparam_name = &amp;#x27;estimator__random_state&amp;#x27;\nparams     = {&amp;#x27;centered&amp;#x27;: True, &amp;#x27;estimated_coef&amp;#x27;: None, &amp;#x27;estimated_intercept&amp;#x27;: None, &amp;#x27;estimator&amp;#x27;: LassoCV(n_jobs=1, random_state=RandomState(PCG64) at 0x7F4CF1E02C40), ...}\ny          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3621: AssertionError\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit1d]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_center&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_center&#34;, &#34;duration&#34;: &#34;538 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_center&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;538 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_sparse_matrix]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_sparse_matrix]&#34;, &#34;duration&#34;: &#34;19 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_sparse_matrix]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;19 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_function_d0crt&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_function_d0crt&#34;, &#34;duration&#34;: &#34;23 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_function_d0crt&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;23 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_sparse_array]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_sparse_array]&#34;, &#34;duration&#34;: &#34;18 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_sparse_array]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;18 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit_errors&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit_errors&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit_errors&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_readonly_memmap_input]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_readonly_memmap_input]&#34;, &#34;duration&#34;: &#34;141 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_readonly_memmap_input]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;141 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_classication[HiDim with correlated noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_classication[HiDim with correlated noise]&#34;, &#34;duration&#34;: &#34;00:00:05&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_classication[HiDim with correlated noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:05&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_regression_intercept&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_regression_intercept&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_regression_intercept&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim]&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_dtypes]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_dtypes]&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_dtypes]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_randomness_with_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_randomness_with_none&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_d0crt_randomness_with_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_set_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_set_params]&#34;, &#34;duration&#34;: &#34;26 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_set_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;26 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_fit_with_no_cv&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_fit_with_no_cv&#34;, &#34;duration&#34;: &#34;546 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_fit_with_no_cv&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;546 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_classication[HiDim]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_classication[HiDim]&#34;, &#34;duration&#34;: &#34;00:00:05&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_classication[HiDim]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:05&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit_score_takes_y]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit_score_takes_y]&#34;, &#34;duration&#34;: &#34;190 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit_score_takes_y]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;190 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_estimed_coefficient&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_estimed_coefficient&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_estimed_coefficient&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features and noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features and noise]&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features and noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_reproducibility_with_integer&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_reproducibility_with_integer&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_d0crt_reproducibility_with_integer&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_RF_regression&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_RF_regression&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_RF_regression&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_mixin_order]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_mixin_order]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_mixin_order]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_dont_overwrite_parameters]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_dont_overwrite_parameters]&#34;, &#34;duration&#34;: &#34;191 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_dont_overwrite_parameters]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;191 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_classication[HiDim with noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_classication[HiDim with noise]&#34;, &#34;duration&#34;: &#34;00:00:05&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_classication[HiDim with noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:05&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_rf&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_rf&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_d0crt_rf&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_distillation_x_different&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_distillation_x_different&#34;, &#34;duration&#34;: &#34;35 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_distillation_x_different&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;35 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features and correlated noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features and correlated noise]&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features and correlated noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_pipeline_consistency]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_pipeline_consistency]&#34;, &#34;duration&#34;: &#34;383 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_pipeline_consistency]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;383 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim with noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim with noise]&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim with noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_linear_data_fail[default_cfi-high level noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_linear_data_fail[default_cfi-high level noise]&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_linear_data_fail[default_cfi-high level noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_reproducibility_with_rng&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_d0crt_reproducibility_with_rng&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_d0crt_reproducibility_with_rng&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_no_attributes_set_in_init]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_no_attributes_set_in_init]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_no_attributes_set_in_init]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ncheck = functools.partial(&amp;lt;function check_no_attributes_set_in_init at 0x7f4cfd8853f0&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_no_attributes_set_in_init at 0x7f4cfd8853f0&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\ntest/test_distilled_conditional_randomization_test.py:73: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;D0CRT&amp;#x27;, D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None))\n        fn         = &amp;lt;function check_no_attributes_set_in_init at 0x7f4cfd885360&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;D0CRT&amp;#x27;\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\n    @ignore_warnings(category=FutureWarning)\n    def check_no_attributes_set_in_init(name, estimator_orig):\n        &amp;quot;&amp;quot;&amp;quot;Check setting during init.&amp;quot;&amp;quot;&amp;quot;\n        try:\n            # Clone fails if the estimator does not store\n            # all parameters as an attribute during init\n            estimator = clone(estimator_orig)\n        except AttributeError:\n            raise AttributeError(\n                f&amp;quot;Estimator {name} should store all parameters as an attribute during init.&amp;quot;\n            )\n    \n        if hasattr(type(estimator).__init__, &amp;quot;deprecated_original&amp;quot;):\n            return\n    \n        init_params = _get_args(type(estimator).__init__)\n        parents_init_params = [\n            param\n            for params_parent in (_get_args(parent) for parent in type(estimator).__mro__)\n            for param in params_parent\n        ]\n    \n        # Test for no setting apart from parameters during init\n        invalid_attr = set(vars(estimator)) - set(init_params) - set(parents_init_params)\n        # Ignore private attributes\n        invalid_attr = set([attr for attr in invalid_attr if not attr.startswith(&amp;quot;_&amp;quot;)])\n&amp;gt;       assert not invalid_attr, (\n            &amp;quot;Estimator %s should not set any attribute apart&amp;quot;\n            &amp;quot; from parameters during init. Found attributes %s.&amp;quot;\n            % (name, sorted(invalid_attr))\n        )\nE       AssertionError: Estimator D0CRT should not set any attribute apart from parameters during init. Found attributes [&amp;#x27;coefficient_&amp;#x27;, &amp;#x27;intercept_&amp;#x27;, &amp;#x27;is_logistic_&amp;#x27;, &amp;#x27;lasso_weights_&amp;#x27;, &amp;#x27;model_x_&amp;#x27;, &amp;#x27;model_y_&amp;#x27;, &amp;#x27;selection_set_&amp;#x27;].\n\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1),\n      lasso_screening=LassoCV(fit_intercept=False, n_alphas=10,\n                   ...m_state=RandomState(PCG64) at 0x7F4D0226EC40,\n                              tol=1e-06),\n      screening_threshold=None)\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ninit_params = [&amp;#x27;self&amp;#x27;, &amp;#x27;estimator&amp;#x27;, &amp;#x27;method&amp;#x27;, &amp;#x27;estimated_coef&amp;#x27;, &amp;#x27;estimated_intercept&amp;#x27;, &amp;#x27;sigma_X&amp;#x27;, ...]\ninvalid_attr = {&amp;#x27;coefficient_&amp;#x27;, &amp;#x27;intercept_&amp;#x27;, &amp;#x27;is_logistic_&amp;#x27;, &amp;#x27;lasso_weights_&amp;#x27;, &amp;#x27;model_x_&amp;#x27;, &amp;#x27;model_y_&amp;#x27;, ...}\nname       = &amp;#x27;D0CRT&amp;#x27;\nparents_init_params = [&amp;#x27;estimator&amp;#x27;, &amp;#x27;method&amp;#x27;, &amp;#x27;estimated_coef&amp;#x27;, &amp;#x27;estimated_intercept&amp;#x27;, &amp;#x27;sigma_X&amp;#x27;, &amp;#x27;lasso_screening&amp;#x27;, ...]\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3654: AssertionError\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit2d_1feature]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit2d_1feature]&#34;, &#34;duration&#34;: &#34;43 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit2d_1feature]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;43 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;D0CRT&amp;#x27;\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\n    @ignore_warnings\n    def check_fit2d_1feature(name, estimator_orig):\n        # check fitting a 2d array with only 1 feature either works or returns\n        # informative message\n        rnd = np.random.RandomState(0)\n        X = 3 * rnd.uniform(size=(10, 1))\n        X = _enforce_estimator_tags_X(estimator_orig, X)\n        y = X[:, 0].astype(int)\n        estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if hasattr(estimator, &amp;quot;n_components&amp;quot;):\n            estimator.n_components = 1\n        if hasattr(estimator, &amp;quot;n_clusters&amp;quot;):\n            estimator.n_clusters = 1\n        # ensure two labels in subsample for RandomizedLogisticRegression\n        if name == &amp;quot;RandomizedLogisticRegression&amp;quot;:\n            estimator.sample_fraction = 1\n        # ensure non skipped trials for RANSACRegressor\n        if name == &amp;quot;RANSACRegressor&amp;quot;:\n            estimator.residual_threshold = 0.5\n    \n        y = _enforce_estimator_tags_y(estimator, y)\n        set_random_state(estimator, 1)\n    \n        msgs = [r&amp;quot;1 feature\\(s\\)&amp;quot;, &amp;quot;n_features = 1&amp;quot;, &amp;quot;n_features=1&amp;quot;]\n    \n        with raises(ValueError, match=msgs, may_pass=True):\n&amp;gt;           estimator.fit(X, y)\n\nX          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7F4CF1E02340),\n      la...ate(PCG64) at 0x7F4CF1E03640,\n                              tol=1e-06),\n      random_state=1, screening_threshold=None)\nestimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\nmsgs       = [&amp;#x27;1 feature\\\\(s\\\\)&amp;#x27;, &amp;#x27;n_features = 1&amp;#x27;, &amp;#x27;n_features=1&amp;#x27;]\nname       = &amp;#x27;D0CRT&amp;#x27;\nrnd        = RandomState(MT19937) at 0x7F4CF1E00240\ny          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1956: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/distilled_conditional_randomization_test.py:285: in fit\n    results = Parallel(self.n_jobs, verbose=self.joblib_verbose)(\n        X          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\n        X_         = array([[-0.36293708],\n       [ 0.53895184],\n       [-0.07048605],\n       [-0.38424253],\n       [-1.04139636],\n       [ 0.16331669],\n       [-0.96587166],\n       [ 1.49617496],\n       [ 1.88587438],\n       [-1.25938418]])\n        rng        = Generator(PCG64) at 0x7F4CF1E83300\n        self       = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7F4CF1E02340),\n      la...ate(PCG64) at 0x7F4CF1E03640,\n                              tol=1e-06),\n      random_state=1, screening_threshold=None)\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n        y_         = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object D0CRT.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf17f2960&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7f4cf17f2a40&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = ()\n        batch_size = 1\n        func       = &amp;lt;function _joblib_fit at 0x7f4cfd8d6200&amp;gt;\n        iterable   = &amp;lt;generator object D0CRT.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7f4cf17f2960&amp;gt;\n        kwargs     = {&amp;#x27;X&amp;#x27;: array([[-0.36293708],\n       [ 0.53895184],\n       [-0.07048605],\n       [-0.38424253],\n       [-1.04139636],\n  ...timator&amp;#x27;: LassoCV(n_jobs=1, random_state=RandomState(PCG64) at 0x7F4CF1E02340), &amp;#x27;fit_y&amp;#x27;: True, &amp;#x27;idx&amp;#x27;: np.int64(0), ...}\n        self       = Parallel(n_jobs=1)\nsrc/hidimstat/distilled_conditional_randomization_test.py:676: in _joblib_fit\n    model_x.fit(X_minus_idx, X[:, idx], sample_weight=sample_weight)\n        X          = array([[-0.36293708],\n       [ 0.53895184],\n       [-0.07048605],\n       [-0.38424253],\n       [-1.04139636],\n       [ 0.16331669],\n       [-0.96587166],\n       [ 1.49617496],\n       [ 1.88587438],\n       [-1.25938418]])\n        X_minus_idx = array([], shape=(10, 0), dtype=float64)\n        estimator  = LassoCV(n_jobs=1, random_state=RandomState(PCG64) at 0x7F4CF1E02340)\n        fit_y      = True\n        idx        = np.int64(0)\n        lasso_weights = None\n        model_distillation_x = LassoCV(n_alphas=10)\n        model_x    = LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4CF1E02A40)\n        random_state = Generator(PCG64) at 0x7F4CF1E81B60\n        sample_weight = None\n        sigma_X    = True\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:2191: in fit\n    return super().fit(X, y, sample_weight=sample_weight, **params)\n        X          = array([], shape=(10, 0), dtype=float64)\n        __class__  = &amp;lt;class &amp;#x27;sklearn.linear_model._coordinate_descent.LassoCV&amp;#x27;&amp;gt;\n        params     = {}\n        sample_weight = None\n        self       = LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4CF1E02A40)\n        y          = array([-0.36293708,  0.53895184, -0.07048605, -0.38424253, -1.04139636,\n        0.16331669, -0.96587166,  1.49617496,  1.88587438, -1.25938418])\n.venv/lib/python3.10/site-packages/sklearn/base.py:1365: in wrapper\n    return fit_method(estimator, *args, **kwargs)\n        args       = (array([], shape=(10, 0), dtype=float64), array([-0.36293708,  0.53895184, -0.07048605, -0.38424253, -1.04139636,\n        0.16331669, -0.96587166,  1.49617496,  1.88587438, -1.25938418]))\n        estimator  = LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4CF1E02A40)\n        fit_method = &amp;lt;function LinearModelCV.fit at 0x7f4cfe8fc4c0&amp;gt;\n        global_skip_validation = False\n        kwargs     = {&amp;#x27;sample_weight&amp;#x27;: None}\n        partial_fit_and_fitted = False\n        prefer_skip_nested_validation = True\n.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:1677: in fit\n    X, y = validate_data(\n        X          = array([], shape=(10, 0), dtype=float64)\n        check_X_params = {&amp;#x27;accept_large_sparse&amp;#x27;: False, &amp;#x27;accept_sparse&amp;#x27;: &amp;#x27;csc&amp;#x27;, &amp;#x27;copy&amp;#x27;: False, &amp;#x27;dtype&amp;#x27;: [&amp;lt;class &amp;#x27;numpy.float64&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.float32&amp;#x27;&amp;gt;], ...}\n        check_y_params = {&amp;#x27;copy&amp;#x27;: False, &amp;#x27;dtype&amp;#x27;: [&amp;lt;class &amp;#x27;numpy.float64&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.float32&amp;#x27;&amp;gt;], &amp;#x27;ensure_2d&amp;#x27;: False}\n        copy_X     = True\n        params     = {}\n        reference_to_old_X = array([], shape=(10, 0), dtype=float64)\n        sample_weight = None\n        self       = LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4CF1E02A40)\n        y          = array([-0.36293708,  0.53895184, -0.07048605, -0.38424253, -1.04139636,\n        0.16331669, -0.96587166,  1.49617496,  1.88587438, -1.25938418])\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2966: in validate_data\n    X = check_array(X, input_name=&amp;quot;X&amp;quot;, **check_X_params)\n        X          = array([], shape=(10, 0), dtype=float64)\n        _estimator = LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4CF1E02A40)\n        check_X_params = {&amp;#x27;accept_large_sparse&amp;#x27;: False, &amp;#x27;accept_sparse&amp;#x27;: &amp;#x27;csc&amp;#x27;, &amp;#x27;copy&amp;#x27;: False, &amp;#x27;dtype&amp;#x27;: [&amp;lt;class &amp;#x27;numpy.float64&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.float32&amp;#x27;&amp;gt;], ...}\n        check_params = {&amp;#x27;estimator&amp;#x27;: LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4CF1E02A40)}\n        check_y_params = {&amp;#x27;copy&amp;#x27;: False, &amp;#x27;dtype&amp;#x27;: [&amp;lt;class &amp;#x27;numpy.float64&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.float32&amp;#x27;&amp;gt;], &amp;#x27;ensure_2d&amp;#x27;: False}\n        default_check_params = {&amp;#x27;estimator&amp;#x27;: LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4CF1E02A40)}\n        no_val_X   = False\n        no_val_y   = False\n        reset      = True\n        skip_check_array = False\n        tags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        validate_separately = ({&amp;#x27;accept_large_sparse&amp;#x27;: False, &amp;#x27;accept_sparse&amp;#x27;: &amp;#x27;csc&amp;#x27;, &amp;#x27;copy&amp;#x27;: False, &amp;#x27;dtype&amp;#x27;: [&amp;lt;class &amp;#x27;numpy.float64&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.float32&amp;#x27;&amp;gt;], ...}, {&amp;#x27;copy&amp;#x27;: False, &amp;#x27;dtype&amp;#x27;: [&amp;lt;class &amp;#x27;numpy.float64&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.float32&amp;#x27;&amp;gt;], &amp;#x27;ensure_2d&amp;#x27;: False})\n        y          = array([-0.36293708,  0.53895184, -0.07048605, -0.38424253, -1.04139636,\n        0.16331669, -0.96587166,  1.49617496,  1.88587438, -1.25938418])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\narray = array([], shape=(10, 0), dtype=float64), accept_sparse = &amp;#x27;csc&amp;#x27;\n\n    def check_array(\n        array,\n        accept_sparse=False,\n        *,\n        accept_large_sparse=True,\n        dtype=&amp;quot;numeric&amp;quot;,\n        order=None,\n        copy=False,\n        force_writeable=False,\n        force_all_finite=&amp;quot;deprecated&amp;quot;,\n        ensure_all_finite=None,\n        ensure_non_negative=False,\n        ensure_2d=True,\n        allow_nd=False,\n        ensure_min_samples=1,\n        ensure_min_features=1,\n        estimator=None,\n        input_name=&amp;quot;&amp;quot;,\n    ):\n        &amp;quot;&amp;quot;&amp;quot;Input validation on an array, list, sparse matrix or similar.\n    \n        By default, the input is checked to be a non-empty 2D array containing\n        only finite values. If the dtype of the array is object, attempt\n        converting to float, raising on failure.\n    \n        Parameters\n        ----------\n        array : object\n            Input object to check / convert.\n    \n        accept_sparse : str, bool or list/tuple of str, default=False\n            String[s] representing allowed sparse matrix formats, such as &amp;#x27;csc&amp;#x27;,\n            &amp;#x27;csr&amp;#x27;, etc. If the input is sparse but not in the allowed format,\n            it will be converted to the first listed format. True allows the input\n            to be any format. False means that a sparse matrix input will\n            raise an error.\n    \n        accept_large_sparse : bool, default=True\n            If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\n            accept_sparse, accept_large_sparse=False will cause it to be accepted\n            only if its indices are stored with a 32-bit dtype.\n    \n            .. versionadded:: 0.20\n    \n        dtype : &amp;#x27;numeric&amp;#x27;, type, list of type or None, default=&amp;#x27;numeric&amp;#x27;\n            Data type of result. If None, the dtype of the input is preserved.\n            If &amp;quot;numeric&amp;quot;, dtype is preserved unless array.dtype is object.\n            If dtype is a list of types, conversion on the first type is only\n            performed if the dtype of the input is not in the list.\n    \n        order : {&amp;#x27;F&amp;#x27;, &amp;#x27;C&amp;#x27;} or None, default=None\n            Whether an array will be forced to be fortran or c-style.\n            When order is None (default), then if copy=False, nothing is ensured\n            about the memory layout of the output array; otherwise (copy=True)\n            the memory layout of the returned array is kept as close as possible\n            to the original array.\n    \n        copy : bool, default=False\n            Whether a forced copy will be triggered. If copy=False, a copy might\n            be triggered by a conversion.\n    \n        force_writeable : bool, default=False\n            Whether to force the output array to be writeable. If True, the returned array\n            is guaranteed to be writeable, which may require a copy. Otherwise the\n            writeability of the input array is preserved.\n    \n            .. versionadded:: 1.6\n    \n        force_all_finite : bool or &amp;#x27;allow-nan&amp;#x27;, default=True\n            Whether to raise an error on np.inf, np.nan, pd.NA in array. The\n            possibilities are:\n    \n            - True: Force all values of array to be finite.\n            - False: accepts np.inf, np.nan, pd.NA in array.\n            - &amp;#x27;allow-nan&amp;#x27;: accepts only np.nan and pd.NA values in array. Values\n              cannot be infinite.\n    \n            .. versionadded:: 0.20\n               ``force_all_finite`` accepts the string ``&amp;#x27;allow-nan&amp;#x27;``.\n    \n            .. versionchanged:: 0.23\n               Accepts `pd.NA` and converts it into `np.nan`\n    \n            .. deprecated:: 1.6\n               `force_all_finite` was renamed to `ensure_all_finite` and will be removed\n               in 1.8.\n    \n        ensure_all_finite : bool or &amp;#x27;allow-nan&amp;#x27;, default=True\n            Whether to raise an error on np.inf, np.nan, pd.NA in array. The\n            possibilities are:\n    \n            - True: Force all values of array to be finite.\n            - False: accepts np.inf, np.nan, pd.NA in array.\n            - &amp;#x27;allow-nan&amp;#x27;: accepts only np.nan and pd.NA values in array. Values\n              cannot be infinite.\n    \n            .. versionadded:: 1.6\n               `force_all_finite` was renamed to `ensure_all_finite`.\n    \n        ensure_non_negative : bool, default=False\n            Make sure the array has only non-negative values. If True, an array that\n            contains negative values will raise a ValueError.\n    \n            .. versionadded:: 1.6\n    \n        ensure_2d : bool, default=True\n            Whether to raise a value error if array is not 2D.\n    \n        allow_nd : bool, default=False\n            Whether to allow array.ndim &amp;gt; 2.\n    \n        ensure_min_samples : int, default=1\n            Make sure that the array has a minimum number of samples in its first\n            axis (rows for a 2D array). Setting to 0 disables this check.\n    \n        ensure_min_features : int, default=1\n            Make sure that the 2D array has some minimum number of features\n            (columns). The default value of 1 rejects empty datasets.\n            This check is only enforced when the input data has effectively 2\n            dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0\n            disables this check.\n    \n        estimator : str or estimator instance, default=None\n            If passed, include the name of the estimator in warning messages.\n    \n        input_name : str, default=&amp;quot;&amp;quot;\n            The data name used to construct the error message. In particular\n            if `input_name` is &amp;quot;X&amp;quot; and the data has NaN values and\n            allow_nan is False, the error message will link to the imputer\n            documentation.\n    \n            .. versionadded:: 1.1.0\n    \n        Returns\n        -------\n        array_converted : object\n            The converted and validated array.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_array\n        &amp;gt;&amp;gt;&amp;gt; X = [[1, 2, 3], [4, 5, 6]]\n        &amp;gt;&amp;gt;&amp;gt; X_checked = check_array(X)\n        &amp;gt;&amp;gt;&amp;gt; X_checked\n        array([[1, 2, 3], [4, 5, 6]])\n        &amp;quot;&amp;quot;&amp;quot;\n        ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n    \n        if isinstance(array, np.matrix):\n            raise TypeError(\n                &amp;quot;np.matrix is not supported. Please convert to a numpy array with &amp;quot;\n                &amp;quot;np.asarray. For more information see: &amp;quot;\n                &amp;quot;https://numpy.org/doc/stable/reference/generated/numpy.matrix.html&amp;quot;\n            )\n    \n        xp, is_array_api_compliant = get_namespace(array)\n    \n        # store reference to original array to check if copy is needed when\n        # function returns\n        array_orig = array\n    \n        # store whether originally we wanted numeric dtype\n        dtype_numeric = isinstance(dtype, str) and dtype == &amp;quot;numeric&amp;quot;\n    \n        dtype_orig = getattr(array, &amp;quot;dtype&amp;quot;, None)\n        if not is_array_api_compliant and not hasattr(dtype_orig, &amp;quot;kind&amp;quot;):\n            # not a data type (e.g. a column named dtype in a pandas DataFrame)\n            dtype_orig = None\n    \n        # check if the object contains several dtypes (typically a pandas\n        # DataFrame), and store them. If not, store None.\n        dtypes_orig = None\n        pandas_requires_conversion = False\n        # track if we have a Series-like object to raise a better error message\n        type_if_series = None\n        if hasattr(array, &amp;quot;dtypes&amp;quot;) and hasattr(array.dtypes, &amp;quot;__array__&amp;quot;):\n            # throw warning if columns are sparse. If all columns are sparse, then\n            # array.sparse exists and sparsity will be preserved (later).\n            with suppress(ImportError):\n                from pandas import SparseDtype\n    \n                def is_sparse(dtype):\n                    return isinstance(dtype, SparseDtype)\n    \n                if not hasattr(array, &amp;quot;sparse&amp;quot;) and array.dtypes.apply(is_sparse).any():\n                    warnings.warn(\n                        &amp;quot;pandas.DataFrame with sparse columns found.&amp;quot;\n                        &amp;quot;It will be converted to a dense numpy array.&amp;quot;\n                    )\n    \n            dtypes_orig = list(array.dtypes)\n            pandas_requires_conversion = any(\n                _pandas_dtype_needs_early_conversion(i) for i in dtypes_orig\n            )\n            if all(isinstance(dtype_iter, np.dtype) for dtype_iter in dtypes_orig):\n                dtype_orig = np.result_type(*dtypes_orig)\n            elif pandas_requires_conversion and any(d == object for d in dtypes_orig):\n                # Force object if any of the dtypes is an object\n                dtype_orig = object\n    \n        elif (_is_extension_array_dtype(array) or hasattr(array, &amp;quot;iloc&amp;quot;)) and hasattr(\n            array, &amp;quot;dtype&amp;quot;\n        ):\n            # array is a pandas series\n            type_if_series = type(array)\n            pandas_requires_conversion = _pandas_dtype_needs_early_conversion(array.dtype)\n            if isinstance(array.dtype, np.dtype):\n                dtype_orig = array.dtype\n            else:\n                # Set to None to let array.astype work out the best dtype\n                dtype_orig = None\n    \n        if dtype_numeric:\n            if (\n                dtype_orig is not None\n                and hasattr(dtype_orig, &amp;quot;kind&amp;quot;)\n                and dtype_orig.kind == &amp;quot;O&amp;quot;\n            ):\n                # if input is object, convert to float.\n                dtype = xp.float64\n            else:\n                dtype = None\n    \n        if isinstance(dtype, (list, tuple)):\n            if dtype_orig is not None and dtype_orig in dtype:\n                # no dtype conversion required\n                dtype = None\n            else:\n                # dtype conversion required. Let&amp;#x27;s select the first element of the\n                # list of accepted types.\n                dtype = dtype[0]\n    \n        if pandas_requires_conversion:\n            # pandas dataframe requires conversion earlier to handle extension dtypes with\n            # nans\n            # Use the original dtype for conversion if dtype is None\n            new_dtype = dtype_orig if dtype is None else dtype\n            array = array.astype(new_dtype)\n            # Since we converted here, we do not need to convert again later\n            dtype = None\n    \n        if ensure_all_finite not in (True, False, &amp;quot;allow-nan&amp;quot;):\n            raise ValueError(\n                &amp;quot;ensure_all_finite should be a bool or &amp;#x27;allow-nan&amp;#x27;. Got &amp;quot;\n                f&amp;quot;{ensure_all_finite!r} instead.&amp;quot;\n            )\n    \n        if dtype is not None and _is_numpy_namespace(xp):\n            # convert to dtype object to conform to Array API to be use `xp.isdtype` later\n            dtype = np.dtype(dtype)\n    \n        estimator_name = _check_estimator_name(estimator)\n        context = &amp;quot; by %s&amp;quot; % estimator_name if estimator is not None else &amp;quot;&amp;quot;\n    \n        # When all dataframe columns are sparse, convert to a sparse array\n        if hasattr(array, &amp;quot;sparse&amp;quot;) and array.ndim &amp;gt; 1:\n            with suppress(ImportError):\n                from pandas import SparseDtype\n    \n                def is_sparse(dtype):\n                    return isinstance(dtype, SparseDtype)\n    \n                if array.dtypes.apply(is_sparse).all():\n                    # DataFrame.sparse only supports `to_coo`\n                    array = array.sparse.to_coo()\n                    if array.dtype == np.dtype(&amp;quot;object&amp;quot;):\n                        unique_dtypes = set([dt.subtype.name for dt in array_orig.dtypes])\n                        if len(unique_dtypes) &amp;gt; 1:\n                            raise ValueError(\n                                &amp;quot;Pandas DataFrame with mixed sparse extension arrays &amp;quot;\n                                &amp;quot;generated a sparse matrix with object dtype which &amp;quot;\n                                &amp;quot;can not be converted to a scipy sparse matrix.&amp;quot;\n                                &amp;quot;Sparse extension arrays should all have the same &amp;quot;\n                                &amp;quot;numeric type.&amp;quot;\n                            )\n    \n        if sp.issparse(array):\n            _ensure_no_complex_data(array)\n            array = _ensure_sparse_format(\n                array,\n                accept_sparse=accept_sparse,\n                dtype=dtype,\n                copy=copy,\n                ensure_all_finite=ensure_all_finite,\n                accept_large_sparse=accept_large_sparse,\n                estimator_name=estimator_name,\n                input_name=input_name,\n            )\n            if ensure_2d and array.ndim &amp;lt; 2:\n                raise ValueError(\n                    f&amp;quot;Expected 2D input, got input with shape {array.shape}.\\n&amp;quot;\n                    &amp;quot;Reshape your data either using array.reshape(-1, 1) if &amp;quot;\n                    &amp;quot;your data has a single feature or array.reshape(1, -1) &amp;quot;\n                    &amp;quot;if it contains a single sample.&amp;quot;\n                )\n        else:\n            # If np.array(..) gives ComplexWarning, then we convert the warning\n            # to an error. This is needed because specifying a non complex\n            # dtype to the function converts complex to real dtype,\n            # thereby passing the test made in the lines following the scope\n            # of warnings context manager.\n            with warnings.catch_warnings():\n                try:\n                    warnings.simplefilter(&amp;quot;error&amp;quot;, ComplexWarning)\n                    if dtype is not None and xp.isdtype(dtype, &amp;quot;integral&amp;quot;):\n                        # Conversion float -&amp;gt; int should not contain NaN or\n                        # inf (numpy#14412). We cannot use casting=&amp;#x27;safe&amp;#x27; because\n                        # then conversion float -&amp;gt; int would be disallowed.\n                        array = _asarray_with_order(array, order=order, xp=xp)\n                        if xp.isdtype(array.dtype, (&amp;quot;real floating&amp;quot;, &amp;quot;complex floating&amp;quot;)):\n                            _assert_all_finite(\n                                array,\n                                allow_nan=False,\n                                msg_dtype=dtype,\n                                estimator_name=estimator_name,\n                                input_name=input_name,\n                            )\n                        array = xp.astype(array, dtype, copy=False)\n                    else:\n                        array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n                except ComplexWarning as complex_warning:\n                    raise ValueError(\n                        &amp;quot;Complex data not supported\\n{}\\n&amp;quot;.format(array)\n                    ) from complex_warning\n    \n            # It is possible that the np.array(..) gave no warning. This happens\n            # when no dtype conversion happened, for example dtype = None. The\n            # result is that np.array(..) produces an array of complex dtype\n            # and we need to catch and raise exception for such cases.\n            _ensure_no_complex_data(array)\n    \n            if ensure_2d:\n                # If input is scalar raise error\n                if array.ndim == 0:\n                    raise ValueError(\n                        &amp;quot;Expected 2D array, got scalar array instead:\\narray={}.\\n&amp;quot;\n                        &amp;quot;Reshape your data either using array.reshape(-1, 1) if &amp;quot;\n                        &amp;quot;your data has a single feature or array.reshape(1, -1) &amp;quot;\n                        &amp;quot;if it contains a single sample.&amp;quot;.format(array)\n                    )\n                # If input is 1D raise error\n                if array.ndim == 1:\n                    # If input is a Series-like object (eg. pandas Series or polars Series)\n                    if type_if_series is not None:\n                        msg = (\n                            f&amp;quot;Expected a 2-dimensional container but got {type_if_series} &amp;quot;\n                            &amp;quot;instead. Pass a DataFrame containing a single row (i.e. &amp;quot;\n                            &amp;quot;single sample) or a single column (i.e. single feature) &amp;quot;\n                            &amp;quot;instead.&amp;quot;\n                        )\n                    else:\n                        msg = (\n                            f&amp;quot;Expected 2D array, got 1D array instead:\\narray={array}.\\n&amp;quot;\n                            &amp;quot;Reshape your data either using array.reshape(-1, 1) if &amp;quot;\n                            &amp;quot;your data has a single feature or array.reshape(1, -1) &amp;quot;\n                            &amp;quot;if it contains a single sample.&amp;quot;\n                        )\n                    raise ValueError(msg)\n    \n            if dtype_numeric and hasattr(array.dtype, &amp;quot;kind&amp;quot;) and array.dtype.kind in &amp;quot;USV&amp;quot;:\n                raise ValueError(\n                    &amp;quot;dtype=&amp;#x27;numeric&amp;#x27; is not compatible with arrays of bytes/strings.&amp;quot;\n                    &amp;quot;Convert your data to numeric values explicitly instead.&amp;quot;\n                )\n            if not allow_nd and array.ndim &amp;gt;= 3:\n                raise ValueError(\n                    f&amp;quot;Found array with dim {array.ndim},&amp;quot;\n                    f&amp;quot; while dim &amp;lt;= 2 is required{context}.&amp;quot;\n                )\n    \n            if ensure_all_finite:\n                _assert_all_finite(\n                    array,\n                    input_name=input_name,\n                    estimator_name=estimator_name,\n                    allow_nan=ensure_all_finite == &amp;quot;allow-nan&amp;quot;,\n                )\n    \n            if copy:\n                if _is_numpy_namespace(xp):\n                    # only make a copy if `array` and `array_orig` may share memory`\n                    if np.may_share_memory(array, array_orig):\n                        array = _asarray_with_order(\n                            array, dtype=dtype, order=order, copy=True, xp=xp\n                        )\n                else:\n                    # always make a copy for non-numpy arrays\n                    array = _asarray_with_order(\n                        array, dtype=dtype, order=order, copy=True, xp=xp\n                    )\n    \n        if ensure_min_samples &amp;gt; 0:\n            n_samples = _num_samples(array)\n            if n_samples &amp;lt; ensure_min_samples:\n                raise ValueError(\n                    &amp;quot;Found array with %d sample(s) (shape=%s) while a&amp;quot;\n                    &amp;quot; minimum of %d is required%s.&amp;quot;\n                    % (n_samples, array.shape, ensure_min_samples, context)\n                )\n    \n        if ensure_min_features &amp;gt; 0 and array.ndim == 2:\n            n_features = array.shape[1]\n            if n_features &amp;lt; ensure_min_features:\n&amp;gt;               raise ValueError(\n                    &amp;quot;Found array with %d feature(s) (shape=%s) while&amp;quot;\n                    &amp;quot; a minimum of %d is required%s.&amp;quot;\n                    % (n_features, array.shape, ensure_min_features, context)\n                )\nE               ValueError: Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by LassoCV.\n\naccept_large_sparse = False\naccept_sparse = &amp;#x27;csc&amp;#x27;\nallow_nd   = False\narray      = array([], shape=(10, 0), dtype=float64)\narray_orig = array([], shape=(10, 0), dtype=float64)\ncontext    = &amp;#x27; by LassoCV&amp;#x27;\ncopy       = False\ndtype      = None\ndtype_numeric = False\ndtype_orig = dtype(&amp;#x27;float64&amp;#x27;)\ndtypes_orig = None\nensure_2d  = True\nensure_all_finite = True\nensure_min_features = 1\nensure_min_samples = 1\nensure_non_negative = False\nestimator  = LassoCV(n_alphas=10, random_state=RandomState(PCG64) at 0x7F4CF1E02A40)\nestimator_name = &amp;#x27;LassoCV&amp;#x27;\nforce_all_finite = &amp;#x27;deprecated&amp;#x27;\nforce_writeable = True\ninput_name = &amp;#x27;X&amp;#x27;\nis_array_api_compliant = False\nn_features = 0\nn_samples  = 10\norder      = None\npandas_requires_conversion = False\ntype_if_series = None\nxp         = &amp;lt;module &amp;#x27;sklearn.externals.array_api_compat.numpy&amp;#x27; from &amp;#x27;/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/externals/array_api_compat/numpy/__init__.py&amp;#x27;&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1137: ValueError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\ncheck = functools.partial(&amp;lt;function check_fit2d_1feature at 0x7f4cfd87a3b0&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit2d_1feature at 0x7f4cfd87a3b0&amp;gt;, &amp;#x27;D0CRT&amp;#x27;)\nestimator  = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n\ntest/test_distilled_conditional_randomization_test.py:73: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;D0CRT&amp;#x27;, D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None))\n        fn         = &amp;lt;function check_fit2d_1feature at 0x7f4cfd87a320&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1955: in check_fit2d_1feature\n    with raises(ValueError, match=msgs, may_pass=True):\n        X          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\n        estimator  = D0CRT(estimator=LassoCV(n_jobs=1,\n                        random_state=RandomState(PCG64) at 0x7F4CF1E02340),\n      la...ate(PCG64) at 0x7F4CF1E03640,\n                              tol=1e-06),\n      random_state=1, screening_threshold=None)\n        estimator_orig = D0CRT(estimator=LassoCV(n_jobs=1), screening_threshold=None)\n        msgs       = [&amp;#x27;1 feature\\\\(s\\\\)&amp;#x27;, &amp;#x27;n_features = 1&amp;#x27;, &amp;#x27;n_features=1&amp;#x27;]\n        name       = &amp;#x27;D0CRT&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7F4CF1E00240\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cf15a1f00&amp;gt;\nexc_type = &amp;lt;class &amp;#x27;ValueError&amp;#x27;&amp;gt;\nexc_value = ValueError(&amp;#x27;Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by LassoCV.&amp;#x27;)\n_ = &amp;lt;traceback object at 0x7f4cf1c23a00&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f&amp;quot;Did not raise: {self.expected_exc_types}&amp;quot;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n                raise AssertionError(self.err_msg) from exc_value\n            else:\n                return False  # will re-raise the original exception\n    \n        if self.matches is not None:\n            err_msg = self.err_msg or (\n                &amp;quot;The error message should contain one of the following &amp;quot;\n                &amp;quot;patterns:\\n{}\\nGot {}&amp;quot;.format(&amp;quot;\\n&amp;quot;.join(self.matches), str(exc_value))\n            )\n            if not any(re.search(match, str(exc_value)) for match in self.matches):\n&amp;gt;               raise AssertionError(err_msg) from exc_value\nE               AssertionError: The error message should contain one of the following patterns:\nE               1 feature\\(s\\)\nE               n_features = 1\nE               n_features=1\nE               Got Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by LassoCV.\n\n_          = &amp;lt;traceback object at 0x7f4cf1c23a00&amp;gt;\nerr_msg    = &amp;#x27;The error message should contain one of the following patterns:\\n1 feature\\\\(s\\\\)\\nn_features = 1\\nn_features=1\\nGot Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by LassoCV.&amp;#x27;\nexc_type   = &amp;lt;class &amp;#x27;ValueError&amp;#x27;&amp;gt;\nexc_value  = ValueError(&amp;#x27;Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by LassoCV.&amp;#x27;)\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7f4cf15a1f00&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:1155: AssertionError\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_exception_not_fitted&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_exception_not_fitted&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_exception_not_fitted&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_refit&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_refit&#34;, &#34;duration&#34;: &#34;102 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_refit&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;102 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_tags_renamed]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_tags_renamed]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_tags_renamed]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_valid_tag_types]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_valid_tag_types]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_valid_tag_types]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_methods_subset_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_methods_subset_invariance]&#34;, &#34;duration&#34;: &#34;188 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_methods_subset_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;188 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features]&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_linear_data_partial[default_cfi-HiDim with correlated features]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_group[high dimension]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_group[high dimension]&#34;, &#34;duration&#34;: &#34;38 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_group[high dimension]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;38 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_positive_only_tag_during_fit]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_positive_only_tag_during_fit]&#34;, &#34;duration&#34;: &#34;244 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_positive_only_tag_during_fit]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;244 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit2d_1sample]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit2d_1sample]&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_fit2d_1sample]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_invalid_lasso_screening&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_invalid_lasso_screening&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_invalid_lasso_screening&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim with correlated noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim with correlated noise]&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_linear_data_exact[default_cfi-HiDim with correlated noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_reproducibility_with_integer&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_reproducibility_with_integer&#34;, &#34;duration&#34;: &#34;143 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_reproducibility_with_integer&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;143 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_reproducibility_with_rng&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_reproducibility_with_rng&#34;, &#34;duration&#34;: &#34;180 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_reproducibility_with_rng&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;180 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_plot[10 features]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_plot[10 features]&#34;, &#34;duration&#34;: &#34;136 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_plot[10 features]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;136 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_repeatibility&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_repeatibility&#34;, &#34;duration&#34;: &#34;70 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_repeatibility&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;70 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_randomness_with_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_randomness_with_none&#34;, &#34;duration&#34;: &#34;143 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_randomness_with_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;143 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_plot_2d_imp[5_features]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_plot_2d_imp[5_features]&#34;, &#34;duration&#34;: &#34;139 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_plot_2d_imp[5_features]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;139 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_screening&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_screening&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_screening&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_refit&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_refit&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_refit&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_get_params_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_get_params_invariance]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_get_params_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_repr]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_repr]&#34;, &#34;duration&#34;: &#34;8 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_repr]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;8 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_empty_data_messages]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_empty_data_messages]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_empty_data_messages]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_cloneable0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_cloneable0]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_cloneable0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_function_cfi[default_cfi-high level noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_function_cfi[default_cfi-high level noise]&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_function_cfi[default_cfi-high level noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_plot_coverage[10-3-1-0.2-0-1.0-1.0-0.0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_plot_coverage[10-3-1-0.2-0-1.0-1.0-0.0]&#34;, &#34;duration&#34;: &#34;152 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_plot_coverage[10-3-1-0.2-0-1.0-1.0-0.0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;152 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_conditional_feature_importance.py::test_cfi_cv[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_conditional_feature_importance.py::test_cfi_cv[default data]&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_conditional_feature_importance.py::test_cfi_cv[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting importance estimators for each fold:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting importance estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 123.65it/s]\n\rComputing importance scores over folds:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importance scores over folds: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 1755.67it/s]\n&#34;}], &#34;test/_utils/test_utils.py::test_rng&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_rng&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_rng&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_error&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_error&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_generated_attributes&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_generated_attributes&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_generated_attributes&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_integer&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_integer&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_integer&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_check_test_statistic&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_check_test_statistic&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_check_test_statistic&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_random_state&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_random_state&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_random_state&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_none&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_utils.py::test_check_test_statistic_warning&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_utils.py::test_check_test_statistic_warning&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_utils.py::test_check_test_statistic_warning&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_aggregation.py::test_quantile_aggregation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_aggregation.py::test_quantile_aggregation&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_aggregation.py::test_quantile_aggregation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_aggregation.py::test_fixed_aggregate_quantiles&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_aggregation.py::test_fixed_aggregate_quantiles&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_aggregation.py::test_fixed_aggregate_quantiles&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_aggregation.py::test_adaptive_quantiles&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_aggregation.py::test_adaptive_quantiles&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_aggregation.py::test_adaptive_quantiles&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_error_no_model_provide&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_error_no_model_provide&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_error_no_model_provide&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/samplers/test_conditional_sampling.py::test_error_no_predic_proba&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/samplers/test_conditional_sampling.py::test_error_no_predic_proba&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/samplers/test_conditional_sampling.py::test_error_no_predic_proba&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_rho&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_rho&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_ar_rho&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[basic_correlation]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[basic_correlation]&#34;, &#34;duration&#34;: &#34;68 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_all[basic_correlation]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;68 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_support_size&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_support_size&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_ar_support_size&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[no_correlation_with_shuffle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[no_correlation_with_shuffle]&#34;, &#34;duration&#34;: &#34;53 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_all[no_correlation_with_shuffle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;53 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_reproducibility&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_reproducibility&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_reproducibility&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_snr&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_snr&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_ar_snr&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_samples&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_samples&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_samples&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_no_shuffle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_no_shuffle]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_no_shuffle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_zero_signal_noise_ratio&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_zero_signal_noise_ratio&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_zero_signal_noise_ratio&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_weights_2D&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_weights_2D&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_weights_2D&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_correlation]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_correlation]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_correlation]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[no noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[no noise]&#34;, &#34;duration&#34;: &#34;8 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_2D[no noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;8 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_weights_3D&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_weights_3D&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_weights_3D&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_target&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_target&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_target&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_2D&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_2D&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_2D&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[basic case]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[basic case]&#34;, &#34;duration&#34;: &#34;8 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_2D[basic case]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;8 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_3D&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_3D&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_3D&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[no roi]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[no roi]&#34;, &#34;duration&#34;: &#34;8 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_2D[no roi]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;8 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_empirical_snr&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_empirical_snr&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_empirical_snr&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_3D&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_3D&#34;, &#34;duration&#34;: &#34;13 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_3D&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;13 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_with_shuffle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_with_shuffle]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_all[temporal_with_shuffle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_roi_full&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_roi_full&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_edge_cases_roi_full&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_invalid&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_invalid&#34;, &#34;duration&#34;: &#34;18 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_invalid&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;18 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_empirical_snr_2&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_empirical_snr_2&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_empirical_snr_2&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[no_correlation]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_all[no_correlation]&#34;, &#34;duration&#34;: &#34;52 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_all[no_correlation]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;52 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_rho_noise&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_rho_noise&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_ar_rho_noise&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_features&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_features&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_ar_n_features&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_zero_support&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_zero_support&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_zero_support&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_warning_not_used_parameters&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_warning_not_used_parameters&#34;, &#34;duration&#34;: &#34;00:00:06&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_warning_not_used_parameters&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:06&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_pickle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_pickle]&#34;, &#34;duration&#34;: &#34;191 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_pickle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;191 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_covariance&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_covariance&#34;, &#34;duration&#34;: &#34;851 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_lasso_with_covariance&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;851 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_cloneable1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_cloneable1]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimator_cloneable1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_complex_data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_complex_data]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_complex_data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit_refit&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit_refit&#34;, &#34;duration&#34;: &#34;135 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_dcrt_logit_refit&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;135 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_pickle(readonly_memmap=True)]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_pickle(readonly_memmap=True)]&#34;, &#34;duration&#34;: &#34;203 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_distilled_conditional_randomization_test.py::test_check_estimator_sklearn[D0CRT(estimator=LassoCV(n_jobs=1),screening_threshold=None)-check_estimators_pickle(readonly_memmap=True)]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;203 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_leave_one_covariate_out.py::test_loco_function&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_leave_one_covariate_out.py::test_loco_function&#34;, &#34;duration&#34;: &#34;274 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_leave_one_covariate_out.py::test_loco_function&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;274 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_leave_one_covariate_out.py::test_loco_cv[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_leave_one_covariate_out.py::test_loco_cv[default data]&#34;, &#34;duration&#34;: &#34;396 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_leave_one_covariate_out.py::test_loco_cv[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;396 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 3885.05it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting importance estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 3949.44it/s]\n\rComputing importance scores over folds:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importance scores over folds: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 3597.79it/s]\n&#34;}], &#34;test/test_leave_one_covariate_out.py::test_raises_value_error&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_leave_one_covariate_out.py::test_raises_value_error&#34;, &#34;duration&#34;: &#34;907 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_leave_one_covariate_out.py::test_raises_value_error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;907 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_leave_one_covariate_out.py::test_loco&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_leave_one_covariate_out.py::test_loco&#34;, &#34;duration&#34;: &#34;710 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_leave_one_covariate_out.py::test_loco&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;710 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_version.py::test_version&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_version.py::test_version&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_version.py::test_version&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_zscore_from_cb&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_zscore_from_cb&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_zscore_from_cb&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_cb&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_cb&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_cb&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_zscore&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_zscore&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_zscore&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_pval&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_pval&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_two_sided_pval_from_pval&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_pval_from_scale&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_pval_from_scale&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_pval_from_scale&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test__replace_infinity&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test__replace_infinity&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test__replace_infinity&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_zscore_from_pval&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_zscore_from_pval&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_zscore_from_pval&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_pval_corr_from_pval&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_pval_corr_from_pval&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_pval_corr_from_pval&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_pval_from_two_sided_pval_and_sign&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_pval_from_two_sided_pval_and_sign&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_pval_from_two_sided_pval_and_sign&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_p_values.py::test_pval_from_cb&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_p_values.py::test_pval_from_cb&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_p_values.py::test_pval_from_cb&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_minimal&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_minimal&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_minimal&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[only noise]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_scenario.py::test_multivariate_simulation_2D[only noise]&#34;, &#34;duration&#34;: &#34;8 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_scenario.py::test_multivariate_simulation_2D[only noise]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;8 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_nan_inf]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_nan_inf]&#34;, &#34;duration&#34;: &#34;92 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_nan_inf]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;92 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_get_params_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_get_params_invariance]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_get_params_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_n_features_in]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_n_features_in]&#34;, &#34;duration&#34;: &#34;46 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_n_features_in]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;46 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = DesparsifiedLasso(confidence=0.9, random_state=0)\ncheck = functools.partial(&amp;lt;function check_n_features_in at 0x7f4cfd8865f0&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_n_features_in at 0x7f4cfd8865f0&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\n\ntest/test_desparsified_lasso.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;DesparsifiedLasso&amp;#x27;\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n\n    def check_n_features_in(name, estimator_orig):\n        # Make sure that n_features_in_ attribute doesn&amp;#x27;t exist until fit is\n        # called, and that its value is correct.\n    \n        rng = np.random.RandomState(0)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if &amp;quot;warm_start&amp;quot; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        assert not hasattr(estimator, &amp;quot;n_features_in_&amp;quot;)\n        estimator.fit(X, y)\n&amp;gt;       assert hasattr(estimator, &amp;quot;n_features_in_&amp;quot;)\nE       AssertionError\n\nX          = array([[101.76405235, 100.40015721],\n       [100.97873798, 102.2408932 ],\n       [101.86755799,  99.02272212],\n       ...9065 ],\n       [100.52327666,  99.82845367],\n       [100.77179055, 100.82350415],\n       [102.16323595, 101.33652795]])\nestimator  = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7F4CF1E03940),\n                  random_state=0)\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\nn_samples  = 100\nname       = &amp;#x27;DesparsifiedLasso&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4D0226FC40\ny          = array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,...1,\n       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4384: AssertionError\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_set_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_set_params]&#34;, &#34;duration&#34;: &#34;26 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_set_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;26 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_function_not_center&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_function_not_center&#34;, &#34;duration&#34;: &#34;76 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_function_not_center&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;76 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_no_attributes_set_in_init]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_no_attributes_set_in_init]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_no_attributes_set_in_init]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = DesparsifiedLasso(confidence=0.9, random_state=0)\ncheck = functools.partial(&amp;lt;function check_no_attributes_set_in_init at 0x7f4cfd8853f0&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_no_attributes_set_in_init at 0x7f4cfd8853f0&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\n\ntest/test_desparsified_lasso.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;DesparsifiedLasso&amp;#x27;, DesparsifiedLasso(confidence=0.9, random_state=0))\n        fn         = &amp;lt;function check_no_attributes_set_in_init at 0x7f4cfd885360&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;DesparsifiedLasso&amp;#x27;\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n\n    @ignore_warnings(category=FutureWarning)\n    def check_no_attributes_set_in_init(name, estimator_orig):\n        &amp;quot;&amp;quot;&amp;quot;Check setting during init.&amp;quot;&amp;quot;&amp;quot;\n        try:\n            # Clone fails if the estimator does not store\n            # all parameters as an attribute during init\n            estimator = clone(estimator_orig)\n        except AttributeError:\n            raise AttributeError(\n                f&amp;quot;Estimator {name} should store all parameters as an attribute during init.&amp;quot;\n            )\n    \n        if hasattr(type(estimator).__init__, &amp;quot;deprecated_original&amp;quot;):\n            return\n    \n        init_params = _get_args(type(estimator).__init__)\n        parents_init_params = [\n            param\n            for params_parent in (_get_args(parent) for parent in type(estimator).__mro__)\n            for param in params_parent\n        ]\n    \n        # Test for no setting apart from parameters during init\n        invalid_attr = set(vars(estimator)) - set(init_params) - set(parents_init_params)\n        # Ignore private attributes\n        invalid_attr = set([attr for attr in invalid_attr if not attr.startswith(&amp;quot;_&amp;quot;)])\n&amp;gt;       assert not invalid_attr, (\n            &amp;quot;Estimator %s should not set any attribute apart&amp;quot;\n            &amp;quot; from parameters during init. Found attributes %s.&amp;quot;\n            % (name, sorted(invalid_attr))\n        )\nE       AssertionError: Estimator DesparsifiedLasso should not set any attribute apart from parameters during init. Found attributes [&amp;#x27;clf_&amp;#x27;, &amp;#x27;confidence_bound_max_&amp;#x27;, &amp;#x27;confidence_bound_min_&amp;#x27;, &amp;#x27;n_samples_&amp;#x27;, &amp;#x27;n_task_&amp;#x27;, &amp;#x27;precision_diagonal_&amp;#x27;, &amp;#x27;pvalues_corr_&amp;#x27;, &amp;#x27;sigma_hat_&amp;#x27;].\n\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\ninit_params = [&amp;#x27;self&amp;#x27;, &amp;#x27;estimator&amp;#x27;, &amp;#x27;centered&amp;#x27;, &amp;#x27;dof_ajdustement&amp;#x27;, &amp;#x27;model_x&amp;#x27;, &amp;#x27;preconfigure_model_x_path&amp;#x27;, ...]\ninvalid_attr = {&amp;#x27;clf_&amp;#x27;, &amp;#x27;confidence_bound_max_&amp;#x27;, &amp;#x27;confidence_bound_min_&amp;#x27;, &amp;#x27;n_samples_&amp;#x27;, &amp;#x27;n_task_&amp;#x27;, &amp;#x27;precision_diagonal_&amp;#x27;, ...}\nname       = &amp;#x27;DesparsifiedLasso&amp;#x27;\nparents_init_params = [&amp;#x27;estimator&amp;#x27;, &amp;#x27;centered&amp;#x27;, &amp;#x27;dof_ajdustement&amp;#x27;, &amp;#x27;model_x&amp;#x27;, &amp;#x27;preconfigure_model_x_path&amp;#x27;, &amp;#x27;alpha_max_fraction&amp;#x27;, ...]\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3654: AssertionError\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_cloneable1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_cloneable1]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_cloneable1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_empty_data_messages]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_empty_data_messages]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_empty_data_messages]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_sparse_array]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_sparse_array]&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_sparse_array]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_pickle]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_pickle]&#34;, &#34;duration&#34;: &#34;47 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_pickle]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;47 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_dl_repeatibility&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_dl_repeatibility&#34;, &#34;duration&#34;: &#34;550 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_dl_repeatibility&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;550 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_methods_subset_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_methods_subset_invariance]&#34;, &#34;duration&#34;: &#34;47 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_methods_subset_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;47 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_cloneable0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_cloneable0]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_cloneable0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_permutation_feature_importance.py::test_permutation_importance&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_permutation_feature_importance.py::test_permutation_importance&#34;, &#34;duration&#34;: &#34;00:00:06&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_permutation_feature_importance.py::test_permutation_importance&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:06&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_permutation_feature_importance.py::test_pfi_randomness_with_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_permutation_feature_importance.py::test_pfi_randomness_with_none&#34;, &#34;duration&#34;: &#34;126 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_permutation_feature_importance.py::test_pfi_randomness_with_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;126 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_dl_reproducibility_with_rng&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_dl_reproducibility_with_rng&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_dl_reproducibility_with_rng&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit2d_predict1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit2d_predict1d]&#34;, &#34;duration&#34;: &#34;48 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit2d_predict1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;48 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_methods_sample_order_invariance]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_methods_sample_order_invariance]&#34;, &#34;duration&#34;: &#34;47 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_methods_sample_order_invariance]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;47 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_permutation_feature_importance.py::test_pfi_cv[default data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_permutation_feature_importance.py::test_pfi_cv[default data]&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_permutation_feature_importance.py::test_pfi_cv[default data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stderr call -----------------------------\n\rFitting estimators for each fold:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting estimators for each fold:  20%|\u2588\u2588        | 1/5 [00:00&amp;lt;00:01,  2.26it/s]\rFitting estimators for each fold:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&amp;lt;00:00,  3.66it/s]\rFitting estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&amp;lt;00:00,  4.37it/s]\n\rFitting importance estimators for each fold:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rFitting importance estimators for each fold: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 79.75it/s]\n\rComputing importance scores over folds:   0%|          | 0/5 [00:00&amp;lt;?, ?it/s]\rComputing importance scores over folds:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:00&amp;lt;00:00, 11.49it/s]\rComputing importance scores over folds: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&amp;lt;00:00, 14.25it/s]\n&#34;}], &#34;test/test_permutation_feature_importance.py::test_pfi_reproducibility_with_integer&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_permutation_feature_importance.py::test_pfi_reproducibility_with_integer&#34;, &#34;duration&#34;: &#34;70 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_permutation_feature_importance.py::test_pfi_reproducibility_with_integer&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;70 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_permutation_feature_importance.py::test_permutation_importance_function&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_permutation_feature_importance.py::test_permutation_importance_function&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_permutation_feature_importance.py::test_permutation_importance_function&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_permutation_feature_importance.py::test_pfi_repeatability&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_permutation_feature_importance.py::test_pfi_repeatability&#34;, &#34;duration&#34;: &#34;62 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_permutation_feature_importance.py::test_pfi_repeatability&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;62 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_permutation_feature_importance.py::test_pfi_reproducibility_with_rng&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_permutation_feature_importance.py::test_pfi_reproducibility_with_rng&#34;, &#34;duration&#34;: &#34;94 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_permutation_feature_importance.py::test_pfi_reproducibility_with_rng&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;94 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_f_contiguous_array_estimator]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_f_contiguous_array_estimator]&#34;, &#34;duration&#34;: &#34;47 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_f_contiguous_array_estimator]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;47 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_exception&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_exception&#34;, &#34;duration&#34;: &#34;337 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_exception&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;337 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_valid_tag_types]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_valid_tag_types]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_valid_tag_types]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_desparsified_group_lasso&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_desparsified_group_lasso&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_desparsified_group_lasso&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\nUsing number of features for multiple testing correction.\nGroup reid: AR1 cov estimation\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit2d_1feature]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit2d_1feature]&#34;, &#34;duration&#34;: &#34;46 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit2d_1feature]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;46 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;DesparsifiedLasso&amp;#x27;\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n\n    @ignore_warnings\n    def check_fit2d_1feature(name, estimator_orig):\n        # check fitting a 2d array with only 1 feature either works or returns\n        # informative message\n        rnd = np.random.RandomState(0)\n        X = 3 * rnd.uniform(size=(10, 1))\n        X = _enforce_estimator_tags_X(estimator_orig, X)\n        y = X[:, 0].astype(int)\n        estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if hasattr(estimator, &amp;quot;n_components&amp;quot;):\n            estimator.n_components = 1\n        if hasattr(estimator, &amp;quot;n_clusters&amp;quot;):\n            estimator.n_clusters = 1\n        # ensure two labels in subsample for RandomizedLogisticRegression\n        if name == &amp;quot;RandomizedLogisticRegression&amp;quot;:\n            estimator.sample_fraction = 1\n        # ensure non skipped trials for RANSACRegressor\n        if name == &amp;quot;RANSACRegressor&amp;quot;:\n            estimator.residual_threshold = 0.5\n    \n        y = _enforce_estimator_tags_y(estimator, y)\n        set_random_state(estimator, 1)\n    \n        msgs = [r&amp;quot;1 feature\\(s\\)&amp;quot;, &amp;quot;n_features = 1&amp;quot;, &amp;quot;n_features=1&amp;quot;]\n    \n        with raises(ValueError, match=msgs, may_pass=True):\n&amp;gt;           estimator.fit(X, y)\n\nX          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\nestimator  = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7FF38EA01940),\n                  random_state=1)\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\nmsgs       = [&amp;#x27;1 feature\\\\(s\\\\)&amp;#x27;, &amp;#x27;n_features = 1&amp;#x27;, &amp;#x27;n_features=1&amp;#x27;]\nname       = &amp;#x27;DesparsifiedLasso&amp;#x27;\nrnd        = RandomState(MT19937) at 0x7FF38EA01640\ny          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1956: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/hidimstat/desparsified_lasso.py:271: in fit\n    results = Parallel(\n        X          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\n        X_         = array([[-0.20085834],\n       [ 0.29826925],\n       [-0.03900872],\n       [-0.2126493 ],\n       [-0.57633445],\n       [ 0.09038349],\n       [-0.53453722],\n       [ 0.82802015],\n       [ 1.04368943],\n       [-0.69697429]])\n        gram       = array([[3.0627888]])\n        list_model_x = [Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7FF38EA01A40)]\n        memory     = Memory(location=None)\n        n_features = 1\n        rng        = Generator(PCG64) at 0x7FF387F326C0\n        self       = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7FF38EA01940),\n                  random_state=1)\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n        y_         = array([-0.3,  0.7, -0.3, -0.3, -0.3, -0.3, -0.3,  0.7,  0.7, -0.3])\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1986: in __call__\n    return output if self.return_generator else list(output)\n        iterable   = &amp;lt;generator object DesparsifiedLasso.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7ff3860b6650&amp;gt;\n        n_jobs     = 1\n        output     = &amp;lt;generator object Parallel._get_sequential_output at 0x7ff3860b6f80&amp;gt;\n        self       = Parallel(n_jobs=1)\n.venv/lib/python3.10/site-packages/joblib/parallel.py:1914: in _get_sequential_output\n    res = func(*args, **kwargs)\n        args       = ()\n        batch_size = 1\n        func       = &amp;lt;function _joblib_compute_residuals at 0x7ff3892551b0&amp;gt;\n        iterable   = &amp;lt;generator object DesparsifiedLasso.fit.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x7ff3860b6650&amp;gt;\n        kwargs     = {&amp;#x27;X&amp;#x27;: array([[-0.20085834],\n       [ 0.29826925],\n       [-0.03900872],\n       [-0.2126493 ],\n       [-0.57633445],\n  ...=float64),\n      random_state=RandomState(PCG64) at 0x7FF38EA01A40), &amp;#x27;gram&amp;#x27;: array([[3.0627888]]), &amp;#x27;id_column&amp;#x27;: 0, ...}\n        self       = Parallel(n_jobs=1)\nsrc/hidimstat/desparsified_lasso.py:518: in _joblib_compute_residuals\n    clf.fit(X_minus_i, X_i)\n        X          = array([[-0.20085834],\n       [ 0.29826925],\n       [-0.03900872],\n       [-0.2126493 ],\n       [-0.57633445],\n       [ 0.09038349],\n       [-0.53453722],\n       [ 0.82802015],\n       [ 1.04368943],\n       [-0.69697429]])\n        X_i        = array([-0.20085834,  0.29826925, -0.03900872, -0.2126493 , -0.57633445,\n        0.09038349, -0.53453722,  0.82802015,  1.04368943, -0.69697429])\n        X_minus_i  = array([], shape=(10, 0), dtype=float64)\n        _          = 1\n        clf        = Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7FF38EA01A40)\n        gram       = array([[3.0627888]])\n        id_column  = 0\n        n_samples  = 10\n        return_clf = False\n.venv/lib/python3.10/site-packages/sklearn/base.py:1365: in wrapper\n    return fit_method(estimator, *args, **kwargs)\n        args       = (array([], shape=(10, 0), dtype=float64), array([-0.20085834,  0.29826925, -0.03900872, -0.2126493 , -0.57633445,\n        0.09038349, -0.53453722,  0.82802015,  1.04368943, -0.69697429]))\n        estimator  = Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7FF38EA01A40)\n        fit_method = &amp;lt;function ElasticNet.fit at 0x7ff38a233e20&amp;gt;\n        global_skip_validation = False\n        kwargs     = {}\n        partial_fit_and_fitted = False\n        prefer_skip_nested_validation = True\n.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:986: in fit\n    X, y = validate_data(\n        X          = array([], shape=(10, 0), dtype=float64)\n        X_copied   = True\n        check_input = True\n        sample_weight = None\n        self       = Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7FF38EA01A40)\n        y          = array([-0.20085834,  0.29826925, -0.03900872, -0.2126493 , -0.57633445,\n        0.09038349, -0.53453722,  0.82802015,  1.04368943, -0.69697429])\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2971: in validate_data\n    X, y = check_X_y(X, y, **check_params)\n        X          = array([], shape=(10, 0), dtype=float64)\n        _estimator = Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7FF38EA01A40)\n        check_params = {&amp;#x27;accept_large_sparse&amp;#x27;: False, &amp;#x27;accept_sparse&amp;#x27;: &amp;#x27;csc&amp;#x27;, &amp;#x27;copy&amp;#x27;: True, &amp;#x27;dtype&amp;#x27;: [&amp;lt;class &amp;#x27;numpy.float64&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.float32&amp;#x27;&amp;gt;], ...}\n        default_check_params = {&amp;#x27;estimator&amp;#x27;: Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7FF38EA01A40)}\n        no_val_X   = False\n        no_val_y   = False\n        reset      = True\n        skip_check_array = False\n        tags       = Tags(estimator_type=&amp;#x27;regressor&amp;#x27;, target_tags=TargetTags(required=True, one_d_labels=False, two_d_labels=False, positiv...False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n        validate_separately = False\n        y          = array([-0.20085834,  0.29826925, -0.03900872, -0.2126493 , -0.57633445,\n        0.09038349, -0.53453722,  0.82802015,  1.04368943, -0.69697429])\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1368: in check_X_y\n    X = check_array(\n        X          = array([], shape=(10, 0), dtype=float64)\n        accept_large_sparse = False\n        accept_sparse = &amp;#x27;csc&amp;#x27;\n        allow_nd   = False\n        copy       = True\n        dtype      = [&amp;lt;class &amp;#x27;numpy.float64&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.float32&amp;#x27;&amp;gt;]\n        ensure_2d  = True\n        ensure_all_finite = True\n        ensure_min_features = 1\n        ensure_min_samples = 1\n        estimator  = Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7FF38EA01A40)\n        force_all_finite = &amp;#x27;deprecated&amp;#x27;\n        force_writeable = True\n        multi_output = True\n        order      = &amp;#x27;F&amp;#x27;\n        y          = array([-0.20085834,  0.29826925, -0.03900872, -0.2126493 , -0.57633445,\n        0.09038349, -0.53453722,  0.82802015,  1.04368943, -0.69697429])\n        y_numeric  = True\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\narray = array([], shape=(10, 0), dtype=float64), accept_sparse = &amp;#x27;csc&amp;#x27;\n\n    def check_array(\n        array,\n        accept_sparse=False,\n        *,\n        accept_large_sparse=True,\n        dtype=&amp;quot;numeric&amp;quot;,\n        order=None,\n        copy=False,\n        force_writeable=False,\n        force_all_finite=&amp;quot;deprecated&amp;quot;,\n        ensure_all_finite=None,\n        ensure_non_negative=False,\n        ensure_2d=True,\n        allow_nd=False,\n        ensure_min_samples=1,\n        ensure_min_features=1,\n        estimator=None,\n        input_name=&amp;quot;&amp;quot;,\n    ):\n        &amp;quot;&amp;quot;&amp;quot;Input validation on an array, list, sparse matrix or similar.\n    \n        By default, the input is checked to be a non-empty 2D array containing\n        only finite values. If the dtype of the array is object, attempt\n        converting to float, raising on failure.\n    \n        Parameters\n        ----------\n        array : object\n            Input object to check / convert.\n    \n        accept_sparse : str, bool or list/tuple of str, default=False\n            String[s] representing allowed sparse matrix formats, such as &amp;#x27;csc&amp;#x27;,\n            &amp;#x27;csr&amp;#x27;, etc. If the input is sparse but not in the allowed format,\n            it will be converted to the first listed format. True allows the input\n            to be any format. False means that a sparse matrix input will\n            raise an error.\n    \n        accept_large_sparse : bool, default=True\n            If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\n            accept_sparse, accept_large_sparse=False will cause it to be accepted\n            only if its indices are stored with a 32-bit dtype.\n    \n            .. versionadded:: 0.20\n    \n        dtype : &amp;#x27;numeric&amp;#x27;, type, list of type or None, default=&amp;#x27;numeric&amp;#x27;\n            Data type of result. If None, the dtype of the input is preserved.\n            If &amp;quot;numeric&amp;quot;, dtype is preserved unless array.dtype is object.\n            If dtype is a list of types, conversion on the first type is only\n            performed if the dtype of the input is not in the list.\n    \n        order : {&amp;#x27;F&amp;#x27;, &amp;#x27;C&amp;#x27;} or None, default=None\n            Whether an array will be forced to be fortran or c-style.\n            When order is None (default), then if copy=False, nothing is ensured\n            about the memory layout of the output array; otherwise (copy=True)\n            the memory layout of the returned array is kept as close as possible\n            to the original array.\n    \n        copy : bool, default=False\n            Whether a forced copy will be triggered. If copy=False, a copy might\n            be triggered by a conversion.\n    \n        force_writeable : bool, default=False\n            Whether to force the output array to be writeable. If True, the returned array\n            is guaranteed to be writeable, which may require a copy. Otherwise the\n            writeability of the input array is preserved.\n    \n            .. versionadded:: 1.6\n    \n        force_all_finite : bool or &amp;#x27;allow-nan&amp;#x27;, default=True\n            Whether to raise an error on np.inf, np.nan, pd.NA in array. The\n            possibilities are:\n    \n            - True: Force all values of array to be finite.\n            - False: accepts np.inf, np.nan, pd.NA in array.\n            - &amp;#x27;allow-nan&amp;#x27;: accepts only np.nan and pd.NA values in array. Values\n              cannot be infinite.\n    \n            .. versionadded:: 0.20\n               ``force_all_finite`` accepts the string ``&amp;#x27;allow-nan&amp;#x27;``.\n    \n            .. versionchanged:: 0.23\n               Accepts `pd.NA` and converts it into `np.nan`\n    \n            .. deprecated:: 1.6\n               `force_all_finite` was renamed to `ensure_all_finite` and will be removed\n               in 1.8.\n    \n        ensure_all_finite : bool or &amp;#x27;allow-nan&amp;#x27;, default=True\n            Whether to raise an error on np.inf, np.nan, pd.NA in array. The\n            possibilities are:\n    \n            - True: Force all values of array to be finite.\n            - False: accepts np.inf, np.nan, pd.NA in array.\n            - &amp;#x27;allow-nan&amp;#x27;: accepts only np.nan and pd.NA values in array. Values\n              cannot be infinite.\n    \n            .. versionadded:: 1.6\n               `force_all_finite` was renamed to `ensure_all_finite`.\n    \n        ensure_non_negative : bool, default=False\n            Make sure the array has only non-negative values. If True, an array that\n            contains negative values will raise a ValueError.\n    \n            .. versionadded:: 1.6\n    \n        ensure_2d : bool, default=True\n            Whether to raise a value error if array is not 2D.\n    \n        allow_nd : bool, default=False\n            Whether to allow array.ndim &amp;gt; 2.\n    \n        ensure_min_samples : int, default=1\n            Make sure that the array has a minimum number of samples in its first\n            axis (rows for a 2D array). Setting to 0 disables this check.\n    \n        ensure_min_features : int, default=1\n            Make sure that the 2D array has some minimum number of features\n            (columns). The default value of 1 rejects empty datasets.\n            This check is only enforced when the input data has effectively 2\n            dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0\n            disables this check.\n    \n        estimator : str or estimator instance, default=None\n            If passed, include the name of the estimator in warning messages.\n    \n        input_name : str, default=&amp;quot;&amp;quot;\n            The data name used to construct the error message. In particular\n            if `input_name` is &amp;quot;X&amp;quot; and the data has NaN values and\n            allow_nan is False, the error message will link to the imputer\n            documentation.\n    \n            .. versionadded:: 1.1.0\n    \n        Returns\n        -------\n        array_converted : object\n            The converted and validated array.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_array\n        &amp;gt;&amp;gt;&amp;gt; X = [[1, 2, 3], [4, 5, 6]]\n        &amp;gt;&amp;gt;&amp;gt; X_checked = check_array(X)\n        &amp;gt;&amp;gt;&amp;gt; X_checked\n        array([[1, 2, 3], [4, 5, 6]])\n        &amp;quot;&amp;quot;&amp;quot;\n        ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n    \n        if isinstance(array, np.matrix):\n            raise TypeError(\n                &amp;quot;np.matrix is not supported. Please convert to a numpy array with &amp;quot;\n                &amp;quot;np.asarray. For more information see: &amp;quot;\n                &amp;quot;https://numpy.org/doc/stable/reference/generated/numpy.matrix.html&amp;quot;\n            )\n    \n        xp, is_array_api_compliant = get_namespace(array)\n    \n        # store reference to original array to check if copy is needed when\n        # function returns\n        array_orig = array\n    \n        # store whether originally we wanted numeric dtype\n        dtype_numeric = isinstance(dtype, str) and dtype == &amp;quot;numeric&amp;quot;\n    \n        dtype_orig = getattr(array, &amp;quot;dtype&amp;quot;, None)\n        if not is_array_api_compliant and not hasattr(dtype_orig, &amp;quot;kind&amp;quot;):\n            # not a data type (e.g. a column named dtype in a pandas DataFrame)\n            dtype_orig = None\n    \n        # check if the object contains several dtypes (typically a pandas\n        # DataFrame), and store them. If not, store None.\n        dtypes_orig = None\n        pandas_requires_conversion = False\n        # track if we have a Series-like object to raise a better error message\n        type_if_series = None\n        if hasattr(array, &amp;quot;dtypes&amp;quot;) and hasattr(array.dtypes, &amp;quot;__array__&amp;quot;):\n            # throw warning if columns are sparse. If all columns are sparse, then\n            # array.sparse exists and sparsity will be preserved (later).\n            with suppress(ImportError):\n                from pandas import SparseDtype\n    \n                def is_sparse(dtype):\n                    return isinstance(dtype, SparseDtype)\n    \n                if not hasattr(array, &amp;quot;sparse&amp;quot;) and array.dtypes.apply(is_sparse).any():\n                    warnings.warn(\n                        &amp;quot;pandas.DataFrame with sparse columns found.&amp;quot;\n                        &amp;quot;It will be converted to a dense numpy array.&amp;quot;\n                    )\n    \n            dtypes_orig = list(array.dtypes)\n            pandas_requires_conversion = any(\n                _pandas_dtype_needs_early_conversion(i) for i in dtypes_orig\n            )\n            if all(isinstance(dtype_iter, np.dtype) for dtype_iter in dtypes_orig):\n                dtype_orig = np.result_type(*dtypes_orig)\n            elif pandas_requires_conversion and any(d == object for d in dtypes_orig):\n                # Force object if any of the dtypes is an object\n                dtype_orig = object\n    \n        elif (_is_extension_array_dtype(array) or hasattr(array, &amp;quot;iloc&amp;quot;)) and hasattr(\n            array, &amp;quot;dtype&amp;quot;\n        ):\n            # array is a pandas series\n            type_if_series = type(array)\n            pandas_requires_conversion = _pandas_dtype_needs_early_conversion(array.dtype)\n            if isinstance(array.dtype, np.dtype):\n                dtype_orig = array.dtype\n            else:\n                # Set to None to let array.astype work out the best dtype\n                dtype_orig = None\n    \n        if dtype_numeric:\n            if (\n                dtype_orig is not None\n                and hasattr(dtype_orig, &amp;quot;kind&amp;quot;)\n                and dtype_orig.kind == &amp;quot;O&amp;quot;\n            ):\n                # if input is object, convert to float.\n                dtype = xp.float64\n            else:\n                dtype = None\n    \n        if isinstance(dtype, (list, tuple)):\n            if dtype_orig is not None and dtype_orig in dtype:\n                # no dtype conversion required\n                dtype = None\n            else:\n                # dtype conversion required. Let&amp;#x27;s select the first element of the\n                # list of accepted types.\n                dtype = dtype[0]\n    \n        if pandas_requires_conversion:\n            # pandas dataframe requires conversion earlier to handle extension dtypes with\n            # nans\n            # Use the original dtype for conversion if dtype is None\n            new_dtype = dtype_orig if dtype is None else dtype\n            array = array.astype(new_dtype)\n            # Since we converted here, we do not need to convert again later\n            dtype = None\n    \n        if ensure_all_finite not in (True, False, &amp;quot;allow-nan&amp;quot;):\n            raise ValueError(\n                &amp;quot;ensure_all_finite should be a bool or &amp;#x27;allow-nan&amp;#x27;. Got &amp;quot;\n                f&amp;quot;{ensure_all_finite!r} instead.&amp;quot;\n            )\n    \n        if dtype is not None and _is_numpy_namespace(xp):\n            # convert to dtype object to conform to Array API to be use `xp.isdtype` later\n            dtype = np.dtype(dtype)\n    \n        estimator_name = _check_estimator_name(estimator)\n        context = &amp;quot; by %s&amp;quot; % estimator_name if estimator is not None else &amp;quot;&amp;quot;\n    \n        # When all dataframe columns are sparse, convert to a sparse array\n        if hasattr(array, &amp;quot;sparse&amp;quot;) and array.ndim &amp;gt; 1:\n            with suppress(ImportError):\n                from pandas import SparseDtype\n    \n                def is_sparse(dtype):\n                    return isinstance(dtype, SparseDtype)\n    \n                if array.dtypes.apply(is_sparse).all():\n                    # DataFrame.sparse only supports `to_coo`\n                    array = array.sparse.to_coo()\n                    if array.dtype == np.dtype(&amp;quot;object&amp;quot;):\n                        unique_dtypes = set([dt.subtype.name for dt in array_orig.dtypes])\n                        if len(unique_dtypes) &amp;gt; 1:\n                            raise ValueError(\n                                &amp;quot;Pandas DataFrame with mixed sparse extension arrays &amp;quot;\n                                &amp;quot;generated a sparse matrix with object dtype which &amp;quot;\n                                &amp;quot;can not be converted to a scipy sparse matrix.&amp;quot;\n                                &amp;quot;Sparse extension arrays should all have the same &amp;quot;\n                                &amp;quot;numeric type.&amp;quot;\n                            )\n    \n        if sp.issparse(array):\n            _ensure_no_complex_data(array)\n            array = _ensure_sparse_format(\n                array,\n                accept_sparse=accept_sparse,\n                dtype=dtype,\n                copy=copy,\n                ensure_all_finite=ensure_all_finite,\n                accept_large_sparse=accept_large_sparse,\n                estimator_name=estimator_name,\n                input_name=input_name,\n            )\n            if ensure_2d and array.ndim &amp;lt; 2:\n                raise ValueError(\n                    f&amp;quot;Expected 2D input, got input with shape {array.shape}.\\n&amp;quot;\n                    &amp;quot;Reshape your data either using array.reshape(-1, 1) if &amp;quot;\n                    &amp;quot;your data has a single feature or array.reshape(1, -1) &amp;quot;\n                    &amp;quot;if it contains a single sample.&amp;quot;\n                )\n        else:\n            # If np.array(..) gives ComplexWarning, then we convert the warning\n            # to an error. This is needed because specifying a non complex\n            # dtype to the function converts complex to real dtype,\n            # thereby passing the test made in the lines following the scope\n            # of warnings context manager.\n            with warnings.catch_warnings():\n                try:\n                    warnings.simplefilter(&amp;quot;error&amp;quot;, ComplexWarning)\n                    if dtype is not None and xp.isdtype(dtype, &amp;quot;integral&amp;quot;):\n                        # Conversion float -&amp;gt; int should not contain NaN or\n                        # inf (numpy#14412). We cannot use casting=&amp;#x27;safe&amp;#x27; because\n                        # then conversion float -&amp;gt; int would be disallowed.\n                        array = _asarray_with_order(array, order=order, xp=xp)\n                        if xp.isdtype(array.dtype, (&amp;quot;real floating&amp;quot;, &amp;quot;complex floating&amp;quot;)):\n                            _assert_all_finite(\n                                array,\n                                allow_nan=False,\n                                msg_dtype=dtype,\n                                estimator_name=estimator_name,\n                                input_name=input_name,\n                            )\n                        array = xp.astype(array, dtype, copy=False)\n                    else:\n                        array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n                except ComplexWarning as complex_warning:\n                    raise ValueError(\n                        &amp;quot;Complex data not supported\\n{}\\n&amp;quot;.format(array)\n                    ) from complex_warning\n    \n            # It is possible that the np.array(..) gave no warning. This happens\n            # when no dtype conversion happened, for example dtype = None. The\n            # result is that np.array(..) produces an array of complex dtype\n            # and we need to catch and raise exception for such cases.\n            _ensure_no_complex_data(array)\n    \n            if ensure_2d:\n                # If input is scalar raise error\n                if array.ndim == 0:\n                    raise ValueError(\n                        &amp;quot;Expected 2D array, got scalar array instead:\\narray={}.\\n&amp;quot;\n                        &amp;quot;Reshape your data either using array.reshape(-1, 1) if &amp;quot;\n                        &amp;quot;your data has a single feature or array.reshape(1, -1) &amp;quot;\n                        &amp;quot;if it contains a single sample.&amp;quot;.format(array)\n                    )\n                # If input is 1D raise error\n                if array.ndim == 1:\n                    # If input is a Series-like object (eg. pandas Series or polars Series)\n                    if type_if_series is not None:\n                        msg = (\n                            f&amp;quot;Expected a 2-dimensional container but got {type_if_series} &amp;quot;\n                            &amp;quot;instead. Pass a DataFrame containing a single row (i.e. &amp;quot;\n                            &amp;quot;single sample) or a single column (i.e. single feature) &amp;quot;\n                            &amp;quot;instead.&amp;quot;\n                        )\n                    else:\n                        msg = (\n                            f&amp;quot;Expected 2D array, got 1D array instead:\\narray={array}.\\n&amp;quot;\n                            &amp;quot;Reshape your data either using array.reshape(-1, 1) if &amp;quot;\n                            &amp;quot;your data has a single feature or array.reshape(1, -1) &amp;quot;\n                            &amp;quot;if it contains a single sample.&amp;quot;\n                        )\n                    raise ValueError(msg)\n    \n            if dtype_numeric and hasattr(array.dtype, &amp;quot;kind&amp;quot;) and array.dtype.kind in &amp;quot;USV&amp;quot;:\n                raise ValueError(\n                    &amp;quot;dtype=&amp;#x27;numeric&amp;#x27; is not compatible with arrays of bytes/strings.&amp;quot;\n                    &amp;quot;Convert your data to numeric values explicitly instead.&amp;quot;\n                )\n            if not allow_nd and array.ndim &amp;gt;= 3:\n                raise ValueError(\n                    f&amp;quot;Found array with dim {array.ndim},&amp;quot;\n                    f&amp;quot; while dim &amp;lt;= 2 is required{context}.&amp;quot;\n                )\n    \n            if ensure_all_finite:\n                _assert_all_finite(\n                    array,\n                    input_name=input_name,\n                    estimator_name=estimator_name,\n                    allow_nan=ensure_all_finite == &amp;quot;allow-nan&amp;quot;,\n                )\n    \n            if copy:\n                if _is_numpy_namespace(xp):\n                    # only make a copy if `array` and `array_orig` may share memory`\n                    if np.may_share_memory(array, array_orig):\n                        array = _asarray_with_order(\n                            array, dtype=dtype, order=order, copy=True, xp=xp\n                        )\n                else:\n                    # always make a copy for non-numpy arrays\n                    array = _asarray_with_order(\n                        array, dtype=dtype, order=order, copy=True, xp=xp\n                    )\n    \n        if ensure_min_samples &amp;gt; 0:\n            n_samples = _num_samples(array)\n            if n_samples &amp;lt; ensure_min_samples:\n                raise ValueError(\n                    &amp;quot;Found array with %d sample(s) (shape=%s) while a&amp;quot;\n                    &amp;quot; minimum of %d is required%s.&amp;quot;\n                    % (n_samples, array.shape, ensure_min_samples, context)\n                )\n    \n        if ensure_min_features &amp;gt; 0 and array.ndim == 2:\n            n_features = array.shape[1]\n            if n_features &amp;lt; ensure_min_features:\n&amp;gt;               raise ValueError(\n                    &amp;quot;Found array with %d feature(s) (shape=%s) while&amp;quot;\n                    &amp;quot; a minimum of %d is required%s.&amp;quot;\n                    % (n_features, array.shape, ensure_min_features, context)\n                )\nE               ValueError: Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by Lasso.\n\naccept_large_sparse = False\naccept_sparse = &amp;#x27;csc&amp;#x27;\nallow_nd   = False\narray      = array([], shape=(10, 0), dtype=float64)\narray_orig = array([], shape=(10, 0), dtype=float64)\ncontext    = &amp;#x27; by Lasso&amp;#x27;\ncopy       = True\ndtype      = None\ndtype_numeric = False\ndtype_orig = dtype(&amp;#x27;float64&amp;#x27;)\ndtypes_orig = None\nensure_2d  = True\nensure_all_finite = True\nensure_min_features = 1\nensure_min_samples = 1\nensure_non_negative = False\nestimator  = Lasso(precompute=array([], shape=(0, 0), dtype=float64),\n      random_state=RandomState(PCG64) at 0x7FF38EA01A40)\nestimator_name = &amp;#x27;Lasso&amp;#x27;\nforce_all_finite = &amp;#x27;deprecated&amp;#x27;\nforce_writeable = True\ninput_name = &amp;#x27;X&amp;#x27;\nis_array_api_compliant = False\nn_features = 0\nn_samples  = 10\norder      = &amp;#x27;F&amp;#x27;\npandas_requires_conversion = False\ntype_if_series = None\nxp         = &amp;lt;module &amp;#x27;sklearn.externals.array_api_compat.numpy&amp;#x27; from &amp;#x27;/home/runner/work/hidimstat/hidimstat/.venv/lib/python3.10/site-packages/sklearn/externals/array_api_compat/numpy/__init__.py&amp;#x27;&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1137: ValueError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = DesparsifiedLasso(confidence=0.9, random_state=0)\ncheck = functools.partial(&amp;lt;function check_fit2d_1feature at 0x7ff3891fa3b0&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit2d_1feature at 0x7ff3891fa3b0&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\n\ntest/test_desparsified_lasso.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;DesparsifiedLasso&amp;#x27;, DesparsifiedLasso(confidence=0.9, random_state=0))\n        fn         = &amp;lt;function check_fit2d_1feature at 0x7ff3891fa320&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:1955: in check_fit2d_1feature\n    with raises(ValueError, match=msgs, may_pass=True):\n        X          = array([[1.64644051],\n       [2.1455681 ],\n       [1.80829013],\n       [1.63464955],\n       [1.2709644 ],\n       [1.93768234],\n       [1.31276163],\n       [2.675319  ],\n       [2.89098828],\n       [1.15032456]])\n        estimator  = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7FF38EA01940),\n                  random_state=1)\n        estimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n        msgs       = [&amp;#x27;1 feature\\\\(s\\\\)&amp;#x27;, &amp;#x27;n_features = 1&amp;#x27;, &amp;#x27;n_features=1&amp;#x27;]\n        name       = &amp;#x27;DesparsifiedLasso&amp;#x27;\n        rnd        = RandomState(MT19937) at 0x7FF38EA01640\n        y          = array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;sklearn.utils._testing._Raises object at 0x7ff385d8da20&amp;gt;\nexc_type = &amp;lt;class &amp;#x27;ValueError&amp;#x27;&amp;gt;\nexc_value = ValueError(&amp;#x27;Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by Lasso.&amp;#x27;)\n_ = &amp;lt;traceback object at 0x7ff384cc2600&amp;gt;\n\n    def __exit__(self, exc_type, exc_value, _):\n        # see\n        # https://docs.python.org/2.5/whatsnew/pep-343.html#SECTION000910000000000000000\n    \n        if exc_type is None:  # No exception was raised in the block\n            if self.may_pass:\n                return True  # CM is happy\n            else:\n                err_msg = self.err_msg or f&amp;quot;Did not raise: {self.expected_exc_types}&amp;quot;\n                raise AssertionError(err_msg)\n    \n        if not any(\n            issubclass(exc_type, expected_type)\n            for expected_type in self.expected_exc_types\n        ):\n            if self.err_msg is not None:\n                raise AssertionError(self.err_msg) from exc_value\n            else:\n                return False  # will re-raise the original exception\n    \n        if self.matches is not None:\n            err_msg = self.err_msg or (\n                &amp;quot;The error message should contain one of the following &amp;quot;\n                &amp;quot;patterns:\\n{}\\nGot {}&amp;quot;.format(&amp;quot;\\n&amp;quot;.join(self.matches), str(exc_value))\n            )\n            if not any(re.search(match, str(exc_value)) for match in self.matches):\n&amp;gt;               raise AssertionError(err_msg) from exc_value\nE               AssertionError: The error message should contain one of the following patterns:\nE               1 feature\\(s\\)\nE               n_features = 1\nE               n_features=1\nE               Got Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by Lasso.\n\n_          = &amp;lt;traceback object at 0x7ff384cc2600&amp;gt;\nerr_msg    = &amp;#x27;The error message should contain one of the following patterns:\\n1 feature\\\\(s\\\\)\\nn_features = 1\\nn_features=1\\nGot Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by Lasso.&amp;#x27;\nexc_type   = &amp;lt;class &amp;#x27;ValueError&amp;#x27;&amp;gt;\nexc_value  = ValueError(&amp;#x27;Found array with 0 feature(s) (shape=(10, 0)) while a minimum of 1 is required by Lasso.&amp;#x27;)\nself       = &amp;lt;sklearn.utils._testing._Raises object at 0x7ff385d8da20&amp;gt;\n\n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:1155: AssertionError\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_repr]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_repr]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_repr]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_pipeline_consistency]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_pipeline_consistency]&#34;, &#34;duration&#34;: &#34;54 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_pipeline_consistency]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;54 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_complex_data]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_complex_data]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_complex_data]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_dict_unchanged]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_dict_unchanged]&#34;, &#34;duration&#34;: &#34;46 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_dict_unchanged]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;46 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_group_reid_2&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_group_reid_2&#34;, &#34;duration&#34;: &#34;175 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_group_reid_2&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;175 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nGroup reid: simple cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: simple cov estimation\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit1d]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit1d]&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit1d]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_sparse_tag]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_sparse_tag]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_sparse_tag]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_positive_only_tag_during_fit]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_positive_only_tag_during_fit]&#34;, &#34;duration&#34;: &#34;52 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_positive_only_tag_during_fit]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;52 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_dl_reproducibility_with_integer&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_dl_reproducibility_with_integer&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_dl_reproducibility_with_integer&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_dont_overwrite_parameters]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_dont_overwrite_parameters]&#34;, &#34;duration&#34;: &#34;46 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_dont_overwrite_parameters]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;46 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_pickle(readonly_memmap=True)]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_pickle(readonly_memmap=True)]&#34;, &#34;duration&#34;: &#34;51 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_pickle(readonly_memmap=True)]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;51 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_desparsified_lasso&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_desparsified_lasso&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_desparsified_lasso&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_tags_renamed]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_tags_renamed]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_tags_renamed]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit_idempotent]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit_idempotent]&#34;, &#34;duration&#34;: &#34;51 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit_idempotent]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;51 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_readonly_memmap_input]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_readonly_memmap_input]&#34;, &#34;duration&#34;: &#34;46 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_readonly_memmap_input]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;46 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_group_reid&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_group_reid&#34;, &#34;duration&#34;: &#34;126 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_group_reid&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;126 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nGroup reid: simple cov estimation\nGroup reid: AR1 cov estimation\nGroup reid: simple cov estimation\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_overwrite_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_overwrite_params]&#34;, &#34;duration&#34;: &#34;47 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_overwrite_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;47 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = DesparsifiedLasso(confidence=0.9, random_state=0)\ncheck = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4cfd8852d0&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_estimators_overwrite_params at 0x7f4cfd8852d0&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\n\ntest/test_desparsified_lasso.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;DesparsifiedLasso&amp;#x27;, DesparsifiedLasso(confidence=0.9, random_state=0))\n        fn         = &amp;lt;function check_estimators_overwrite_params at 0x7f4cfd885240&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;DesparsifiedLasso&amp;#x27;\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n\n    @ignore_warnings(category=FutureWarning)\n    def check_estimators_overwrite_params(name, estimator_orig):\n        X, y = make_blobs(random_state=0, n_samples=21)\n        X = _enforce_estimator_tags_X(estimator_orig, X, kernel=rbf_kernel)\n        estimator = clone(estimator_orig)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        set_random_state(estimator)\n    \n        # Make a physical copy of the original estimator parameters before fitting.\n        params = estimator.get_params()\n        original_params = deepcopy(params)\n    \n        # Fit the model\n        estimator.fit(X, y)\n    \n        # Compare the state of the model parameters with the original parameters\n        new_params = estimator.get_params()\n        for param_name, original_value in original_params.items():\n            new_value = new_params[param_name]\n    \n            # We should never change or mutate the internal state of input\n            # parameters by default. To check this we use the joblib.hash function\n            # that introspects recursively any subobjects to compute a checksum.\n            # The only exception to this rule of immutable constructor parameters\n            # is possible RandomState instance but in this check we explicitly\n            # fixed the random_state params recursively to be integer seeds.\n&amp;gt;           assert joblib.hash(new_value) == joblib.hash(original_value), (\n                &amp;quot;Estimator %s should not change or mutate &amp;quot;\n                &amp;quot; the parameter %s from %s to %s during fit.&amp;quot;\n                % (name, param_name, original_value, new_value)\n            )\nE           AssertionError: Estimator DesparsifiedLasso should not change or mutate  the parameter estimator__n_jobs from None to 1 during fit.\n\nX          = array([[ 2.21021495,  1.27582618],\n       [ 1.28933778,  3.44969159],\n       [ 2.10102604,  0.71047981],\n       [ 2.91...-1.08313281],\n       [-2.77969937,  3.69537262],\n       [ 1.7373078 ,  4.42546234],\n       [-0.29661333,  4.12026211]])\nestimator  = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7F4CF1E00240),\n                  random_state=0)\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\nname       = &amp;#x27;DesparsifiedLasso&amp;#x27;\nnew_params = {&amp;#x27;alpha_max_fraction&amp;#x27;: 0.01, &amp;#x27;centered&amp;#x27;: True, &amp;#x27;confidence&amp;#x27;: 0.9, &amp;#x27;covariance&amp;#x27;: None, ...}\nnew_value  = 1\noriginal_params = {&amp;#x27;alpha_max_fraction&amp;#x27;: 0.01, &amp;#x27;centered&amp;#x27;: True, &amp;#x27;confidence&amp;#x27;: 0.9, &amp;#x27;covariance&amp;#x27;: None, ...}\noriginal_value = None\nparam_name = &amp;#x27;estimator__n_jobs&amp;#x27;\nparams     = {&amp;#x27;alpha_max_fraction&amp;#x27;: 0.01, &amp;#x27;centered&amp;#x27;: True, &amp;#x27;confidence&amp;#x27;: 0.9, &amp;#x27;covariance&amp;#x27;: None, ...}\ny          = array([1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 1, 2, 0, 2])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3621: AssertionError\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_parameters_default_constructible]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_parameters_default_constructible]&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_parameters_default_constructible]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = DesparsifiedLasso(confidence=0.9, random_state=0)\ncheck = functools.partial(&amp;lt;function check_parameters_default_constructible at 0x7f4cfd885a20&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_parameters_default_constructible at 0x7f4cfd885a20&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\n\ntest/test_desparsified_lasso.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;DesparsifiedLasso&amp;#x27;\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n\n    def check_parameters_default_constructible(name, estimator_orig):\n        # test default-constructibility\n        # get rid of deprecation warnings\n    \n        Estimator = estimator_orig.__class__\n        estimator = clone(estimator_orig)\n    \n        with ignore_warnings(category=FutureWarning):\n            # test that set_params returns self\n            # TODO(devtools): this should be a separate check.\n            assert estimator.set_params() is estimator\n    \n            # test if init does nothing but set parameters\n            # this is important for grid_search etc.\n            # We get the default parameters from init and then\n            # compare these against the actual values of the attributes.\n    \n            # this comes from getattr. Gets rid of deprecation decorator.\n            init = getattr(estimator.__init__, &amp;quot;deprecated_original&amp;quot;, estimator.__init__)\n    \n            try:\n    \n                def param_default_value(p):\n                    &amp;quot;&amp;quot;&amp;quot;Identify hyper parameters of an estimator.&amp;quot;&amp;quot;&amp;quot;\n                    return (\n                        p.name != &amp;quot;self&amp;quot;\n                        and p.kind != p.VAR_KEYWORD\n                        and p.kind != p.VAR_POSITIONAL\n                        # and it should have a default value for this test\n                        and p.default != p.empty\n                    )\n    \n                def param_required(p):\n                    &amp;quot;&amp;quot;&amp;quot;Identify hyper parameters of an estimator.&amp;quot;&amp;quot;&amp;quot;\n                    return (\n                        p.name != &amp;quot;self&amp;quot;\n                        and p.kind != p.VAR_KEYWORD\n                        # technically VAR_POSITIONAL is also required, but we don&amp;#x27;t have a\n                        # nice way to check for it. We assume there&amp;#x27;s no VAR_POSITIONAL in\n                        # the constructor parameters.\n                        #\n                        # TODO(devtools): separately check that the constructor doesn&amp;#x27;t\n                        # have *args.\n                        and p.kind != p.VAR_POSITIONAL\n                        # these are parameters that don&amp;#x27;t have a default value and are\n                        # required to construct the estimator.\n                        and p.default == p.empty\n                    )\n    \n                required_params_names = [\n                    p.name for p in signature(init).parameters.values() if param_required(p)\n                ]\n    \n                default_value_params = [\n                    p for p in signature(init).parameters.values() if param_default_value(p)\n                ]\n    \n            except (TypeError, ValueError):\n                # init is not a python function.\n                # true for mixins\n                return\n    \n            # here we construct an instance of the estimator using only the required\n            # parameters.\n            old_params = estimator.get_params()\n            init_params = {\n                param: old_params[param]\n                for param in old_params\n                if param in required_params_names\n            }\n            estimator = Estimator(**init_params)\n            params = estimator.get_params()\n    \n            for init_param in default_value_params:\n                allowed_types = {\n                    str,\n                    int,\n                    float,\n                    bool,\n                    tuple,\n                    type(None),\n                    type,\n                }\n                # Any numpy numeric such as np.int32.\n                allowed_types.update(np.sctypeDict.values())\n    \n                allowed_value = (\n                    type(init_param.default) in allowed_types\n                    or\n                    # Although callables are mutable, we accept them as argument\n                    # default value and trust that neither the implementation of\n                    # the callable nor of the estimator changes the state of the\n                    # callable.\n                    callable(init_param.default)\n                )\n    \n&amp;gt;               assert allowed_value, (\n                    f&amp;quot;Parameter &amp;#x27;{init_param.name}&amp;#x27; of estimator &amp;quot;\n                    f&amp;quot;&amp;#x27;{Estimator.__name__}&amp;#x27; is of type &amp;quot;\n                    f&amp;quot;{type(init_param.default).__name__} which is not allowed. &amp;quot;\n                    f&amp;quot;&amp;#x27;{init_param.name}&amp;#x27; must be a callable or must be of type &amp;quot;\n                    f&amp;quot;{set(type.__name__ for type in allowed_types)}.&amp;quot;\n                )\nE               AssertionError: Parameter &amp;#x27;estimator&amp;#x27; of estimator &amp;#x27;DesparsifiedLasso&amp;#x27; is of type LassoCV which is not allowed. &amp;#x27;estimator&amp;#x27; must be a callable or must be of type {&amp;#x27;int64&amp;#x27;, &amp;#x27;float16&amp;#x27;, &amp;#x27;bool&amp;#x27;, &amp;#x27;ulonglong&amp;#x27;, &amp;#x27;int&amp;#x27;, &amp;#x27;float&amp;#x27;, &amp;#x27;clongdouble&amp;#x27;, &amp;#x27;uint64&amp;#x27;, &amp;#x27;tuple&amp;#x27;, &amp;#x27;timedelta64&amp;#x27;, &amp;#x27;bytes_&amp;#x27;, &amp;#x27;uint8&amp;#x27;, &amp;#x27;NoneType&amp;#x27;, &amp;#x27;int8&amp;#x27;, &amp;#x27;int16&amp;#x27;, &amp;#x27;type&amp;#x27;, &amp;#x27;int32&amp;#x27;, &amp;#x27;object_&amp;#x27;, &amp;#x27;uint32&amp;#x27;, &amp;#x27;float64&amp;#x27;, &amp;#x27;str&amp;#x27;, &amp;#x27;str_&amp;#x27;, &amp;#x27;void&amp;#x27;, &amp;#x27;longlong&amp;#x27;, &amp;#x27;datetime64&amp;#x27;, &amp;#x27;complex64&amp;#x27;, &amp;#x27;longdouble&amp;#x27;, &amp;#x27;uint16&amp;#x27;, &amp;#x27;complex128&amp;#x27;, &amp;#x27;float32&amp;#x27;}.\n\nEstimator  = &amp;lt;class &amp;#x27;hidimstat.desparsified_lasso.DesparsifiedLasso&amp;#x27;&amp;gt;\nallowed_types = {&amp;lt;class &amp;#x27;numpy.datetime64&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.complex128&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.float16&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.uint8&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;numpy.int8&amp;#x27;&amp;gt;, &amp;lt;class &amp;#x27;bool&amp;#x27;&amp;gt;, ...}\nallowed_value = False\ndefault_value_params = [&amp;lt;Parameter &amp;quot;estimator=LassoCV(eps=0.01, fit_intercept=False)&amp;quot;&amp;gt;, &amp;lt;Parameter &amp;quot;centered=True&amp;quot;&amp;gt;, &amp;lt;Parameter &amp;quot;dof_ajdustem...Parameter &amp;quot;model_x=Lasso()&amp;quot;&amp;gt;, &amp;lt;Parameter &amp;quot;preconfigure_model_x_path=True&amp;quot;&amp;gt;, &amp;lt;Parameter &amp;quot;alpha_max_fraction=0.01&amp;quot;&amp;gt;, ...]\nestimator  = DesparsifiedLasso()\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\ninit       = &amp;lt;bound method DesparsifiedLasso.__init__ of DesparsifiedLasso(confidence=0.9, random_state=0)&amp;gt;\ninit_param = &amp;lt;Parameter &amp;quot;estimator=LassoCV(eps=0.01, fit_intercept=False)&amp;quot;&amp;gt;\ninit_params = {}\nname       = &amp;#x27;DesparsifiedLasso&amp;#x27;\nold_params = {&amp;#x27;alpha_max_fraction&amp;#x27;: 0.01, &amp;#x27;centered&amp;#x27;: True, &amp;#x27;confidence&amp;#x27;: 0.9, &amp;#x27;covariance&amp;#x27;: None, ...}\nparam_default_value = &amp;lt;function check_parameters_default_constructible.&amp;lt;locals&amp;gt;.param_default_value at 0x7f4cf1adfbe0&amp;gt;\nparam_required = &amp;lt;function check_parameters_default_constructible.&amp;lt;locals&amp;gt;.param_required at 0x7f4cf1ade560&amp;gt;\nparams     = {&amp;#x27;alpha_max_fraction&amp;#x27;: 0.01, &amp;#x27;centered&amp;#x27;: True, &amp;#x27;confidence&amp;#x27;: 0.95, &amp;#x27;covariance&amp;#x27;: None, ...}\nrequired_params_names = []\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:3890: AssertionError\n&#34;}], &#34;test/test_desparsified_lasso.py::test_reid_exception&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_reid_exception&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_reid_exception&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\n----------------------------- Captured stdout call -----------------------------\nGroup reid: AR1 cov estimation\nGroup reid: AR10000.0 cov estimation\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_do_not_raise_errors_in_init_or_set_params]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_do_not_raise_errors_in_init_or_set_params]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_do_not_raise_errors_in_init_or_set_params]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = DesparsifiedLasso(confidence=0.9, random_state=0)\ncheck = functools.partial(&amp;lt;function check_do_not_raise_errors_in_init_or_set_params at 0x7f4cfd887250&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_do_not_raise_errors_in_init_or_set_params at 0x7f4cfd887250&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\n\ntest/test_desparsified_lasso.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:5307: in check_do_not_raise_errors_in_init_or_set_params\n    est = Estimator(**new_params)\n        Estimator  = &amp;lt;class &amp;#x27;hidimstat.desparsified_lasso.DesparsifiedLasso&amp;#x27;&amp;gt;\n        estimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n        name       = &amp;#x27;DesparsifiedLasso&amp;#x27;\n        new_params = {&amp;#x27;alpha_max_fraction&amp;#x27;: -1, &amp;#x27;centered&amp;#x27;: -1, &amp;#x27;confidence&amp;#x27;: -1, &amp;#x27;covariance&amp;#x27;: -1, ...}\n        params     = mappingproxy(OrderedDict([(&amp;#x27;estimator&amp;#x27;, &amp;lt;Parameter &amp;quot;estimator=LassoCV(eps=0.01, fit_intercept=False)&amp;quot;&amp;gt;), (&amp;#x27;centered&amp;#x27;, ...&amp;quot;&amp;gt;), (&amp;#x27;n_jobs&amp;#x27;, &amp;lt;Parameter &amp;quot;n_jobs=1&amp;quot;&amp;gt;), (&amp;#x27;memory&amp;#x27;, &amp;lt;Parameter &amp;quot;memory=None&amp;quot;&amp;gt;), (&amp;#x27;verbose&amp;#x27;, &amp;lt;Parameter &amp;quot;verbose=0&amp;quot;&amp;gt;)]))\n        smoke_test_values = [-1, 3.0, &amp;#x27;helloworld&amp;#x27;, array([1., 4.]), [1], {}, ...]\n        value      = -1\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;[AttributeError(&amp;quot;&amp;#x27;DesparsifiedLasso&amp;#x27; object has no attribute &amp;#x27;alpha_max_fraction&amp;#x27;&amp;quot;) raised in repr()] DesparsifiedLasso object at 0x7f4cf1913070&amp;gt;\nestimator = -1, centered = -1, dof_ajdustement = -1, model_x = -1\npreconfigure_model_x_path = -1, alpha_max_fraction = -1, random_state = -1\nsave_model_x = -1, tolerance_reid = -1, noise_method = -1, order = -1\nstationary = -1, confidence = -1, distribution = -1, epsilon_pvalue = -1\ntest = -1, covariance = -1, n_jobs = -1, memory = -1, verbose = -1\n\n    def __init__(\n        self,\n        estimator=LassoCV(\n            max_iter=1000, tol=0.0001, eps=0.01, fit_intercept=False\n        ),\n        centered=True,\n        dof_ajdustement=False,\n        # parameters for model_x\n        model_x=Lasso(),\n        preconfigure_model_x_path=True,\n        alpha_max_fraction=0.01,\n        random_state=None,\n        save_model_x=False,\n        # parameters for reid\n        tolerance_reid=1e-4,\n        noise_method=&amp;quot;AR&amp;quot;,\n        order=1,\n        stationary=True,\n        # parameters for tests\n        confidence=0.95,\n        distribution=&amp;quot;norm&amp;quot;,\n        epsilon_pvalue=1e-14,\n        test=&amp;quot;chi2&amp;quot;,\n        covariance=None,\n        # parameters for optimization\n        n_jobs=1,\n        memory=None,\n        verbose=0,\n    ):\n        super().__init__()\n        if issubclass(LassoCV, estimator.__class__):\n            self.n_task_ = 1\n        elif issubclass(MultiTaskLassoCV, estimator.__class__):\n            self.n_task_ = -1\n        else:\n&amp;gt;           raise AssertionError(\n                &amp;quot;lasso_cv needs to be a LassoCV or a MultiTaskLassoCV&amp;quot;\n            )\nE           AssertionError: lasso_cv needs to be a LassoCV or a MultiTaskLassoCV\n\n__class__  = &amp;lt;class &amp;#x27;hidimstat.desparsified_lasso.DesparsifiedLasso&amp;#x27;&amp;gt;\nalpha_max_fraction = -1\ncentered   = -1\nconfidence = -1\ncovariance = -1\ndistribution = -1\ndof_ajdustement = -1\nepsilon_pvalue = -1\nestimator  = -1\nmemory     = -1\nmodel_x    = -1\nn_jobs     = -1\nnoise_method = -1\norder      = -1\npreconfigure_model_x_path = -1\nrandom_state = -1\nsave_model_x = -1\nself       = &amp;lt;[AttributeError(&amp;quot;&amp;#x27;DesparsifiedLasso&amp;#x27; object has no attribute &amp;#x27;alpha_max_fraction&amp;#x27;&amp;quot;) raised in repr()] DesparsifiedLasso object at 0x7f4cf1913070&amp;gt;\nstationary = -1\ntest       = -1\ntolerance_reid = -1\nverbose    = -1\n\nsrc/hidimstat/desparsified_lasso.py:138: AssertionError\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_fit_returns_self]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_fit_returns_self]&#34;, &#34;duration&#34;: &#34;45 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_fit_returns_self]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;45 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_mixin_order]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_mixin_order]&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_mixin_order]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_reid&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_reid&#34;, &#34;duration&#34;: &#34;81 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_reid&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;81 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_dtype_object]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_dtype_object]&#34;, &#34;duration&#34;: &#34;66 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_dtype_object]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;66 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_sparse_matrix]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_sparse_matrix]&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimator_sparse_matrix]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_unfitted]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_unfitted]&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_unfitted]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_dtypes]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_dtypes]&#34;, &#34;duration&#34;: &#34;186 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_estimators_dtypes]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;186 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_n_features_in_after_fitting]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_n_features_in_after_fitting]&#34;, &#34;duration&#34;: &#34;47 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_n_features_in_after_fitting]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;47 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nestimator = DesparsifiedLasso(confidence=0.9, random_state=0)\ncheck = functools.partial(&amp;lt;function check_n_features_in_after_fitting at 0x7f4cfd8867a0&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_n_features_in_after_fitting at 0x7f4cfd8867a0&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\n\ntest/test_desparsified_lasso.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/sklearn/utils/_testing.py:145: in wrapper\n    return fn(*args, **kwargs)\n        args       = (&amp;#x27;DesparsifiedLasso&amp;#x27;, DesparsifiedLasso(confidence=0.9, random_state=0))\n        fn         = &amp;lt;function check_n_features_in_after_fitting at 0x7f4cfd886710&amp;gt;\n        kwargs     = {}\n        self       = _IgnoreWarnings(record=True)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;DesparsifiedLasso&amp;#x27;\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n\n    @ignore_warnings(category=FutureWarning)\n    def check_n_features_in_after_fitting(name, estimator_orig):\n        # Make sure that n_features_in are checked after fitting\n        tags = get_tags(estimator_orig)\n    \n        is_supported_X_types = tags.input_tags.two_d_array or tags.input_tags.categorical\n    \n        if not is_supported_X_types or tags.no_validation:\n            return\n    \n        rng = np.random.RandomState(0)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if &amp;quot;warm_start&amp;quot; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 10\n        X = rng.normal(size=(n_samples, 4))\n        X = _enforce_estimator_tags_X(estimator, X)\n    \n        if is_regressor(estimator):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        err_msg = (\n            &amp;quot;`{name}.fit()` does not set the `n_features_in_` attribute. &amp;quot;\n            &amp;quot;You might want to use `sklearn.utils.validation.validate_data` instead &amp;quot;\n            &amp;quot;of `check_array` in `{name}.fit()` which takes care of setting the &amp;quot;\n            &amp;quot;attribute.&amp;quot;.format(name=name)\n        )\n    \n        estimator.fit(X, y)\n&amp;gt;       assert hasattr(estimator, &amp;quot;n_features_in_&amp;quot;), err_msg\nE       AssertionError: `DesparsifiedLasso.fit()` does not set the `n_features_in_` attribute. You might want to use `sklearn.utils.validation.validate_data` instead of `check_array` in `DesparsifiedLasso.fit()` which takes care of setting the attribute.\n\nX          = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n       [ 1.86755799, -0.97727788,  0.95008842, -0.1513572...    [-0.88778575, -1.98079647, -0.34791215,  0.15634897],\n       [ 1.23029068,  1.20237985, -0.38732682, -0.30230275]])\nerr_msg    = &amp;#x27;`DesparsifiedLasso.fit()` does not set the `n_features_in_` attribute. You might want to use `sklearn.utils.validation.validate_data` instead of `check_array` in `DesparsifiedLasso.fit()` which takes care of setting the attribute.&amp;#x27;\nestimator  = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7F4CF1E02640),\n                  random_state=0)\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\nis_supported_X_types = True\nn_samples  = 10\nname       = &amp;#x27;DesparsifiedLasso&amp;#x27;\nrng        = RandomState(MT19937) at 0x7F4CF1E01B40\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\ny          = array([0, 1, 1, 0, 1, 0, 0, 1, 0, 0])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4449: AssertionError\n&#34;}], &#34;test/_utils/test_regression.py::test_alpha_max&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/_utils/test_regression.py::test_alpha_max&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/_utils/test_regression.py::test_alpha_max&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_multiple_testing.py::test_aggregate_docstring&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_multiple_testing.py::test_aggregate_docstring&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_multiple_testing.py::test_aggregate_docstring&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_multiple_testing.py::test_fdr_threshold_extreme_values&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_multiple_testing.py::test_fdr_threshold_extreme_values&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_multiple_testing.py::test_fdr_threshold_extreme_values&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_multiple_testing.py::test_fdr_threshold&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_multiple_testing.py::test_fdr_threshold&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_multiple_testing.py::test_fdr_threshold&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/statistical_tools/test_multiple_testing.py::test_fdp_power&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/statistical_tools/test_multiple_testing.py::test_fdp_power&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/statistical_tools/test_multiple_testing.py::test_fdp_power&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw1] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_dl_randomness_with_none&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_dl_randomness_with_none&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_dl_randomness_with_none&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit_check_is_fitted]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;XFailed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit_check_is_fitted]&#34;, &#34;duration&#34;: &#34;50 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;XFailed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit_check_is_fitted]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;50 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n\nname = &amp;#x27;DesparsifiedLasso&amp;#x27;\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n\n    def check_fit_check_is_fitted(name, estimator_orig):\n        # Make sure that estimator doesn&amp;#x27;t pass check_is_fitted before calling fit\n        # and that passes check_is_fitted once it&amp;#x27;s fit.\n    \n        rng = np.random.RandomState(42)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if &amp;quot;warm_start&amp;quot; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if get_tags(estimator).requires_fit:\n            # stateless estimators (such as FunctionTransformer) are always &amp;quot;fit&amp;quot;!\n            try:\n                check_is_fitted(estimator)\n                raise AssertionError(\n                    f&amp;quot;{estimator.__class__.__name__} passes check_is_fitted before being&amp;quot;\n                    &amp;quot; fit!&amp;quot;\n                )\n            except NotFittedError:\n                pass\n        estimator.fit(X, y)\n        try:\n&amp;gt;           check_is_fitted(estimator)\n\nX          = array([[100.49671415,  99.8617357 ],\n       [100.64768854, 101.52302986],\n       [ 99.76584663,  99.76586304],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\nestimator  = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7FF38EA02240),\n                  random_state=0)\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\nn_samples  = 100\nname       = &amp;#x27;DesparsifiedLasso&amp;#x27;\nrng        = RandomState(MT19937) at 0x7FF38EA02940\ny          = array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,...1,\n       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4355: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nestimator = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7FF38EA02240),\n                  random_state=0)\nattributes = None\n\n    def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n        &amp;quot;&amp;quot;&amp;quot;Perform is_fitted validation for estimator.\n    \n        Checks if the estimator is fitted by verifying the presence of\n        fitted attributes (ending with a trailing underscore) and otherwise\n        raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n    \n        If an estimator does not set any attributes with a trailing underscore, it\n        can define a ``__sklearn_is_fitted__`` method returning a boolean to\n        specify if the estimator is fitted or not. See\n        :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n        for an example on how to use the API.\n    \n        If no `attributes` are passed, this function will pass if an estimator is stateless.\n        An estimator can indicate it&amp;#x27;s stateless by setting the `requires_fit` tag. See\n        :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n        is ignored if `attributes` are passed.\n    \n        Parameters\n        ----------\n        estimator : estimator instance\n            Estimator instance for which the check is performed.\n    \n        attributes : str, list or tuple of str, default=None\n            Attribute name(s) given as string or a list/tuple of strings\n            Eg.: ``[&amp;quot;coef_&amp;quot;, &amp;quot;estimator_&amp;quot;, ...], &amp;quot;coef_&amp;quot;``\n    \n            If `None`, `estimator` is considered fitted if there exist an\n            attribute that ends with a underscore and does not start with double\n            underscore.\n    \n        msg : str, default=None\n            The default error message is, &amp;quot;This %(name)s instance is not fitted\n            yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this\n            estimator.&amp;quot;\n    \n            For custom messages if &amp;quot;%(name)s&amp;quot; is present in the message string,\n            it is substituted for the estimator name.\n    \n            Eg. : &amp;quot;Estimator, %(name)s, must be fitted before sparsifying&amp;quot;.\n    \n        all_or_any : callable, {all, any}, default=all\n            Specify whether all or any of the given attributes must exist.\n    \n        Raises\n        ------\n        TypeError\n            If the estimator is a class or not an estimator instance\n    \n        NotFittedError\n            If the attributes are not found.\n    \n        Examples\n        --------\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegression\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.utils.validation import check_is_fitted\n        &amp;gt;&amp;gt;&amp;gt; from sklearn.exceptions import NotFittedError\n        &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; try:\n        ...     check_is_fitted(lr)\n        ... except NotFittedError as exc:\n        ...     print(f&amp;quot;Model is not fitted yet.&amp;quot;)\n        Model is not fitted yet.\n        &amp;gt;&amp;gt;&amp;gt; lr.fit([[1, 2], [1, 3]], [1, 0])\n        LogisticRegression()\n        &amp;gt;&amp;gt;&amp;gt; check_is_fitted(lr)\n        &amp;quot;&amp;quot;&amp;quot;\n        if isclass(estimator):\n            raise TypeError(&amp;quot;{} is a class, not an instance.&amp;quot;.format(estimator))\n        if msg is None:\n            msg = (\n                &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with &amp;quot;\n                &amp;quot;appropriate arguments before using this estimator.&amp;quot;\n            )\n    \n        if not hasattr(estimator, &amp;quot;fit&amp;quot;):\n            raise TypeError(&amp;quot;%s is not an estimator instance.&amp;quot; % (estimator))\n    \n        tags = get_tags(estimator)\n    \n        if not tags.requires_fit and attributes is None:\n            return\n    \n        if not _is_fitted(estimator, attributes, all_or_any):\n&amp;gt;           raise NotFittedError(msg % {&amp;quot;name&amp;quot;: type(estimator).__name__})\nE           sklearn.exceptions.NotFittedError: This DesparsifiedLasso instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.\n\nall_or_any = &amp;lt;built-in function all&amp;gt;\nattributes = None\nestimator  = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7FF38EA02240),\n                  random_state=0)\nmsg        = &amp;quot;This %(name)s instance is not fitted yet. Call &amp;#x27;fit&amp;#x27; with appropriate arguments before using this estimator.&amp;quot;\ntags       = Tags(estimator_type=None, target_tags=TargetTags(required=False, one_d_labels=False, two_d_labels=False, positive_only...alse, sparse=False, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False))\n\n.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1754: NotFittedError\n\nThe above exception was the direct cause of the following exception:\n\nestimator = DesparsifiedLasso(confidence=0.9, random_state=0)\ncheck = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7ff389206560&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\n\n    @parametrize_with_checks(\n        estimators=ESTIMATORS_TO_CHECK,\n        expected_failed_checks=expected_failed_checks,\n    )\n    def test_check_estimator_sklearn(estimator, check):\n&amp;gt;       check(estimator)\n\ncheck      = functools.partial(&amp;lt;function check_fit_check_is_fitted at 0x7ff389206560&amp;gt;, &amp;#x27;DesparsifiedLasso&amp;#x27;)\nestimator  = DesparsifiedLasso(confidence=0.9, random_state=0)\n\ntest/test_desparsified_lasso.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = &amp;#x27;DesparsifiedLasso&amp;#x27;\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\n\n    def check_fit_check_is_fitted(name, estimator_orig):\n        # Make sure that estimator doesn&amp;#x27;t pass check_is_fitted before calling fit\n        # and that passes check_is_fitted once it&amp;#x27;s fit.\n    \n        rng = np.random.RandomState(42)\n    \n        estimator = clone(estimator_orig)\n        set_random_state(estimator)\n        if &amp;quot;warm_start&amp;quot; in estimator.get_params():\n            estimator.set_params(warm_start=False)\n    \n        n_samples = 100\n        X = rng.normal(loc=100, size=(n_samples, 2))\n        X = _enforce_estimator_tags_X(estimator, X)\n        if is_regressor(estimator_orig):\n            y = rng.normal(size=n_samples)\n        else:\n            y = rng.randint(low=0, high=2, size=n_samples)\n        y = _enforce_estimator_tags_y(estimator, y)\n    \n        if get_tags(estimator).requires_fit:\n            # stateless estimators (such as FunctionTransformer) are always &amp;quot;fit&amp;quot;!\n            try:\n                check_is_fitted(estimator)\n                raise AssertionError(\n                    f&amp;quot;{estimator.__class__.__name__} passes check_is_fitted before being&amp;quot;\n                    &amp;quot; fit!&amp;quot;\n                )\n            except NotFittedError:\n                pass\n        estimator.fit(X, y)\n        try:\n            check_is_fitted(estimator)\n        except NotFittedError as e:\n&amp;gt;           raise NotFittedError(\n                &amp;quot;Estimator fails to pass `check_is_fitted` even though it has been fit.&amp;quot;\n            ) from e\nE           sklearn.exceptions.NotFittedError: Estimator fails to pass `check_is_fitted` even though it has been fit.\n\nX          = array([[100.49671415,  99.8617357 ],\n       [100.64768854, 101.52302986],\n       [ 99.76584663,  99.76586304],\n       ...26122],\n       [100.17318093, 100.38531738],\n       [ 99.11614256, 100.15372511],\n       [100.05820872,  98.8570297 ]])\nestimator  = DesparsifiedLasso(confidence=0.9,\n                  estimator=LassoCV(eps=0.01, fit_intercept=False, n_jobs=1,\n                                    random_state=RandomState(PCG64) at 0x7FF38EA02240),\n                  random_state=0)\nestimator_orig = DesparsifiedLasso(confidence=0.9, random_state=0)\nn_samples  = 100\nname       = &amp;#x27;DesparsifiedLasso&amp;#x27;\nrng        = RandomState(MT19937) at 0x7FF38EA02940\ny          = array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,...1,\n       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n\n.venv/lib/python3.10/site-packages/sklearn/utils/estimator_checks.py:4357: NotFittedError\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit2d_1sample]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit2d_1sample]&#34;, &#34;duration&#34;: &#34;8 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit2d_1sample]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;8 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}], &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit_score_takes_y]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit_score_takes_y]&#34;, &#34;duration&#34;: &#34;47 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;test/test_desparsified_lasso.py::test_check_estimator_sklearn[DesparsifiedLasso(confidence=0.9,random_state=0)-check_fit_score_takes_y]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;47 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;[gw0] linux -- Python 3.10.19 /home/runner/work/hidimstat/hidimstat/.venv/bin/python3\n&#34;}]}, &#34;renderCollapsed&#34;: [&#34;passed&#34;], &#34;initialSort&#34;: &#34;result&#34;, &#34;title&#34;: &#34;report-3.10-os-ubuntu-latest.html&#34;}"></div>
    <script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > .col-result')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > .col-result')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`)?.classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
  </footer>
  </body>
</html>