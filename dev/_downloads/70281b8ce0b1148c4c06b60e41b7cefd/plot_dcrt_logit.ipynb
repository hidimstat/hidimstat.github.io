{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Conditional Randomization Test for Sparse Logistic Regression\n\nThis example demonstrates how to apply the distilled conditional randomization test\n(D0CRT) to logistic regression. The hidimstat package implements the decorrelation\nmethod described in :footcite:t:`nguyen2022conditional`, which ensures that the\ndistribution of the test statistic under the null hypothesis closely approximates a\nstandard Gaussian distribution. We illustrate this property by comparing the quantiles\nof the test statistics obtained using this method (dCRT-logit) with those from the\noriginal D0CRT.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate synthetic data for logistic regression\nTo begin, we'll generate synthetic data for logistic regression. We'll adapt the\nmultivariate_simulation function to first create class probabilities using a logit\nlink function, and then generate binary observations with a Bernoulli distribution.\nBy simulating the data, we know the true underlying process and can identify which\nfeatures are null. This information will be used to plot the quantiles of the test\nstatistics under the null hypothesis.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom scipy.special import expit\n\nfrom hidimstat._utils.scenario import multivariate_simulation\n\n# Simulation parameters\nn_samples = 200\nn_features = 100\nsupport_size = 10\nrho = 0.2  # strength of the serial correlation between adjacent features\nsignal_noise_ratio = 2.0\n\n# Generate data for 5 different random seeds\nX_list, y_list, beta_true_list = [], [], []\nfor seed in range(5):\n    X, y_, beta_true, _ = multivariate_simulation(\n        n_samples=n_samples,\n        n_features=n_features,\n        support_size=support_size,\n        rho=rho,\n        signal_noise_ratio=signal_noise_ratio,\n        seed=seed,\n    )\n    X_list.append(X)\n    # Transform y to binary using the logit link function\n    y_logit = expit(y_)\n    rng = np.random.default_rng(seed)\n    y = rng.binomial(1, y_logit)\n    y_list.append(y)\n    beta_true_list.append(beta_true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute the test statistics\nNext, we compute the test statistics using both the dCRT and dCRT-logit methods.\nFor dCRT-logit, we use a `LogisticRegressionCV` estimator; the D0CRT class automatically\napplies the decorrelation method. For dCRT, we use a `LassoCV` estimator, which implements\nthe original Lasso-distillation approach described in :footcite:t:`liu2022fast`.\nWe store the test statistic values for the null features only.\nThe simulation uses n=200 samples and p=100 correlated features, with a support size of 10\nand a signal-to-noise ratio of 3.0. The experiment is repeated for 5 different random seeds.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nfrom sklearn.linear_model import LassoCV, LogisticRegressionCV\n\nfrom hidimstat import D0CRT\n\n# Run dCRT and dCRT-logit for each random seed\nresults_list = []\nfor seed, (X, y, beta_true) in enumerate(zip(X_list, y_list, beta_true_list)):\n    # Fit the dCRT-logit model\n    dcrt_logit = D0CRT(\n        estimator=LogisticRegressionCV(\n            penalty=\"l1\",\n            solver=\"liblinear\",\n            random_state=seed,\n        ),\n        screening_threshold=None,\n        n_jobs=5,\n    )\n    dcrt_logit.fit(X, y)\n    importance_logit = dcrt_logit.importance(X, y)\n    power_logit = np.mean(dcrt_logit.pvalues_[beta_true] < 0.05)\n\n    # Fit the dCRT with Lasso-distillation\n    dcrt = D0CRT(\n        estimator=LassoCV(random_state=seed, alphas=10, fit_intercept=False),\n        screening_threshold=None,\n        n_jobs=5,\n    )\n    dcrt.fit(X, y)\n    importance = dcrt.importance(X, y)\n    power = np.mean(dcrt.pvalues_[beta_true] < 0.05)\n\n    # Store the results in a DataFrame\n    results_list.append(\n        pd.DataFrame(\n            {\n                \"stat_dcrt\": importance[~beta_true],\n                \"stat_dcrt_logit\": importance_logit[~beta_true],\n                \"seed\": seed,\n                \"power_dcrt\": power,\n                \"power_dcrt_logit\": power_logit,\n            }\n        )\n    )\n\n\ndf_plot = pd.concat(results_list, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## QQ-plot visualization\nNext, we compare the quantiles of the test statistics from both methods\nto the theoretical quantiles of a standard Gaussian distribution.\nWe use a QQ-plot, which displays the theoretical quantiles (from norm.ppf)\nagainst the empirical quantiles computed from the test statistics for each method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\n\nquantiles = np.linspace(1e-2, 1.0 - 1e-2, 100)\ntheoretical_quantiles = norm.ppf(quantiles)\n\nempirical_quantiles = np.quantile(df_plot[\"stat_dcrt\"], quantiles)\nempirical_quantiles_logit = np.quantile(df_plot[\"stat_dcrt_logit\"], quantiles)\n\n\n_, axes = plt.subplots(1, 2, figsize=(6, 3), sharey=True, sharex=True)\nsns.scatterplot(\n    x=theoretical_quantiles,\n    y=empirical_quantiles,\n    ax=axes[0],\n    edgecolor=None,\n)\naxes[0].plot(\n    theoretical_quantiles,\n    theoretical_quantiles,\n    color=\"tab:red\",\n    ls=\"--\",\n    lw=2,\n)\naxes[0].set_title(\"dCRT\")\nsns.scatterplot(\n    x=theoretical_quantiles,\n    y=empirical_quantiles_logit,\n    ax=axes[1],\n    edgecolor=None,\n)\naxes[1].plot(\n    theoretical_quantiles,\n    theoretical_quantiles,\n    color=\"tab:red\",\n    ls=\"--\",\n    lw=2,\n)\naxes[1].set_title(\"dCRT-logit\")\naxes[0].set_xlabel(\"Theoretical quantiles\")\naxes[0].set_ylabel(\"Empirical quantiles\")\naxes[1].set_xlabel(\"Theoretical quantiles\")\n\nsns.despine()\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the QQ-plot, the points for the dCRT-logit method are closer to the diagonal red\ndashed line compared to those for the dCRT method. This indicates that the test statistics\nfrom dCRT-logit more closely follow a standard Gaussian distribution under the null\nhypothesis.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Power comparison\nWe also compare the statistical power of both methods. The plot below shows the average\npower across the 5 random seeds, with error bars representing the standard deviation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_, ax = plt.subplots(figsize=(4, 3))\nax = sns.pointplot(\n    data=df_plot[[\"power_dcrt\", \"power_dcrt_logit\"]],\n    errorbar=\"sd\",\n    capsize=0.2,\n    linestyle=\"\",\n    c=\"k\",\n)\nsns.despine()\nax.set_ylabel(\"Power\")\nax.set_xticks([0, 1], labels=[\"dCRT\", \"dCRT-logit\"])\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}