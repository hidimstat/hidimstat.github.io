{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Knockoff aggregation on simulated data\n\nIn this example, we show an example of variable selection using\nmodel-X Knockoffs introduced by :footcite:t:`candes2018panning`. A notable\ndrawback of this procedure is the randomness associated with generating\nknockoff variables. This can result in fluctuations of the statistical power\nand false discovery proportion, and consequently, unstable inference.\n\nThis example exhibits the two aggregation procedures described\nby :footcite:t:`pmlr-v119-nguyen20a` and :footcite:t:`Ren_2023` to derandomize\ninference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nfrom joblib import Parallel, delayed\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.model_selection import KFold\n\nfrom hidimstat._utils.scenario import multivariate_simulation\nfrom hidimstat.knockoffs import (\n    model_x_knockoff,\n    model_x_knockoff_bootstrap_e_value,\n    model_x_knockoff_bootstrap_quantile,\n    model_x_knockoff_pvalue,\n)\nfrom hidimstat.statistical_tools.multiple_testing import fdp_power"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data simulation\nThe comparison of the three methods relies on evaluating the\n:term:`False Discovery Proportion <FDP>` (FDP) and statistical power. Assessing these\nmetrics requires knowledge of the actual data-generating process.\nWe therefore use simulated data with the following parameters:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# number of repetitions of he methods\nruns = 20\n# Number of observations\nn_samples = 200\n# Number of variables\nn_features = 150\n# Correlation parameter\nrho = 0.5\n# Ratio of number of variables with non-zero coefficients over total\n# coefficients\nsparsity = 0.2\n# Desired controlled False Discovery Rate (FDR) level\nfdr = 0.1\n# signal noise ration\nsignal_noise_ratio = 10\n# number of repetitions for the bootstraps\nn_bootstraps = 25\n# number of jobs for repetition of the method\nn_jobs = 2\n# verbosity of the joblib\njoblib_verbose = 0\n# Define the seeds for the reproducibility of the example\nrng = np.random.default_rng(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the function for running the three procedures on the same data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def single_run(\n    n_samples,\n    n_features,\n    rho,\n    sparsity,\n    signal_noise_ratio,\n    fdr,\n    n_bootstraps,\n    seed=None,\n):\n    # Generate data\n    X, y, beta_true, noise = multivariate_simulation(\n        n_samples,\n        n_features,\n        rho=rho,\n        support_size=int(n_features * sparsity),\n        signal_noise_ratio=signal_noise_ratio,\n        seed=seed,\n    )\n    non_zero_index = np.where(beta_true)[0]\n\n    # Use model-X Knockoffs [1]\n    selected, test_scores, threshold, X_tildes = model_x_knockoff(\n        X,\n        y,\n        estimator=LassoCV(\n            n_jobs=1,\n            cv=KFold(n_splits=5, shuffle=True, random_state=0),\n            random_state=1,\n        ),\n        n_bootstraps=1,\n        random_state=2,\n    )\n    mx_selection, _ = model_x_knockoff_pvalue(test_scores, fdr=fdr)\n    fdp_mx, power_mx = fdp_power(mx_selection, non_zero_index)\n\n    # Use aggregation model-X Knockoffs [2]\n    selected, test_scores, threshold, X_tildes = model_x_knockoff(\n        X,\n        y,\n        estimator=LassoCV(\n            n_jobs=1,\n            cv=KFold(n_splits=5, shuffle=True, random_state=3),\n            random_state=4,\n        ),\n        n_bootstraps=n_bootstraps,\n        n_jobs=1,\n        random_state=5,\n    )\n\n    # Use p-values aggregation [2]\n    aggregated_ko_selection, _, _ = model_x_knockoff_bootstrap_quantile(\n        test_scores, fdr=fdr, adaptive_aggregation=True\n    )\n\n    fdp_pval, power_pval = fdp_power(aggregated_ko_selection, non_zero_index)\n\n    # Use e-values aggregation [3]\n    eval_selection, _, _ = model_x_knockoff_bootstrap_e_value(\n        test_scores, threshold, fdr=fdr\n    )\n\n    fdp_eval, power_eval = fdp_power(eval_selection, non_zero_index)\n\n    return fdp_mx, fdp_pval, fdp_eval, power_mx, power_pval, power_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the function for plotting the result\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_results(bounds, fdr, n_samples, n_features, power=False):\n    plt.figure(figsize=(5, 5), layout=\"constrained\")\n    for nb in range(len(bounds)):\n        for i in range(len(bounds[nb])):\n            y = bounds[nb][i]\n            x = rng.normal(nb + 1, 0.05)\n            plt.scatter(x, y, alpha=0.65, c=\"blue\")\n\n    plt.boxplot(bounds, sym=\"\")\n    if power:\n        plt.xticks(\n            [1, 2, 3],\n            [\"MX Knockoffs\", \"Quantile aggregation\", \"e-values aggregation\"],\n            rotation=45,\n            ha=\"right\",\n        )\n        plt.title(f\"FDR = {fdr}, n = {n_samples}, p = {n_features}\")\n        plt.ylabel(\"Empirical Power\")\n\n    else:\n        plt.hlines(fdr, xmin=0.5, xmax=3.5, label=\"Requested FDR control\", color=\"red\")\n        plt.xticks(\n            [1, 2, 3],\n            [\"MX Knockoffs\", \"Quantile aggregation\", \"e-values aggregation\"],\n            rotation=45,\n            ha=\"right\",\n        )\n        plt.title(f\"FDR = {fdr}, n = {n_samples}, p = {n_features}\")\n        plt.ylabel(\"Empirical FDP\")\n        plt.legend(loc=\"best\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the function for evaluate the effect of the population\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def effect_number_samples(n_samples):\n    parallel = Parallel(n_jobs, verbose=joblib_verbose)\n    results = parallel(\n        delayed(single_run)(\n            n_samples,\n            n_features,\n            rho,\n            sparsity,\n            signal_noise_ratio,\n            fdr,\n            n_bootstraps,\n            seed=seed,\n        )\n        for seed in range(runs)\n    )\n\n    fdps_mx = []\n    fdps_pval = []\n    fdps_eval = []\n    powers_mx = []\n    powers_pval = []\n    powers_eval = []\n    for fdp_mx, fdp_pval, fdp_eval, power_mx, power_pval, power_eval in results:\n        fdps_mx.append(fdp_mx)\n        fdps_pval.append(fdp_pval)\n        fdps_eval.append(fdp_eval)\n\n        powers_mx.append(power_mx)\n        powers_pval.append(power_pval)\n        powers_eval.append(power_eval)\n\n    # Plot FDP and Power distributions\n\n    fdps = [fdps_mx, fdps_pval, fdps_eval]\n    powers = [powers_mx, powers_pval, powers_eval]\n\n    plot_results(fdps, fdr, n_samples, n_features)\n    plot_results(powers, fdr, n_samples, n_features, power=True)\n    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aggregation methods provide a more stable inference\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "effect_number_samples(n_samples=n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By repeating the model-X Knockoffs, we can see that instability\nof the inference. Additionally, we can see that the aggregation method\nis more stable. However, the e-values aggregation is more conservative,\ni.e. the expect variables of importance is not find.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Limitation of the aggregation methods\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "effect_number_samples(n_samples=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One important point of this method is that they require enough samples to\nestimate the distribution of each feature.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}