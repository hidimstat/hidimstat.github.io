{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Knockoff aggregation on simulated data\n\nIn this example, we show an example of variable selection using\nmodel-X Knockoffs introduced by :footcite:t:`candes2018panning`. A notable\ndrawback of this procedure is the randomness associated with generating\nknockoff variables. This can result in fluctuations of the statistical power\nand false discovery proportion, and consequently, unstable inference.\n\nThis example exhibits the two aggregation procedures described\nby :footcite:t:`pmlr-v119-nguyen20a` and :footcite:t:`Ren_2023` to derandomize\ninference.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports needed for this script\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from joblib import Parallel, delayed\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.utils import check_random_state\n\nfrom hidimstat.knockoffs import (\n    model_x_knockoff,\n    model_x_knockoff_bootstrap_e_value,\n    model_x_knockoff_bootstrap_quantile,\n    model_x_knockoff_pvalue,\n)\nfrom hidimstat.statistical_tools.multiple_testing import fdp_power\nfrom hidimstat._utils.scenario import multivariate_1D_simulation_AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data simulation\nThe comparison of the three methods relies on evaluating the\nFalse Discovery Proportion (FDP) and statistical power. Assessing these\nmetrics requires knowledge of the actual data-generating process.\nWe therefore use simulated data with the following parameters:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# number of repetitions of the methods\nruns = 20\n# Number of observations\nn_samples = 200\n# Number of variables\nn_features = 150\n# Correlation parameter\nrho = 0.4\n# Ratio of number of variables with non-zero coefficients over total\n# coefficients\nsparsity = 0.2\n# Desired controlled False Discovery Rate (FDR) level\nfdr = 0.1\n# signal noise ration\nsnr = 10\n# number of repetitions for the bootstraps\nn_bootstraps = 25\n# seed for the random generator\nseed = 45\n# number of jobs for repetition of the method\nn_jobs = 2\n# verbosity of the joblib\njoblib_verbose = 0\n\nrng = check_random_state(seed)\nseed_list = rng.randint(1, np.iinfo(np.int32).max, runs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the function for running the three procedures on the same data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def single_run(n_samples, n_features, rho, sparsity, snr, fdr, n_bootstraps, seed=None):\n    # Generate data\n    X, y, _, non_zero_index = multivariate_1D_simulation_AR(\n        n_samples, n_features, rho=rho, sparsity=sparsity, seed=seed, snr=snr\n    )\n\n    # Use model-X Knockoffs [1]\n    selected, test_scores, threshold, X_tildes = model_x_knockoff(\n        X,\n        y,\n        estimator=LassoCV(\n            n_jobs=1,\n            cv=KFold(n_splits=5, shuffle=True, random_state=0),\n        ),\n        n_bootstraps=1,\n        random_state=seed,\n    )\n    mx_selection, _ = model_x_knockoff_pvalue(test_scores, fdr=fdr)\n    fdp_mx, power_mx = fdp_power(mx_selection, non_zero_index)\n\n    # Use aggregation model-X Knockoffs [2]\n    selected, test_scores, threshold, X_tildes = model_x_knockoff(\n        X,\n        y,\n        estimator=LassoCV(\n            n_jobs=1,\n            cv=KFold(n_splits=5, shuffle=True, random_state=0),\n        ),\n        n_bootstraps=n_bootstraps,\n        n_jobs=1,\n        random_state=seed,\n    )\n\n    # Use p-values aggregation [2]\n    aggregated_ko_selection, _, _ = model_x_knockoff_bootstrap_quantile(\n        test_scores, fdr=fdr, adaptive_aggregation=True\n    )\n\n    fdp_pval, power_pval = fdp_power(aggregated_ko_selection, non_zero_index)\n\n    # Use e-values aggregation [3]\n    eval_selection, _, _ = model_x_knockoff_bootstrap_e_value(\n        test_scores, threshold, fdr=fdr\n    )\n\n    fdp_eval, power_eval = fdp_power(eval_selection, non_zero_index)\n\n    return fdp_mx, fdp_pval, fdp_eval, power_mx, power_pval, power_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the function for plotting the result\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_results(bounds, fdr, n_samples, n_features, power=False):\n    plt.figure(figsize=(5, 5), layout=\"constrained\")\n    for nb in range(len(bounds)):\n        for i in range(len(bounds[nb])):\n            y = bounds[nb][i]\n            x = np.random.normal(nb + 1, 0.05)\n            plt.scatter(x, y, alpha=0.65, c=\"blue\")\n\n    plt.boxplot(bounds, sym=\"\")\n    if power:\n        plt.xticks(\n            [1, 2, 3],\n            [\"MX Knockoffs\", \"Quantile aggregation\", \"e-values aggregation\"],\n            rotation=45,\n            ha=\"right\",\n        )\n        plt.title(f\"FDR = {fdr}, n = {n_samples}, p = {n_features}\")\n        plt.ylabel(\"Empirical Power\")\n\n    else:\n        plt.hlines(fdr, xmin=0.5, xmax=3.5, label=\"Requested FDR control\", color=\"red\")\n        plt.xticks(\n            [1, 2, 3],\n            [\"MX Knockoffs\", \"Quantile aggregation\", \"e-values aggregation\"],\n            rotation=45,\n            ha=\"right\",\n        )\n        plt.title(f\"FDR = {fdr}, n = {n_samples}, p = {n_features}\")\n        plt.ylabel(\"Empirical FDP\")\n        plt.legend(loc=\"best\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the function for evaluate the effect of the population\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def effect_number_samples(n_samples):\n    parallel = Parallel(n_jobs, verbose=joblib_verbose)\n    results = parallel(\n        delayed(single_run)(\n            n_samples, n_features, rho, sparsity, snr, fdr, n_bootstraps, seed=seed\n        )\n        for seed in seed_list\n    )\n\n    fdps_mx = []\n    fdps_pval = []\n    fdps_eval = []\n    powers_mx = []\n    powers_pval = []\n    powers_eval = []\n    for fdp_mx, fdp_pval, fdp_eval, power_mx, power_pval, power_eval in results:\n        fdps_mx.append(fdp_mx)\n        fdps_pval.append(fdp_pval)\n        fdps_eval.append(fdp_eval)\n\n        powers_mx.append(power_mx)\n        powers_pval.append(power_pval)\n        powers_eval.append(power_eval)\n\n    # Plot FDP and Power distributions\n\n    fdps = [fdps_mx, fdps_pval, fdps_eval]\n    powers = [powers_mx, powers_pval, powers_eval]\n\n    plot_results(fdps, fdr, n_samples, n_features)\n    plot_results(powers, fdr, n_samples, n_features, power=True)\n    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aggregation methods provide a more stable inference\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "effect_number_samples(n_samples=n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By repeating the model-X Knockoffs, we can see that instability\nof the inference. Additionally, we can see that the aggregation method\nis more stable. However, the e-values aggregation is more conservative,\ni.e. the exepect variables of importance is not find.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Limitation of the aggregation methods\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "effect_number_samples(n_samples=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One important point of this method is that they require enough samples to\nestimate the distribution of each feature.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}