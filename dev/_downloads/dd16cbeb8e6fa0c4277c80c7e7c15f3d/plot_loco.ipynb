{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Leave-One-Covariate-Out (LOCO) feature importance with different regression models\n\nThis example demonstrates how to compare LOCO feature importance [:footcite:t:`Williamson_General_2023`] across different\npredictive models on the same regression dataset. LOCO is model-agnostic and can be\napplied to any predictive model. Here, we use a linear model, a random forest, a neural\nnetwork, and a support vector machine. We compare the models based on their predictive\nperformance (R2 score) and the LOCO feature importance they yield.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading and preparing the data\nWe begin by simulating a regression dataset with 10 features, 5 of which\nare in the support set, meaning they contribute to generating the outcome. In this example,\nwe use a simulated dataset to have access to the true support set of features and\nevaluate how well the different models identify these important features.\nThe data is then split into training and test sets. These sets are used both to fit\nthe predictive models and within the LOCO procedure, which refits models on subsets\nof features that exclude the feature of interest.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\n\nX, y, beta = make_regression(\n    n_samples=300,\n    n_features=10,\n    n_informative=5,\n    random_state=0,\n    coef=True,\n    noise=10.0,\n)\n\n# We convert the coefficients of the data-generating process into a binary array\n# indicating the true support set of features.\nbeta = beta != 0\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=0.2,\n    random_state=0,\n    shuffle=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fitting models and computing LOCO feature importance\nWe define a list of predictive models to compare. We use RidgeCV for linear\nregression, RandomForestRegressor for a tree-based model, MLPRegressor for a\nneural network, and SVR for a support vector machine, with RBF kernel. We then fit\neach model on the training data, compute the LOCO feature importance on the test\ndata, and store the results in a DataFrame for comparison.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.svm import SVR\n\nfrom hidimstat import LOCO\n\nmodels_list = [\n    RidgeCV(),\n    RandomForestRegressor(n_estimators=150, random_state=0),\n    MLPRegressor(\n        hidden_layer_sizes=(8),\n        random_state=0,\n        max_iter=500,\n        learning_rate_init=0.1,\n    ),\n    SVR(kernel=\"linear\"),\n]\n\ndf_list = []\nfor model in models_list:\n    # Fit the full model\n    model = model.fit(X_train, y_train)\n    loco = LOCO(model)\n    # For each feature, remove it from the dataset, refit the model, and compute LOCO\n    # importance. This process is repeated for all features to assess their individual\n    # contributions.\n    loco.fit(X_train, y_train)\n    importances = loco.importance(X_test, y_test)\n    df_list.append(\n        pd.DataFrame(\n            {\n                \"feature\": list(range(X.shape[1])),\n                \"importance\": importances,\n                \"model\": model.__class__.__name__,\n                \"R2 score\": model.score(X_test, y_test),\n            }\n        )\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The predictive performance of the models can be compared using their R2 scores.\nThis helps assess how effectively each model captures the underlying data-generating\nprocess.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_plot = pd.concat(df_list)\ndf_plot.groupby(\"model\").mean()[\"R2 score\"].to_frame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization of LOCO feature importance\nFinally, we visualize the LOCO feature importance for each model using a horizontal\nbar plot. The true support features are highlighted in the plot with a green shaded\nbackground.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport seaborn as sns\n\nax = sns.barplot(\n    data=df_plot,\n    y=\"feature\",\n    x=\"importance\",\n    hue=\"model\",\n    palette=\"muted\",\n    orient=\"h\",\n)\nsns.despine()\n\nfor i, support in enumerate(beta):\n    if support != 0:\n        ax.axhspan(\n            i - 0.45,\n            i + 0.45,\n            color=\"tab:olive\",\n            alpha=0.3,\n            zorder=-1,\n            label=\"True Support\" if i == 1 else None,\n        )\nax.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The plot shows that the different models all identify the true support features and\nassign them higher importance scores. However, the magnitude of the importance scores\nvaries across models. It can be observed that models with a greater predictive\nperformance (higher R2 score) tend to assign higher importance scores to the true\nsupport features.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}