{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Controlled multiple variable selection on the Wisconsin breast cancer dataset\n\nIn this example, we explore the basics of variable selection and illustrate the need to\nstatistically control the amount of faslely selected variables. We compare two variable\nselection methods: the Lasso and the Model-X Knockoffs :footcite:t:`candes2018panning`.\nWe show how the Lasso is not robust to the presence of irrelevant variables, while the\nKnockoffs (KO) method is able to address this issue.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\n\nseed = 0\nrng = np.random.RandomState(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the breast cancer dataset\nThere are 569 samples and 30 features that correspond to tumor attributes.\nThe downstream task is to classify tumors as benign or malignant. We leave out 10% of\nthe data to evaluate the performance of the Logistic Lasso (Logistic Regression with\nL1 regularization) on the prediction task.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\ndata = load_breast_cancer()\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.1, random_state=seed\n)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\nn_train, p = X_train.shape\nn_test = X_test.shape[0]\nfeature_names = [str(name) for name in data.feature_names]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selecting variables with the Logistic Lasso\nWe want to select variables that are relevant to the outcome, i.e. tumor\ncharacteristics that are associated with tumor malignance. We start off by applying a\nclassical method using Lasso logistic regression and retaining variables with non-null\ncoefficients:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n\nclf = LogisticRegressionCV(\n    Cs=np.logspace(-3, 3, 10), penalty=\"l1\", solver=\"liblinear\", random_state=rng\n)\nclf.fit(X_train, y_train)\nprint(f\"Accuracy of Lasso on test set: {clf.score(X_test, y_test):.3f}\")\n\n\nselected_lasso = np.where(np.abs(clf.coef_[0]) > 1e-6)[0]\nprint(f\"The Lasso selects {len(selected_lasso)} variables:\")\nprint(f\"{'Variable name':<30} | {'Coefficient':>10}\")\nprint(\"-\" * 45)\nfor i in selected_lasso:\n    print(f\"{feature_names[i]:<30} | {clf.coef_[0][i]:>10.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating the rejection set\nSince we do not have the ground truth for the selected variables (i.e. we do not know\nthe relationship between the tumor characteristics and the the malignance of the tumor\n), we cannot evaluate this selection set directly. To investigate the reliability of\nthis method, we artificially increase the number of variables by adding noisy copies\nof the features. These are correlated with the variables in the dataset, but are not\nrelated to the outcome.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "repeats_noise = 5  # Number of synthetic noisy sets to add\n\nnoises_train = [X_train]\nnoises_test = [X_test]\nfeature_names_noise = [x for x in feature_names]\nfor k in range(repeats_noise):\n    X_train_c = X_train.copy()\n    X_test_c = X_test.copy()\n    noises_train.append(X_train_c + 2 * rng.randn(n_train, p))\n    noises_test.append(X_test_c + 2 * rng.randn(n_test, p))\n    feature_names_noise += [f\"spurious #{k*p+i}\" for i in range(p)]\n\nnoisy_train = np.concatenate(noises_train, axis=1)\nnoisy_test = np.concatenate(noises_test, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are 180 features, 30 of them are real and 150 of them are fake and independent\nof the outcome. We now apply the Lasso (with cross-validation to select the best\nregularization parameter) to the noisy dataset and observe the results:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lasso_noisy = LogisticRegressionCV(\n    Cs=np.logspace(-3, 3, 10),\n    penalty=\"l1\",\n    solver=\"liblinear\",\n    random_state=rng,\n    n_jobs=1,\n)\nlasso_noisy.fit(noisy_train, y_train)\ny_pred_noisy = lasso_noisy.predict(noisy_test)\nprint(\n    f\"Accuracy of Lasso on test set with noise: {lasso_noisy.score(noisy_test, y_test):.3f}\"\n)\n\nselected_mask = [\n    \"selected\" if np.abs(x) > 1e-6 else \"not selected\" for x in lasso_noisy.coef_[0]\n]\ndf_lasso_noisy = pd.DataFrame(\n    {\n        \"score\": np.abs(lasso_noisy.coef_[0]),\n        \"variable\": feature_names_noise,\n        \"selected\": selected_mask,\n    }\n)\n# Count how many selected features are actually noise\nnum_false_discoveries = np.sum(\n    np.array(selected_mask[p:]) == \"selected\"\n)  # Count the number of selected spurious variables\nprint(f\"The Lasso makes at least {num_false_discoveries} False Discoveries!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Lasso selects many spurious variables that are not directly related to the outcome.\nTo mitigate this problem, we can use one of the statistically controlled variable\nselection methods implemented in hidimstat. This ensures that the proportion of False\nDiscoveries is below a certain bound set by the user in all scenarios.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Controlled variable selection with Knockoffs\nWe use the Model-X Knockoff procedure to control the FDR (False Discovery Rate). The\nselection of variables is based on the Lasso Coefficient Difference (LCD) statistic\n:footcite:t:`candes2018panning`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from hidimstat import model_x_knockoff\n\nfdr = 0.2\n\nselected, test_scores, threshold, X_tildes = model_x_knockoff(\n    noisy_train,\n    y_train,\n    estimator=LogisticRegressionCV(\n        solver=\"liblinear\",\n        penalty=\"l1\",\n        Cs=np.logspace(-3, 3, 10),\n        random_state=rng,\n        tol=1e-3,\n        max_iter=1000,\n    ),\n    n_bootstraps=1,\n    random_state=0,\n    tol_gauss=1e-15,\n    preconfigure_estimator=None,\n    fdr=fdr,\n)\n\n# Count how many selected features are actually noise\nnum_false_discoveries = np.sum(selected >= p)\nprint(f\"Knockoffs make at least {num_false_discoveries} False Discoveries\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the results\nWe can compare the selection sets obtained by the two methods. In addition to the\nbinary selection (selected or not), we can also visualize the the KO statistic\nalong with the selection threshold for the knockoffs and the absolute value of the\nLasso coefficients. We plot the 25 most important features according to the KO\nstatistic.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport seaborn as sns\n\nselected_mask = np.array([\"not selected\"] * len(test_scores))\nselected_mask[selected] = \"selected\"\ndf_ko = pd.DataFrame(\n    {\n        \"score\": test_scores,\n        \"variable\": feature_names_noise,\n        \"selected\": selected_mask,\n    }\n)\ndf_ko = df_ko.sort_values(by=\"score\", ascending=False).head(25)\n\nfig, axes = plt.subplots(\n    1,\n    2,\n    sharey=True,\n)\nax = axes[0]\nsns.scatterplot(\n    data=df_ko,\n    x=\"score\",\n    y=\"variable\",\n    hue=\"selected\",\n    ax=ax,\n    palette={\"selected\": \"tab:red\", \"not selected\": \"tab:gray\"},\n)\nax.axvline(x=threshold, color=\"k\", linestyle=\"--\", label=\"Threshold\")\nax.legend()\nax.set_xlabel(\"KO statistic (LCD)\")\nax.set_ylabel(\"\")\nax.set_title(\"Knockoffs\", fontweight=\"bold\")\n\nax = axes[1]\nsns.scatterplot(\n    data=df_lasso_noisy[df_lasso_noisy[\"variable\"].isin(df_ko[\"variable\"])],\n    x=\"score\",\n    y=\"variable\",\n    hue=\"selected\",\n    ax=ax,\n    palette={\"selected\": \"tab:red\", \"not selected\": \"tab:gray\"},\n    legend=False,\n)\nax.set_xlabel(\"$|\\\\hat{\\\\beta}|$\")\nax.axvline(\n    x=0,\n    color=\"k\",\n    linestyle=\"--\",\n)\nax.set_title(\"Lasso\", fontweight=\"bold\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can clearly see that the knockoffs procedure is more conservative than the Lasso\nand rejects the spurious features while many of them are selected by the Lasso. It is\nalso interesting to note that some of the selected variables (with the high KO\nstatistic (e.g., worst radius, worst area, mean concave points) are also variables\nwith the largest Lasso coefficients.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}