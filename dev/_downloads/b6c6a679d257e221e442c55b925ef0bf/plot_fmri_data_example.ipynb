{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Support Recovery on fMRI Data\n\nThis example compares methods based on Desparsified Lasso (DL) to estimate\nvoxel activation maps associated with behavior, specifically decoder map support.\nAll methods presented here provide statistical guarantees.\n\nTo demonstrate these methods, we use the Haxby dataset, focusing on the\n'face vs house' contrast. We analyze labeled activation maps from a single subject\nto produce a brain map showing the discriminative pattern between these two conditions.\n\nThis example illustrates that in high-dimensional settings (many voxels),\nDL becomes impractical due to memory constraints. However, we can overcome\nthis limitation using feature aggregation methods that leverage the spatial structure\nof the data (high correlation between neighboring voxels).\n\nWe introduce two feature aggregation methods that maintain statistical guarantees,\nthough with a small spatial tolerance in support detection (i.e., they may identify\nnull covariates \"close\" to non-null covariates):\n\n* Clustered Desparsified Lasso (CLuDL): combines clustering (parcellation)\n    with statistical inference\n* Ensemble Clustered Desparsified Lasso (EnCluDL): adds randomization\n    to the clustering process\n\nEnCluDL is particularly powerful as it doesn't rely on a single clustering choice.\nAs demonstrated in :footcite:t:`chevalier2021decoding`, it produces relevant\npredictive regions across various tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports needed for this script\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import resource\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib.pyplot import get_cmap\nfrom nilearn import datasets\nfrom nilearn.image import mean_img\nfrom nilearn.maskers import NiftiMasker\nfrom nilearn.plotting import plot_stat_map, show\nfrom sklearn.cluster import FeatureAgglomeration\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction import image\nfrom sklearn.utils import Bunch\n\nfrom hidimstat.ensemble_clustered_inference import (\n    clustered_inference,\n    clustered_inference_pvalue,\n)\nfrom hidimstat.ensemble_clustered_inference import (\n    ensemble_clustered_inference,\n    ensemble_clustered_inference_pvalue,\n)\nfrom hidimstat.desparsified_lasso import (\n    desparsified_lasso,\n    desparsified_lasso_pvalue,\n)\nfrom hidimstat.statistical_tools.p_values import zscore_from_pval\n\n\n# Remmove warnings during loading data\nwarnings.filterwarnings(\n    \"ignore\", message=\"The provided image has no sform in its header.\"\n)\n\n# Limit the ressoruce use for the example to 5 G or maximum of possible.\nlimit_5G = int(5 * 1e9)\nsoft, hard = resource.getrlimit(resource.RLIMIT_AS)\nnew_soft_limit = limit_5G if soft < 0 else min(limit_5G, soft)\nnew_hard_limit = limit_5G if hard < 0 else min(limit_5G, hard)\nresource.setrlimit(resource.RLIMIT_AS, (new_soft_limit, new_hard_limit))\nn_job = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to fetch and preprocess Haxby dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def preprocess_haxby(subject=2, memory=None):\n    \"\"\"Gathering and preprocessing Haxby dataset for a given subject.\"\"\"\n\n    # Gathering data\n    haxby_dataset = datasets.fetch_haxby(subjects=[subject])\n    fmri_filename = haxby_dataset.func[0]\n\n    behavioral = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n\n    conditions = behavioral[\"labels\"].values\n    session_label = behavioral[\"chunks\"].values\n\n    condition_mask = np.logical_or(conditions == \"face\", conditions == \"house\")\n    groups = session_label[condition_mask]\n\n    # Loading anatomical image (back-ground image)\n    if haxby_dataset.anat[0] is None:\n        bg_img = None\n    else:\n        bg_img = mean_img(haxby_dataset.anat, copy_header=True)\n\n    # Building target where '1' corresponds to 'face' and '-1' to 'house'\n    y = np.asarray((conditions[condition_mask] == \"face\") * 2 - 1)\n\n    # Loading mask\n    mask_img = haxby_dataset.mask\n    masker = NiftiMasker(\n        mask_img=mask_img,\n        standardize=\"zscore_sample\",\n        smoothing_fwhm=None,\n        memory=memory,\n    )\n\n    # Computing masked data\n    fmri_masked = masker.fit_transform(fmri_filename)\n    X = np.asarray(fmri_masked)[condition_mask, :]\n\n    return Bunch(X=X, y=y, groups=groups, bg_img=bg_img, masker=masker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gathering and preprocessing Haxby dataset for a given subject\nThe `preprocess_haxby` function make the preprocessing of the Haxby dataset,\nit outputs the preprocessed activation maps for the two conditions\n'face' or 'house' (contained in `X`), the conditions (in `y`),\nthe session labels (in `groups`) and the mask (in `masker`).\nYou may choose a subject in [1, 2, 3, 4, 5, 6]. By default subject=2.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = preprocess_haxby(subject=2)\nX, y, groups, masker = data.X, data.y, data.groups, data.masker\nmask = masker.mask_img_.get_fdata().astype(bool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initializing FeatureAgglomeration object that performs the clustering\nFor fMRI data taking 500 clusters is generally a good default choice.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_clusters = 500\n# Deriving voxels connectivity.\nshape = mask.shape\nn_x, n_y, n_z = shape[0], shape[1], shape[2]\nconnectivity = image.grid_to_graph(n_x=n_x, n_y=n_y, n_z=n_z, mask=mask)\n# Initializing FeatureAgglomeration object.\nward = FeatureAgglomeration(n_clusters=n_clusters, connectivity=connectivity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Making the inference with several algorithms\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we try to recover the discriminative pattern by computing\np-values from desparsified lasso.\nDue to the size of the X, it's not possible to use this method with a limit\nof 5 G for memory. To handle this problem, the following methods use some\nfeature aggregation methods.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    beta_hat, sigma_hat, precision_diagonal = desparsified_lasso(\n        X, y, noise_method=\"median\", max_iteration=1000\n    )\n    pval_dl, _, one_minus_pval_dl, _, cb_min, cb_max = desparsified_lasso_pvalue(\n        X.shape[0], beta_hat, sigma_hat, precision_diagonal\n    )\nexcept MemoryError as err:\n    pval_dl = None\n    one_minus_pval_dl = None\n    print(\"As expected, Desparsified Lasso uses too much memory.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, the clustered inference algorithm which combines parcellation\nand high-dimensional inference (c.f. References).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ward_, beta_hat, theta_hat, omega_diag = clustered_inference(\n    X, y, ward, n_clusters, scaler_sampling=StandardScaler(), tolerance=1e-2\n)\nbeta_hat, pval_cdl, _, one_minus_pval_cdl, _ = clustered_inference_pvalue(\n    X.shape[0], None, ward_, beta_hat, theta_hat, omega_diag\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below, we run the ensemble clustered inference algorithm which adds a\nrandomization step over the clustered inference algorithm (c.f. References).\nTo make the example as short as possible we take `n_bootstraps=5`\nwhich means that 5 different parcellations are considered and\nthen 5 statistical maps are produced and aggregated into one.\nHowever you might benefit from clustering randomization taking\n`n_bootstraps=25` or `n_bootstraps=100`, also we set `n_jobs=2`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "list_ward, list_beta_hat, list_theta_hat, list_omega_diag = (\n    ensemble_clustered_inference(\n        X,\n        y,\n        ward,\n        n_clusters,\n        groups=groups,\n        scaler_sampling=StandardScaler(),\n        n_bootstraps=5,\n        max_iteration=6000,\n        tolerance=1e-2,\n        n_jobs=2,\n    )\n)\nbeta_hat, selected = ensemble_clustered_inference_pvalue(\n    X.shape[0],\n    False,\n    list_ward,\n    list_beta_hat,\n    list_theta_hat,\n    list_omega_diag,\n    fdr=0.1,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the results\nTo allow a better visualization of the disciminative pattern we will plot\nz-maps rather than p-value maps. Assuming Gaussian distribution of the\nestimators we can recover a z-score from a p-value by using the\ninverse survival function.\n\nFirst, we set theoretical FWER target at 10%.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_samples, n_features = X.shape\ntarget_fwer = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now translate the FWER target into a z-score target.\nFor the permutation test methods we do not need any additional correction\nsince the p-values are already adjusted for multiple testing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "zscore_threshold_corr = zscore_from_pval((target_fwer / 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Other methods need to be corrected. We consider the Bonferroni correction.\nFor methods that do not reduce the feature space, the correction\nconsists in dividing by the number of features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "correction = 1.0 / n_features\nzscore_threshold_no_clust = zscore_from_pval((target_fwer / 2) * correction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For methods that parcelates the brain into groups of voxels, the correction\nconsists in dividing by the number of parcels (or clusters).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "correction_clust = 1.0 / n_clusters\nzscore_threshold_clust = zscore_from_pval((target_fwer / 2) * correction_clust)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we can plot the thresholded z-score maps by translating the\np-value maps estimated previously into z-score maps and using the\nsuitable threshold. For a better readability, we make a small function\ncalled `plot_map` that wraps all these steps.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_map(\n    data,\n    threshold,\n    title=None,\n    cut_coords=[-25, -40, -5],\n    masker=masker,\n    bg_img=data.bg_img,\n    vmin=None,\n    vmax=None,\n):\n    zscore_img = masker.inverse_transform(data)\n    plot_stat_map(\n        zscore_img,\n        threshold=threshold,\n        bg_img=bg_img,\n        dim=-1,\n        cut_coords=cut_coords,\n        title=title,\n        cmap=get_cmap(\"bwr\"),\n        vmin=vmin,\n        vmax=vmax,\n    )\n\n\nif pval_dl is not None:\n    plot_map(\n        zscore_from_pval(pval_dl, one_minus_pval_dl),\n        float(zscore_threshold_no_clust),\n        \"Desparsified Lasso\",\n    )\n\nplot_map(\n    zscore_from_pval(pval_cdl, one_minus_pval_cdl),\n    float(zscore_threshold_clust),\n    \"CluDL\",\n)\n\nplot_map(selected, 0.5, \"EnCluDL\", vmin=-1, vmax=1)\n# Finally, calling plotting.show() is necessary to display the figure when\n# running as a script outside IPython\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis of the results\nAs advocated in introduction, the methods that do not reduce the original\nproblem are not satisfying since they are too conservative.\nAmong those methods, the only one that makes discoveries is the one that\nthreshold the SVR decoder using a parametric approximation.\nHowever this method has no statistical guarantees and we can see that some\nisolated voxels are discovered, which seems quite spurious.\nThe discriminative pattern derived from the clustered inference algorithm\n(CluDL) show that the method is less conservative.\nHowever, some reasonable paterns are also included in this solution.\nFinally, the solution provided by the ensemble clustered inference algorithm\n(EnCluDL) seems realistic as we recover the visual cortex and do not make\nspurious discoveries.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}