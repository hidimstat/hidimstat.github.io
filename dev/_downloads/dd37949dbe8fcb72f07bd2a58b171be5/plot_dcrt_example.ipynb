{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Distilled Conditional Randomization Test (dCRT) using Lasso vs Random Forest learners\n\nThis example compares the performance of d0crt based on\nthe lasso (1) and random forest (2) implementations. The number of\nrepetitions is set to 10. The metrics used are the type-I error and\nthe power\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports needed for this script\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LassoCV\n\nfrom hidimstat import D0CRT\nfrom hidimstat._utils.scenario import multivariate_simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Processing the computations\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results_list = []\nfor sim_ind in range(10):\n    print(f\"Processing: {sim_ind+1}\")\n    np.random.seed(sim_ind)\n\n    # Number of observations\n    n = 100\n    # Number of variables\n    p = 10\n    # Number of relevant variables\n    n_signal = 2\n    # Signal-to-noise ratio\n    signal_noise_ratio = 4\n    # Correlation coefficient\n    rho = 0.8\n    # Nominal false positive rate\n    alpha = 5e-2\n\n    X, y, beta_true, noise = multivariate_simulation(\n        n_samples=n,\n        n_features=p,\n        support_size=n_signal,\n        rho=rho,\n        signal_noise_ratio=signal_noise_ratio,\n        shuffle=True,\n        seed=sim_ind,\n    )\n\n    # Applying a reLu function on the outcome y to get non-linear relationships\n    y = np.maximum(0.0, y)\n\n    ## dcrt Lasso ##\n    d0crt_lasso = D0CRT(\n        estimator=LassoCV(random_state=42, n_jobs=1), screening_threshold=None\n    )\n    d0crt_lasso.fit_importance(X, y)\n    pvals_lasso = d0crt_lasso.pvalues_\n    results_list.append(\n        {\n            \"model\": \"Lasso\",\n            \"type-1 error\": sum(pvals_lasso[np.logical_not(beta_true)] < alpha)\n            / (p - n_signal),\n            \"power\": sum(pvals_lasso[beta_true] < alpha) / (n_signal),\n        }\n    )\n\n    ## dcrt Random Forest ##\n    d0crt_random_forest = D0CRT(\n        estimator=RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=1),\n        screening_threshold=None,\n    )\n    d0crt_random_forest.fit_importance(X, y)\n    pvals_forest = d0crt_random_forest.pvalues_\n    results_list.append(\n        {\n            \"model\": \"RF\",\n            \"type-1 error\": sum(pvals_forest[np.logical_not(beta_true)] < alpha)\n            / (n_signal),\n            \"power\": sum(pvals_forest[beta_true] < alpha) / (n_signal),\n        }\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the comparison\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_plot = pd.DataFrame(results_list)\n\n_, ax = plt.subplots(nrows=1, ncols=2)\nsns.swarmplot(data=df_plot, x=\"model\", y=\"type-1 error\", ax=ax[0], hue=\"model\")\nax[0].axhline(alpha, linewidth=1, color=\"tab:red\", ls=\"--\", label=\"Nominal Level\")\nax[0].legend()\nax[0].set_ylim(-0.01)\n\nsns.boxplot(data=df_plot, x=\"model\", y=\"power\", ax=ax[1], hue=\"model\")\n\nsns.despine()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both methods empirically control the type-I error. In addition, it can\nbe observed that the power of the Random Forest model is generally higher\nthan that of the Lasso model, indicating a better ability to detect true\nsignals in the data. This is likely due to the capacity of the Random\nForest model to capture interactions and non-linear relationships which\nare introduced in this simulation by the ReLU transformation applied to the\noutcome.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}